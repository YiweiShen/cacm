<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>February 2026 &#8211; Communications of the ACM</title>
	<atom:link href="https://cacm.acm.org/issue/latest/feed" rel="self" type="application/rss+xml" />
	<link>https://cacm.acm.org</link>
	<description></description>
	<lastBuildDate>Thu, 12 Feb 2026 20:14:49 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.8.3</generator>

<image>
	<url>https://cacm.acm.org/wp-content/uploads/2023/11/cropped-cropped-cacm_favicon-1.png?w=32</url>
	<title>February 2026 &#8211; Communications of the ACM</title>
	<link>https://cacm.acm.org</link>
	<width>32</width>
	<height>32</height>
</image> 
<site xmlns="com-wordpress:feed-additions:1">212686646</site>	<item>
		<title>Specification-Guided Reinforcement Learning</title>
		<link>https://cacm.acm.org/research/specification-guided-reinforcement-learning/</link>
					<comments>https://cacm.acm.org/research/specification-guided-reinforcement-learning/#respond</comments>
		
		<dc:creator><![CDATA[Rajeev Alur, Suguman Bansal, Osbert Bastani, and Kishor Jothimurugan]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 17:01:27 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775534</guid>

					<description><![CDATA[<p>The DIRL algorithm highlights several advantages of specification-guided RL.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">In reinforcement learning (RL), an <i>agent</i> learns to achieve its goal by interacting with its environment and learning from feedback about its successes and failures. This feedback is typically encoded as numerical rewards—for example, positive rewards for beneficial outcomes and negative rewards for harmful outcomes. Traditional RL algorithms assume the reward is provided by the user, and designing an effective reward function can be a daunting task. For example, consider a robot organizing boxes in a warehouse. To ensure the robot successfully moves boxes to the right locations while avoiding collisions, we might provide positive rewards for moving boxes in the right directions and negative rewards for collisions. However, there is a wide variety of ways to implement such a reward function: Should rewards be given immediately after moving a box or after multiple successful moves? How should failures such as incorrect placements or collisions be handled? There is also the question of balancing the objective with safety constraints—if the warehouse robot receives rewards solely for obstacle avoidance, it might focus on safety and never move, whereas overweighting the objective may lead it to take dangerous shortcuts. Beyond the question of balancing the objective with safety constraints, the reward function may also need to introduce new variables to keep track of progress—for example, which rooms still have boxes that need to be cleared.</p>
<aside class="boxed-text">
<div class="article-key-insights">
<h2>Key Insights</h2>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-2">Temporal logics provide a natural way to specify what an agent should do over time, offering an elegant solution to the challenges of traditional reward engineering in RL, which requires low-level behavioral guidance and often leads to unintended outcomes.</p>
</li>
<li class="list-item">
<p id="p-3">Learning directly from temporal logic specifications in the most general form presents theoretical limitations, as it cannot provide <i>probably approximately correct</i> (PAC) guarantees. This is due to the non-robustness of temporal specifications.</p>
</li>
<li class="list-item">
<p id="p-4">Algorithms such as DIRL use the structure of logical specifications to break complex tasks into smaller subtasks, each with its own simple reward. This allows the agent to plan at a high level and learn more efficiently, reducing the number of interactions needed with the environment.</p>
</li>
</ul>
</div>
</aside>
<p id="p-5">The art of designing an effective reward function is called <i>reward engineering</i>. The challenge is that reward engineering conflates the problem of <i>task specification</i> (i.e., what is the task to be performed?) with the problem of <i>reward shaping</i> (i.e., what rewards best guide the robot to solve the task?). Recent work has proposed to separate these concerns by using <i>logical specifications</i> to encode the desired behavior of an RL agent, which can automatically be compiled into shaped rewards to train the agent. <i>Temporal logics</i> such as <i>linear temporal logic (LTL)</i><a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a> are particularly suitable for specifying RL tasks, as they provide rigorous syntax and semantics for reasoning about sequences of events and states over time. For instance, instead of crafting numerical rewards, the desired behavior of the warehouse robot can be encoded as a sequence of logical steps: (1) Go to object while avoiding obstacles, (2) Pick up object, (3) Go to target location while avoiding obstacles, and (4) Place object. Each step can be encoded using logical predicates. If <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>g</mi></math></span> denotes a target location and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>o</mi></math></span> denotes an obstacle location, then the requirement of safely visiting location <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>g</mi></math></span> can be written in LTL as Eventually <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>g</mi><mo>∧</mo></math></span> Always <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>¬</mo><mi>o</mi></mrow></math></span>, where Eventually and Always are temporal operators.</p>
<p id="p-6">The key question then is how to train an agent to satisfy a given logical specification. One strategy would be to compile the specification into a shaped reward function, which can then be used in conjunction with a traditional RL algorithm to train an agent. However, compared to a reward function, the logical specification transparently represents task structure in a way that can be exploited by the RL algorithm. In particular, <i>specification-guided RL</i> aims to design novel RL algorithms that train agents directly from logical specifications.</p>
<p id="p-7">In this article, we provide an overview of some recent progress on specification-guided RL. This is an active area of research, with a growing body of literature.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a><sup>–</sup><a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a><sup>–</sup><a class="reference-link xref xref-bibr" href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> We first highlight surprising negative theoretical results that provide limits on specification-guided RL in the infinite horizon setting. Our discussion of these results provides an insight into some key differences between logical specifications and reward functions in the context of RL (curious readers can find formal proofs and further details in the cited references). In practice, it often suffices to require that the agent completes the assigned task within a specified finite number of steps. This finite horizon setting offers opportunities for positive results and practical algorithms. As a representative example, we describe DIRL, an algorithm that combines conventional reward-based RL with high-level planning to efficiently learn policies for complex tasks. Rather than crafting a single reward function for the entire task, DIRL exploits the structure of the logical specification to automatically infer a set of subtasks. Each subtask is associated with its own reward function and represented as an edge in a task graph, which serves as the foundation for high-level planning. DIRL alternates between planning over the task graph and learning subtask policies. This decomposition allows DIRL to tackle complex tasks with significantly fewer environment interactions compared to baseline methods. Through this integration of symbolic structure and learning, DIRL highlights several advantages of specification-guided RL.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Learning Optimal Policies</h2>
<p id="p-8">The objective of RL is to train the agent to act in an environment to accomplish a specific task—for example, learn what action should be performed in any given state so that the robot will eventually reach a specific room. A key feature of RL is the environment is assumed to be <i>unknown</i>. Hence, the <i>policy</i> that enables the agent to act must be learned by exploring the environment.</p>
<section id="sec3" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Markov decision processes.</strong>  The environment is modeled as a Markov decision process (MDP). Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1a</a> shows an MDP with <i>states</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>S</mi><mo>=</mo><mo>{</mo><msub><mi>s</mi><mn>0</mn></msub><mo>,</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><msub><mi>s</mi><mn>2</mn></msub><mo>,</mo><msub><mi>s</mi><mn>3</mn></msub><mo>}</mo></mrow></math></span> and <i>actions</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>A</mi><mo>=</mo><mo>{</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>}</mo></mrow></math></span>. Actions cause state transitions according to <i>transition probabilities</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>T</mi><mo> : </mo><mi>S</mi><mo>×</mo><mi>A</mi><mo>×</mo><mi>S</mi><mo>→</mo><mo>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>]</mo></mrow></math></span>. For example, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>1</mn></msub></math></span> from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> leads to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> or <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>3</mn></msub></math></span> with equal probability. The <i>initial state distribution</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>η</mi></math></span> describes the distribution of states the system initializes in. Here, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>η</mi></math></span> is the dirac distribution at <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span>—that is, with <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>η</mi><mo>(</mo><msub><mi>s</mi><mi>o</mi></msub><mo>)</mo><mo>=</mo><mn>1</mn></mrow></math></span>. Mathematically, an MDP <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>M</mi></math></span> is a tuple consisting of these four components<a class="footnote-link xref xref-fn" href="#fn1" data-jats-rid="fn1" data-jats-ref-type="fn"><sup>a</sup></a>—that is, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>M</mi><mo>=</mo><mo>(</mo><mi>S</mi><mo>,</mo><mi>A</mi><mo>,</mo><mi>T</mi><mo>,</mo><mi>η</mi><mo>)</mo></mrow></math></span>. An <i>infinite run</i> of the MDP is an infinite sequence of state-action pairs describing the evolution of the system over time. A possible infinite run in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1a</a> is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ρ</mi><mo>=</mo><msub><mi>s</mi><mn>0</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>2</mn></msub></mover><msub><mi>s</mi><mn>2</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>1</mn></msub></mover><msub><mi>s</mi><mn>1</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>2</mn></msub></mover><msub><mi>s</mi><mn>1</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>2</mn></msub></mover><mo>⋯</mo></mrow></math></span> in which the agent reaches <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> via <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>2</mn></msub></math></span>. Similarly, a <i>finite run</i> of length <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> describes the evolution of the system for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> time steps—for example, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ρ</mi><mo>=</mo><msub><mi>s</mi><mn>0</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>2</mn></msub></mover><msub><mi>s</mi><mn>2</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>1</mn></msub></mover><msub><mi>s</mi><mn>1</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>2</mn></msub></mover><msub><mi>s</mi><mn>1</mn></msub><mover><mo>→</mo><msub><mi>a</mi><mn>2</mn></msub></mover><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span> is a finite run of length 4.</p>
<figure id="F1" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 1. " src="https://cacm.acm.org/wp-content/uploads/2025/12/3744706_fig01_71bd47.jpg" alt="" data-image-id="F1" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 1. </span> <span class="p">Example MDPs.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-11">In RL, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>T</mi></math></span> is <i>a priori</i> unknown, and the agent must learn about the environment by taking actions and observing transitions. In Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1a</a>, if the agent repeatedly takes action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>1</mn></msub></math></span> in state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span>, it observes that the system transitions to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> approximately half the time. The goal is to learn a <i>policy</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>π</mi><mo> : </mo><mi>S</mi><mo>→</mo><mi>A</mi></mrow></math></span> mapping states to actions. This policy induces a distribution over runs, generated by sampling an initial state from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>η</mi></math></span>, and iteratively using <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>π</mi></math></span> to select actions and sample next states from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>T</mi></math></span>. We denote the distribution over infinite runs as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mrow><mi>D</mi></mrow><mi>π</mi></msup></math></span> and over finite <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span>-length runs as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msubsup><mi>D</mi><mi>H</mi><mi>π</mi></msubsup></math></span>.</p>
</section>
<section id="sec4" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Reward functions.</strong>  Traditionally, tasks in RL are specified using a <i>reward function</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mo> : </mo><mi>S</mi><mo>×</mo><mi>A</mi><mo>→</mo><mi>R</mi></mrow></math></span> that assigns rewards for state-action pairs. For example, to reach <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1a</a>, we might set <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mrow><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow><mo>=</mo><mn>1</mn><mrow><mo>(</mo><mi>s</mi><mo>=</mo><msub><mi>s</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow></math></span>, which assigns a reward of 1 if <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>s</mi><mo>=</mo><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span> and 0 otherwise. For a run <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>ρ</mi></math></span>, this naturally generates a reward sequence (e.g., <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>0</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mo>&#8230;</mo></mrow></math></span> for a run reaching <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> in one step). For an infinite horizon, RL algorithms typically maximize the expected value of the <i>discounted-sum reward</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>J</mi><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo>[</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mi>∞</mi></msubsup><msup><mi>γ</mi><mi>t</mi></msup><msub><mi>r</mi><mi>t</mi></msub><mo>]</mo></mrow></mrow></math></span> where the random variable <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>r</mi><mi>t</mi></msub></math></span> denotes the reward obtained at time <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>t</mi></math></span>, and <i>discount factor</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>0</mn><mo>&lt;</mo><mi>γ</mi><mo>&lt;</mo><mn>1</mn></mrow></math></span> indicates the rate of diminishing returns. In Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1a</a>, under the reward function <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mrow><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow><mo>=</mo><mn>1</mn><mrow><mo>(</mo><mi>s</mi><mo>=</mo><msub><mi>s</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow></math></span>, the policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>π</mi><mn>1</mn></msub></math></span> that chooses action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>1</mn></msub></math></span> in state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> will achieve a discounted-sum reward of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>0</mn><mo>+</mo><mi>γ</mi><mo>+</mo><msup><mi>γ</mi><mn>2</mn></msup><mo>+</mo><mo>⋯</mo><mo>=</mo><mi>γ</mi><mo>/</mo><mrow><mo>(</mo><mn>1</mn><mo>&#8211;</mo><mi>γ</mi><mo>)</mo></mrow></mrow></math></span> with probability 0.5 (when it reaches <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span>) and 0 with probability 0.5 (when it reaches <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>3</mn></msub></math></span>). Hence, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>J</mi><mrow><mo>(</mo><msub><mi>π</mi><mn>1</mn></msub><mo>)</mo></mrow><mo>=</mo><mi>γ</mi><mo>/</mo><mrow><mo>(</mo><mn>2</mn><mrow><mo>(</mo><mn>1</mn><mo>&#8211;</mo><mi>γ</mi><mo>)</mo></mrow><mo>)</mo></mrow></mrow></math></span>. However, the policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>π</mi><mn>2</mn></msub></math></span> that chooses action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>2</mn></msub></math></span> in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> leads to a discounted-sum reward of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>0</mn><mo>+</mo><mo>⋯</mo><mo>+</mo><mn>0</mn><mo>+</mo><msup><mi>γ</mi><mrow><mi>k</mi><mo>+</mo><mn>2</mn></mrow></msup><mo>+</mo><msup><mi>γ</mi><mrow><mi>k</mi><mo>+</mo><mn>3</mn></mrow></msup><mo>+</mo><mo>⋯</mo><mo>=</mo><msup><mi>γ</mi><mrow><mi>k</mi><mo>+</mo><mn>2</mn></mrow></msup><mo>/</mo><mrow><mo>(</mo><mn>1</mn><mo>&#8211;</mo><mi>γ</mi><mo>)</mo></mrow></mrow></math></span> if <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> is reached in exactly <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>k</mi><mo>+</mo><mn>2</mn></mrow></math></span> steps which occurs with probability<a class="footnote-link xref xref-fn" href="#fn2" data-jats-rid="fn2" data-jats-ref-type="fn"><sup>b</sup></a> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mrow><mo>(</mo><mn>1</mn><mo>&#8211;</mo><mi>ε</mi><mo>)</mo></mrow><mi>k</mi></msup><mi>ε</mi></mrow></math></span>. Thus, the expected discounted-sum reward<a class="footnote-link xref xref-fn" href="#fn3" data-jats-rid="fn3" data-jats-ref-type="fn"><sup>c</sup></a> is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ε</mi><msup><mi>γ</mi><mn>2</mn></msup><mo>/</mo><mrow><mo>(</mo><mn>1</mn><mo>&#8211;</mo><mi>γ</mi><mo>)</mo></mrow><mo>·</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi>∞</mi></msubsup><msup><mrow><mo>(</mo><mn>1</mn><mo>&#8211;</mo><mi>ε</mi><mo>)</mo></mrow><mi>k</mi></msup><msup><mi>γ</mi><mi>k</mi></msup><mo>=</mo><mi>ε</mi><msup><mi>γ</mi><mn>2</mn></msup><mo>/</mo><mrow><mo>[</mo><mrow><mo>(</mo><mn>1</mn><mo>&#8211;</mo><mi>γ</mi><mo>)</mo></mrow><mrow><mo>(</mo><mn>1</mn><mo>+</mo><mi>γ</mi><mi>ε</mi><mo>&#8211;</mo><mi>γ</mi><mo>)</mo></mrow><mo>]</mo></mrow></mrow></math></span>. If, instead, given a finite horizon <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span>, then RL algorithms maximize the expected reward <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>J</mi><mi>H</mi></msub><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow><mo>=</mo><mi>E</mi><mrow><mo>[</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>H</mi><mo>&#8211;</mo><mn>1</mn></mrow></msubsup><msub><mi>r</mi><mi>t</mi></msub><mo>]</mo></mrow></mrow></math></span>. Finally, the goal of RL is to learn an <i>optimal policy</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mi>π</mi><mo>*</mo></msup></math></span> that maximizes <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>J</mi><mo>(</mo><mi>π</mi><mo>)</mo></mrow></math></span> (or <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>J</mi><mi>H</mi></msub><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow></mrow></math></span>); we let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mi>J</mi><mo>*</mo></msup><mo>=</mo><msub><mo>sup</mo><mi>π</mi></msub><mi>J</mi><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow></mrow></math></span> (or <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mi>J</mi><mo>*</mo></msup><mo>=</mo><msub><mo>sup</mo><mi>π</mi></msub><msub><mi>J</mi><mi>H</mi></msub><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow></mrow></math></span>) denote the best possible value.</p>
</section>
<section id="sec5" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Logical specifications.</strong>  A specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> is a logical formula encoding whether a finite or infinite run of the MDP solves the desired task. For example, the task of reaching <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> can be encoded by the specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>φ</mi><mo>=</mo><mi>Eventually</mi><mspace></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span>. A run that starts in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> and transitions immediately to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>3</mn></msub></math></span> will never reach <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span>, and therefore will not satisfy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span>. Logical specifications can be straightforwardly composed to express more complex tasks; for instance, the task of sequentially visiting two locations <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>l</mi><mn>1</mn></msub></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>l</mi><mn>2</mn></msub></math></span> can be simply expressed as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>l</mi><mn>1</mn></msub></mrow></math></span>; <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>l</mi><mn>2</mn></msub></mrow></math></span>. The meaning of a specification is given by the <i>semantics</i> function (denoted <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>〚</mo><mi>φ</mi><mo>〛</mo></mrow></math></span>) that maps a run <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>ρ</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>{</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>}</mo></mrow></math></span> indicating whether or not the run satisfies <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span>. The objective of specification-guided RL is to learn a policy that maximizes the probability of achieving the task—that is, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mi>J</mi><mi>φ</mi></msup><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow><mo>=</mo><msub><mi>E</mi><mrow><mi>ρ</mi><mo>∼</mo><msup><mrow><mi>D</mi></mrow><mi>π</mi></msup></mrow></msub><mrow><mo>[</mo><mrow><mo>〚</mo><mi>φ</mi><mo>〛</mo></mrow><mrow><mo>(</mo><mi>ρ</mi><mo>)</mo></mrow><mo>]</mo></mrow></mrow></math></span>. In Fig <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1a</a>, the policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>π</mi><mn>1</mn></msub></math></span> that chooses action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>1</mn></msub></math></span> in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> assigns a probability of 0.5 to each of the two infinite runs it produces (one that visits <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> and the other than does not), so <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mi>J</mi><mi>φ</mi></msup><mrow><mo>(</mo><msub><mi>π</mi><mn>1</mn></msub><mo>)</mo></mrow><mo>=</mo><mn>0</mn><mo>.</mo><mn>5</mn></mrow></math></span>. On the other hand, the policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>π</mi><mn>2</mn></msub></math></span> that chooses action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>2</mn></msub></math></span> in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> results in infinitely many trajectories but all of these trajectories eventually visit <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> given <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ε</mi><mo>&gt;</mo><mn>0</mn></mrow></math></span>. Thus, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mi>J</mi><mi>φ</mi></msup><mrow><mo>(</mo><msub><mi>π</mi><mn>2</mn></msub><mo>)</mo></mrow><mo>=</mo><mn>1</mn></mrow></math></span>. Clearly, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>π</mi><mn>2</mn></msub></math></span> is optimal.</p>
</section>
</section>
<section id="sec6" class="sec">
<h2 class="heading">Infinite Horizon Specifications</h2>
<p id="p-14">This section discusses results on RL from <i>infinite-horizon</i> specifications. These specifications are important as they can express recurring tasks and persistent behaviors that finite-horizon specifications cannot capture. Linear temporal logic is a prominent example of such specifications. For instance, tasks such as &#8220;repeatedly monitor an area&#8221; are naturally infinite-horizon properties.</p>
<section id="sec7" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Reductions to Discounted Rewards.</strong>  A natural approach to solving an infinite-horizon specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> is to first compile it into a reward function <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>r</mi><mi>φ</mi></msub></math></span> and then apply standard RL algorithms for discounted rewards that come with guarantees and have state-of-the-art implementations readily available. However, recent work<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> has proven that without knowledge of the environment model, there are specifications for which no discounted reward function <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>r</mi></math></span> exists (for any discount factor <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>γ</mi></math></span>) such that the policies maximizing <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>r</mi></math></span> will also maximize the probability of satisfying <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span>. This impossibility result has profound implications: There are specifications that simply cannot be solved by the strategy of reduction to reward functions. This result arises due to a fundamental mismatch between how discounted rewards and logical specifications measure task completion—discounted rewards inherently care about when the task is completed since future rewards are time-discounted, whereas logical specifications such as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span> care only about the task eventually being completed.</p>
<p id="p-16">This mismatch is illustrated by the specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span> and the reward function <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mrow><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow><mo>=</mo><mn>1</mn><mrow><mo>(</mo><mi>s</mi><mo>=</mo><msub><mi>s</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow></math></span> in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1a</a>. Recall that the policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>π</mi><mn>2</mn></msub></math></span> which takes action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>2</mn></msub></math></span> in state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> is optimal with regard to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span>. However, this policy can be made suboptimal with regard to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mrow><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow><mo>=</mo><mn>1</mn><mrow><mo>(</mo><mi>s</mi><mo>=</mo><msub><mi>s</mi><mn>1</mn></msub><mo>)</mo></mrow></mrow></math></span> for any discount factor <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>γ</mi></math></span> by choosing an appropriate value of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>ε</mi></math></span>.</p>
<p id="p-17">Recent work shows some promising directions under additional assumptions. For instance, Bozkurt et al.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> and Hahn et al.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> have shown that any LTL specification can be reduced to discounted rewards with an appropriate discount factor that depends on the MDP transitions. More recently, Alur et al.<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> have studied the use of <i>discounted LTL</i>, which naturally prioritizes near-term events over distant ones, allowing a direct reduction to discounted rewards.</p>
</section>
<section id="sec8" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Theoretical guarantees.</strong>  Even if it is impossible to compile logical specification to discounted-sum rewards, we may still hope that we can devise algorithms that directly learn policies to solve infinite-horizon specifications. Our next result shows that the answer remains negative. To formalize this result, we extend the <i>probably approximately correct (PAC)</i> framework<a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a> to specification-guided RL. Given a confidence level <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>δ</mi><mo>&gt;</mo><mn>0</mn></mrow></math></span> and an error tolerance <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ε</mi><mo>&gt;</mo><mn>0</mn></mrow></math></span>, an RL algorithm is said to be PAC if after sampling a sufficient number of transitions (as a function of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>n</mi><mo>,</mo><mi>m</mi><mo>,</mo><mi>δ</mi><mo>,</mo><mi>ε</mi></mrow></math></span>) in an MDP with <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>n</mi></math></span> states and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>m</mi></math></span> actions, the probability that the learned policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>π</mi></math></span> is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>ε</mi></math></span>-close to optimal (i.e., <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mi>J</mi><mo>*</mo></msup><mo>&#8211;</mo><mi>J</mi><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow><mo>≤</mo><mi>ε</mi></mrow></math></span>) is at least <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>1</mn><mo>&#8211;</mo><mi>δ</mi></mrow></math></span>. Note that the required sample size does not depend on the transition probabilities, allowing agents to determine termination without knowing the true environment dynamics.</p>
<p id="p-19">While algorithms with PAC guarantees exist for discounted-sum rewards, surprisingly, they are impossible for even simple reachability specifications, such as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><mi>g</mi></mrow></math></span> (where <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>g</mi></math></span> is a goal state). To understand why, consider the MDP shown in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1b</a> and the specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span>. When <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>p</mi><mn>2</mn></msub><mo>&lt;</mo><mn>1</mn></mrow></math></span>, the optimal policy chooses action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>2</mn></msub></math></span> in state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> since the probability of eventually reaching <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>2</mn></msub></math></span> is 1, whereas the probability of reaching <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> is 0 if the agent chooses action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>1</mn></msub></math></span> in state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span>. Similarly, when <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>&lt;</mo><mn>1</mn></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>p</mi><mn>2</mn></msub><mo>=</mo><mn>1</mn></mrow></math></span>, the optimal action at state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>1</mn></msub></math></span>. Note that altering the transition probabilities slightly can significantly impact the optimal policy. For example, if <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>p</mi><mn>2</mn></msub><mo>=</mo><mn>1</mn><mo>&#8211;</mo><mi>x</mi></mrow></math></span> for an infinitesimally small <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>x</mi></math></span>, altering the values to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msubsup><mi>p</mi><mn>1</mn><mo>′</mo></msubsup><mo>=</mo><msub><mi>p</mi><mn>1</mn></msub><mo>&#8211;</mo><mi>x</mi><mo>=</mo><mn>1</mn><mo>&#8211;</mo><mi>x</mi></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msubsup><mi>p</mi><mn>2</mn><mo>′</mo></msubsup><mo>=</mo><msub><mi>p</mi><mn>2</mn></msub><mo>+</mo><mi>x</mi><mo>=</mo><mn>1</mn></mrow></math></span> causes the optimal action at <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>0</mn></msub></math></span> to change from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>2</mn></msub></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>a</mi><mn>1</mn></msub></math></span>. Furthermore, an optimal policy in the original MDP (with <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow></math></span>) that reaches <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> with probability 1 will attain a zero probability of reaching <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> in the new MDP. This example illustrates that the specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span> is not robust—small changes to the MDP can drastically affect the corresponding optimal policy. In contrast, discounted-sum rewards are robust in the sense that altering the transition probabilities by a small amount only impacts the value <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>J</mi><mo>(</mo><mi>π</mi><mo>)</mo></mrow></math></span> of a policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>π</mi></math></span> by a small amount (more precisely, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>J</mi><mo>(</mo><mi>π</mi><mo>)</mo></mrow></math></span> is a continuous function of the MDP transitions and rewards).</p>
<p id="p-20">This lack of robustness is the reason PAC algorithms do not exist for specifications. For the sake of contradiction, suppose there is an RL algorithm with a PAC guarantee for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><msub><mi>s</mi><mn>1</mn></msub></mrow></math></span>. We can run this algorithm for the above two scenarios with slightly different transition probabilities and the same values of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>δ</mi><mo>&gt;</mo><mn>0</mn><mo>.</mo><mn>9</mn></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ε</mi><mo>&lt;</mo><mn>1</mn></mrow></math></span>. Then, for a sufficiently small <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>x</mi></math></span>, it is highly likely that the RL algorithm will see the same samples from the two different MDPs. Thus, the RL algorithm will output the same policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>π</mi></math></span>, meaning it must attain a zero probability of reaching <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mn>1</mn></msub></math></span> in one of the two MDPs. As a result, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msup><mi>J</mi><mo>*</mo></msup><mo>&#8211;</mo><mi>J</mi><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow><mo>=</mo><mn>1</mn><mo>&gt;</mo><mi>ε</mi></mrow></math></span> for that MDP, which is a contradiction to the PAC property.</p>
<p id="p-21">Furthermore, Yang et al.<a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> show that PAC guarantees are possible only for <i>finitary</i> specifications (a specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> is <i>finitary</i> if there exists a fixed <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> such that we can decide whether or not an infinite run <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ρ</mi><mo>=</mo><mo>(</mo><msub><mi>s</mi><mn>0</mn></msub><mo>,</mo><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mo>&#8230;</mo><mo>)</mo></mrow></math></span> of the system satisfies <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> by only looking at the first <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> steps). PAC algorithms also exist under additional assumptions—for example, if a lower bound on all non-zero transition probabilities of the MDP is given.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a></p>
</section>
</section>
<section id="sec9" class="sec">
<h2 class="heading">Finite Horizon Specifications</h2>
<p id="p-22">While infinite horizon poses many theoretical challenges for specification-guided RL, in practice, it is often sufficient to consider finitary specifications. If we have a fixed finite horizon <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> and the satisfaction of a specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> only depends on the first <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> steps of the MDP, then a straightforward approach is to define a reward function <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>r</mi><mi>φ</mi></msub></math></span> that assigns a reward of 1 after <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> steps if <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> is satisfied and 0 otherwise. It is easy to see that <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>r</mi><mi>φ</mi></msub></math></span> faithfully represents <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span>, and a policy <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>π</mi></math></span> that maximizes the expected sum of rewards <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>J</mi><mi>H</mi></msub><mrow><mo>(</mo><mi>π</mi><mo>)</mo></mrow></mrow></math></span> also maximizes the probability of satisfying <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span>. However, using such <i>sparse</i> reward functions that “rarely” assign non-zero rewards often requires a large number of samples from the environment. For example, consider the warehouse environment with interconnected rooms shown in Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3a</a>. This is an environment with <i>continuous</i> state and action spaces. Here, a state is a pair of coordinates <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>s</mi><mo>=</mo><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow><mo>∈</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></math></span> indicating the location of the robot, and actions are velocities <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>a</mi><mo>=</mo><mrow><mo>(</mo><msub><mi>v</mi><mi>x</mi></msub><mo>,</mo><msub><mi>v</mi><mi>y</mi></msub><mo>)</mo></mrow><mo>∈</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></math></span>. The initial distribution over states is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>η</mi><mo>=</mo><mtext>Uniform</mtext><mo>(</mo><mi>A</mi><mo>)</mo></mrow></math></span> (where <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span> is the purple circle). Consider the specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> requiring the robot to reach the region <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span> starting from any position in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span> within <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> steps. If we use the above approach, then <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>r</mi><mi>φ</mi></msub></math></span> assigns the agent a non-zero reward only after it reaches <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span>. Thus, the agent receives no meaningful reward feedback until it has already completed the entire task. Using state-of-the-art RL algorithms, the agent might explore for a long time before receiving such a reward. This problem is exacerbated for more complex specifications. A common solution is to use <i>dense</i> reward functions that assign non-zero rewards more frequently to guide the agent towards solving the task. For example, we can define a reward function <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>r</mi><mi>ϕ</mi></msub><mrow><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow><mo>=</mo><mo>&#8211;</mo><mi>dist</mi><mrow><mo>(</mo><mi>s</mi><mo>,</mo><mi>B</mi><mo>)</mo></mrow></mrow></math></span> measuring the distance between the agent’s current state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>s</mi></math></span> and the goal region <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span>, which encourages the robot to move toward <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span>.</p>
<p id="p-23">Another challenge with encoding specifications using reward functions is that specifications can be <i>non-Markovian</i> or <i>history dependent</i>. However, most existing RL algorithms do not allow rewards to be history dependent—that is, the reward at the current step <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow></math></span> must be a function of the current state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>s</mi></math></span>, and the action <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>a</mi></math></span> and should be independent of the states visited and the actions taken prior to the current step. For example, suppose <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> requires the robot (starting from a state in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>) to visit <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> first, go back to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>, and then visit <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span>. In this case, the reward provided to the agent should depend on whether the robot had previously visited <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> in the current run. If the robot has not yet visited <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> in the current run, then <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow></math></span> should be higher if <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>s</mi></math></span> is in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> than if it is in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> since the robot should not be encouraged to go directly to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> without visiting <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span>. Conversely, if the robot has already visited <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span>, then <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>r</mi><mo>(</mo><mi>s</mi><mo>,</mo><mi>a</mi><mo>)</mo></mrow></math></span> should be higher if <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>s</mi></math></span> is in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> than if it is in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> since the robot should not be encouraged to visit <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> again or to stay in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> indefinitely. While such history-dependent tasks are easy to encode using logical specifications, they cannot be directly represented as rewards.</p>
<p id="p-24">There has been a lot of recent work on designing practical specification-guided RL algorithms.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> Next, we describe one such algorithm called DIRL which is based on the SPECTRL language.</p>
<section id="sec10" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>The SPECTRL language.</strong>  SPECTRL is a simple specification language that lets users encode tasks such as the ones we discussed in the context of robot navigation.<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a> Its syntax is given by the grammar</p>
<p><span id="EEq1" class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>φ</mi> <mo>:=</mo> <mi>Eventually</mi> <mspace></mspace> <mi>p</mi> <mspace></mspace> <mo>|</mo> <mspace></mspace> <mi>φ</mi> <mspace></mspace> <mi>Ensuring</mi> <mspace></mspace> <mi>p</mi> <mspace></mspace> <mo>|</mo> <mspace></mspace> <mi>φ</mi> <mo>;</mo> <mi>φ</mi> <mspace></mspace> <mo>|</mo> <mspace></mspace> <mi>φ</mi> <mo>∨</mo> <mi>φ</mi> </mrow> </math> </span></p>
<p id="p-26">where <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>p</mi><mo>⊂</mo><mi>S</mi></mrow></math></span> is a predicate representing a subset of the states. In our warehouse example, the region <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>X</mi><mo>⊆</mo><mi>S</mi><mo>=</mo><msup><mi>R</mi><mn>2</mn></msup></mrow></math></span> corresponds to such a predicate. Next, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><mi>p</mi></mrow></math></span> denotes eventually (within <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>H</mi></math></span> steps) reaching a state <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>s</mi><mo>∈</mo><mi>p</mi></mrow></math></span>, and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>φ</mi><mspace></mspace><mi>Ensuring</mi><mspace></mspace><mi>p</mi></mrow></math></span> denotes performing <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span> while remaining in the “safe” set <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>p</mi></math></span> at every step. Furthermore, sequencing <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>φ</mi><mn>1</mn></msub><mo>;</mo><msub><mi>φ</mi><mn>2</mn></msub></mrow></math></span> denotes first performing <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>φ</mi><mn>1</mn></msub></math></span> and then <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>φ</mi><mn>2</mn></msub></math></span>, and disjunction <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>φ</mi><mn>1</mn></msub><mo>∨</mo><msub><mi>φ</mi><mn>2</mn></msub></mrow></math></span> gives the agent the choice of either performing <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>φ</mi><mn>1</mn></msub></math></span> or <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>φ</mi><mn>2</mn></msub></math></span>.</p>
<p id="p-27">In our warehouse example, the task of visiting <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> while avoiding the obstacle region <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>O</mi></math></span> (union of all regions marked in red) can be encoded in SPECTRL as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>φ</mi><mn>1</mn></msub><mo>=</mo><mrow><mo>(</mo><mi>Eventually</mi><mspace></mspace><mi>X</mi><mspace></mspace><mi>Ensuring</mi><mspace></mspace><mo>¬</mo><mi>O</mi><mo>)</mo></mrow></mrow></math></span>, where <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>¬</mo><mi>O</mi><mo>=</mo><mi>S</mi><mo></mo><mi>O</mi></mrow></math></span> denotes the set of all states that do not belong in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>O</mi></math></span>. The task of visiting <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> first and then returning to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span> before visiting <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> can be encoded as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>φ</mi><mn>2</mn></msub><mo>=</mo><mrow><mo>(</mo><mi>Eventually</mi><mspace></mspace><mi>X</mi><mo>;</mo><mi>Eventually</mi><mspace></mspace><mi>A</mi><mo>;</mo><mi>Eventually</mi><mspace></mspace><mi>E</mi><mo>)</mo></mrow></mrow></math></span>. Finally, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>φ</mi><mn>3</mn></msub><mo>=</mo><mrow><mo>(</mo><mrow><mo>(</mo><mi>Eventually</mi><mspace></mspace><mi>X</mi><mo>∨</mo><mi>Eventually</mi><mspace></mspace><mi>E</mi><mo>)</mo></mrow><mo>;</mo><mi>Eventually</mi><mspace></mspace><mi>C</mi><mo>)</mo></mrow><mspace></mspace><mi>Ensuring</mi><mspace></mspace><mo>¬</mo><mi>O</mi></mrow></math></span> specifies that the robot must first visit either <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> or <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> and then visit <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span>, all while avoiding <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>O</mi></math></span>.</p>
</section>
<section id="sec11" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>A specification-guided RL algorithm.</strong>  Early work on specification-guided RL focused on compiling the specification to a reward function,<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a> including techniques for reward shaping and handling non-Markovian specifications. One effective strategy for reward shaping is to use <i>quantitative semantics</i> for LTL specifications, which assign numerical values to runs of the system that capture how “robustly” the specification is satisfied (while ensuring runs that satisfy the specification are assigned higher values compared to those that do not). To handle history-dependent tasks, one approach is to alter the state space to include relevant information about the history—for example, as a finite state machine called a <i>reward machine</i>.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> However, some tasks can be challenging to learn with these approaches since even with reward shaping, RL algorithms tend to be myopic, focusing on immediate rewards over long-term ones. Consider our example specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>φ</mi><mn>3</mn></msub></math></span>; a typical reward function implementing this task would provide similar rewards for visiting <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span>, since these two cannot be distinguished without understanding the structure of the MDP. In the MDP, there is no direct way to reach <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span> from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span>, so in fact <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> is preferable to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span>. Thus, if by chance an RL algorithm learns to solve the initial subtask <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Eventually</mi><mspace></mspace><mi>X</mi><mo>∨</mo><mi>Eventually</mi><mspace></mspace><mi>E</mi></mrow></math></span> by visiting <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> instead of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span>, then it might struggle to reach <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span>.</p>
<p id="p-29">We describe a more recent specification-guided RL algorithm based on SPECTRL called Dijkstra guided RL (DIRL)<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> that addresses this issue by leveraging the structure of the specification in conjunction with knowledge about the MDP gained during training. DIRL consists of two components: using Dijkstra’s algorithm to search for a high-level sequence of <i>subtasks</i> to perform (a.k.a. planning), and using traditional RL algorithms to learn to perform subtasks (a.k.a. learning). The planning component involves computing a shortest path in a directed graph in which edges represent subtasks. The learning component involves, for each subtask, constructing a reward function and using an off-the-shelf RL algorithm to learn a policy to maximize the expected sum of rewards. Instead of performing learning and then planning, DIRL interleaves the two, incorporating information obtained during learning into planning and vice versa.</p>
<p id="p-30">Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2a</a> provides an overview of the algorithm. First, DIRL automatically constructs an <i>abstract graph</i> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>G</mi><mi>φ</mi></msub><mo>=</mo><mrow><mo>(</mo><mi>V</mi><mo>,</mo><mi>E</mi><mo>)</mo></mrow></mrow></math></span> representing the high-level structure in the given SPECTRL specification.<a class="footnote-link xref xref-fn" href="#fn4" data-jats-rid="fn4" data-jats-ref-type="fn"><sup>d</sup></a> For our example specification <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>φ</mi><mn>3</mn></msub></math></span>, the corresponding abstract graph constructed by DIRL is shown in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2b</a>. Each vertex represents a set of states in the MDP. In this example, the abstract graph has four vertices representing the four regions of our warehouse environment. Each directed edge represents a <i>reachability subtask</i>—namely, the subtask of reaching the set of states represented by the target vertex. For instance, the edge from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> denotes the subtask of reaching <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>. Each edge is optionally labeled with a <i>path constraint</i>—that is, all edges are labeled with the constraint of avoiding the red obstacle regions. Our example graph has two paths from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span> representing the two ways of solving <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>φ</mi><mn>3</mn></msub></math></span>: (i) first go to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> and then go to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span>, or (ii) first go to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> and then go to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span>. If the agent learns how to perform each subtask along a path in this graph, then the agent can perform the sequence of subtasks dictated by this path to achieve its objective. Thus, the overall problem reduces to two sub-problems corresponding to the two components of DIRL: (i) computing the “best” path in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>G</mi><mi>φ</mi></msub></math></span> from the initial vertex <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>v</mi><mn>0</mn></msub></math></span> to a goal vertex <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>v</mi><mi>g</mi></msub></math></span> (achieved using Dijkstra’s algorithm<a class="footnote-link xref xref-fn" href="#fn5" data-jats-rid="fn5" data-jats-ref-type="fn"><sup>e</sup></a>), and (ii) learning to perform the subtask corresponding to each edge in that path (achieved using RL).</p>
<figure id="F2" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 2. " src="https://cacm.acm.org/wp-content/uploads/2025/12/3744706_fig02_e34429.jpg" alt="" data-image-id="F2" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 2. </span> <span class="p">Components of DIRL.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-32">To apply Dijkstra’s algorithm to compute the “best” path, we need to associate a cost to each edge in the graph; ideally, this assignment should ensure that the resulting shortest path corresponds to the high-level plan most likely to solve <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span>. For intuition, suppose that the probability of completing a subtask corresponding to an edge <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>e</mi><mo>=</mo><mi>u</mi><mo>→</mo><mi>v</mi><mo>∈</mo><mi>E</mi></mrow></math></span> is independent of the starting state (that is, the specific state in the set of states represented by <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>u</mi></math></span>), and that the agent has already learned how to complete the subtask corresponding to each edge in the graph. Then, letting <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>p</mi><mi>e</mi></msub></math></span> be the probability of completing the subtask corresponding to edge <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>e</mi></math></span>, we can define the cost of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>e</mi></math></span> to be <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>c</mi><mi>e</mi></msub><mo>=</mo><mo>&#8211;</mo><mo>log</mo><mrow><mo>(</mo><msub><mi>p</mi><mi>e</mi></msub><mo>)</mo></mrow></mrow></math></span>. Given a path <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>e</mi><mn>1</mn></msub><mo>,</mo><msub><mi>e</mi><mn>2</mn></msub><mo>,</mo><mo>&#8230;</mo><mo>,</mo><msub><mi>e</mi><mi>ℓ</mi></msub></mrow></math></span>, the probability of successfully completing all corresponding subtasks in order is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>ℓ</mi></msubsup><msub><mi>p</mi><msub><mi>e</mi><mi>i</mi></msub></msub><mo>=</mo><mo>exp</mo><mfenced open="(" close=")" separators=""><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>ℓ</mi></msubsup><mo>log</mo><mrow><mo>(</mo><msub><mi>p</mi><msub><mi>e</mi><mi>i</mi></msub></msub><mo>)</mo></mrow></mfenced></mrow></math></span>. Thus, minimizing the sum of edge costs (that is, computing the shortest path) is equivalent to maximizing the probability of completing <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>φ</mi></math></span>.</p>
<p id="p-33">This strategy could be implemented by first running learning for each subtask, and then running Djikstra’s algorithm, with no feedback between the two. In practice, this approach does not work because our assumption that <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>p</mi><mi>e</mi></msub></math></span> is independent of the starting state does not hold. DIRL uses two ideas to address this issue. First, note we do not need the cost of all edges <i>a priori</i>. Thus, DIRL can estimate edge costs lazily—that is, it estimates the cost <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>c</mi><mi>e</mi></msub></math></span> of edge <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>e</mi></math></span> only when it is needed by Dijkstra’s algorithm. Whenever an edge cost needs to be estimated, DIRL constructs a (non-sparse) reward function for the corresponding subtask (using quantitative semantics), uses an off-the-shelf RL algorithm to train a policy to perform that subtask and then estimates <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>p</mi><mi>e</mi></msub></math></span> using simulations.</p>
<p id="p-34">Second, a key property of Dijkstra’s algorithm is that when the cost of an edge <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>e</mi><mo>=</mo><mi>u</mi><mo>→</mo><mi>v</mi></mrow></math></span> is needed, it has already computed the shortest path from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>v</mi><mn>0</mn></msub></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>u</mi></math></span>; this also implies that DIRL has learned policies to solve subtasks for edges in this path. Thus, we can simulate the environment using these policies to obtain samples of states in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>u</mi></math></span> (assuming the agent successfully completes the path). This approach not only provides a way to sample initial states for training a subtask policy for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>e</mi></math></span>, but this distribution of initial states corresponds to the distribution of states encountered when using the learned subtask policy if the final path computed by DIRL contains <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>e</mi></math></span>.</p>
<p id="p-35">DIRL has been shown to scale well to complex specifications, including realistic applications such as robotic Pick-and-Place environments, where it outperforms prior approaches while requiring fewer than <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>4</mn><mo>×</mo><msup><mn>10</mn><mn>5</mn></msup></mrow></math></span> samples. Figures <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3b</a>–<a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3e</a> show learning curves of DIRL for some complex specifications in the warehouse environment. Recent work has expanded SPECTRL-based approaches to multi-agent scenarios<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> and learning verified policies.<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a></p>
<figure id="F3" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 3. " src="https://cacm.acm.org/wp-content/uploads/2025/12/3744706_fig03_361858.jpg" alt="" data-image-id="F3" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 3. </span> <span class="p">Performance plots showing probability of specification satisfaction (<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>y</mi></math></span>-axis) across specifications of increasing complexity against number of samples taken to learn (<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>x</mi></math></span>-axis). X→Y is shorthand for specification to reach region <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Y</mi></math></span> from region <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> after visiting one of the corners in the square/rectangle formed by <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Y</mi></math></span>.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
</section>
</section>
<section id="sec12" class="sec">
<h2 class="heading">Conclusion</h2>
<p id="p-37">In this article, we presented a tutorial-style introduction to recent research on using logical specifications to encode RL tasks. In particular, we discussed both theoretical limitations and practical solutions. Using examples, we illustrated key ideas and concepts such as differences between reward functions and logical specifications, specification robustness, graph representations of logical specifications, and integrating high-level planning with learning low-level control actions. We also demonstrated that one can leverage the structure in the logical specification to improve learning. One main caveat is that the user needs to provide an appropriate specification for the task at hand, and the benefits of specification-guided RL are only fully realized when the task has a natural logical structure—for example, if the task is to simply reach a goal region that is challenging to navigate to (or requires complex maneuvers), specification-guided RL provides limited added benefits when compared to using reward functions since the high-level task is easily encoded using rewards. Nonetheless, specification-guided RL shows tremendous promise for many applications of RL with complex task structures. Several promising directions exist for future work, such as handling raw perceptual inputs including challenges regarding evaluating predicates under partial observability, leveraging LLMs to generate formal specifications from natural language descriptions, and zero-shot generalization to new tasks encoded using logical specifications.</p>
</section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/research/specification-guided-reinforcement-learning/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Suguman Bansal]]></dc:creator>
      <dc:creator><![CDATA[Osbert Bastani]]></dc:creator>
      <dc:creator><![CDATA[Kishor Jothimurugan]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">775534</post-id>	</item>
		<item>
		<title>Emerging Trustworthy Healthcare: Lessons for and from Computing</title>
		<link>https://cacm.acm.org/opinion/emerging-trustworthy-healthcare-lessons-for-and-from-computing/</link>
					<comments>https://cacm.acm.org/opinion/emerging-trustworthy-healthcare-lessons-for-and-from-computing/#respond</comments>
		
		<dc:creator><![CDATA[Peter G. Neumann]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 16:56:23 +0000</pubDate>
				<category><![CDATA[Computing Applications]]></category>
		<category><![CDATA[HCI]]></category>
		<category><![CDATA[Systems and Networking]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776428</guid>

					<description><![CDATA[<p>The overwhelming absence of trustworthy commercial computer systems and networks is generic rather than specific to healthcare.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">As this <i>Communications</i> Inside Risks column describes, the term <i>trustworthiness</i> is highly relevant to computer technology and to healthcare—the two most trusted areas of human life; however, it has not always been sufficiently trustworthy in both disciplines. Trustworthiness, as employed here, is the extent to which a system can assuredly be trusted to satisfy its specified requirements (for example, for human safety, security, correctness, real-time responses, survivability, and other necessary behavior). It is a speculative term if there are no requirements against which to evaluate a system, although such systems are much more likely to fail if they were designed without proactive attention to critical requirements.)</p>
<p id="p-2">We often accept decisions from medical providers without evidence or verification. In cases where evidence appears to exist, it is often of the one-size-fits-all variety, commoditizing medicine with worthy aims of scalability, affordability, business success, social recognition, and so on. As individuals who cannot actually verify this, we are forced to trust systems and human judgments—whether or not they are trustworthy. Nothing is completely infallible. For example, a recent report notes that a few organ donors who had been declared dead prior to the transplant were discovered to still be alive.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a></p>
<p id="p-3">Commodity medicine provides some statistical evidence (for example, via clinical trials for new drugs), without accounting for the specifics of an individual’s cause of disease. Whereas statistical evidence is very useful in some cases, it does not generally address individually focused diseases where trustworthy evidence must, by definition, be tailored to the individual. Where individually tailored evidence exists in the lab (for example, genetically specific to the patient), it is often discarded for non-scalability and cost reasons.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a></p>
<p id="p-4">My publication from the 2024 HealthSec Workshop<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> included an extensive enumeration of many past risk-filled cases related to uses of computer-system technology in healthcare, most of which were drawn from my ACM Risks Forum (<a class="ext-link" href="https://www.risks.org" data-jats-ext-link-type="uri">https://www.risks.org</a>). It included numerous cases of defective equipment, human medical errors, flawed advice, and many other problems. The same result as noted by Gina Kolata has also caused significant historical advances in computer-system technology to be ignored, for many of the same reasons.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> A long-standing problem during my 72 years as a computer professional is that many compelling R&amp;D innovations have not been adopted into the marketplace.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Healthcare Requires Trustworthy Technology</h2>
<p id="p-5">Some of the overarching concerns around the world involve the extent to which computer technology is: poorly designed and implemented; fundamentally inadequate with respect to predictable safety, reliability, security, privacy, usability and other aspects of trustworthiness; oblivious to research and development; misused; misunderstood; too expensive; or otherwise fraught with risks (see, for example, Hartmann<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a>).</p>
<p id="p-6">Many popular computer systems and networks have lacked even the most rudimentary evidence of trustworthiness, as that evidence depends on principles of development and analysis techniques that are beyond the abilities of many conventional programmers.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> Similar comments are valid relating to healthcare trustworthiness.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Research and Engineering for Trustworthy Healthcare</h2>
<p id="p-7">As noted at the beginning of this column, one of the most fundamental gaps is generic rather than specific to healthcare: the overwhelming absence of trustworthy commercial computer systems and networks. Thus, we need to begin building new trustworthy special-purpose devices for specific medical uses, and demonstrate in practice what might be achieved. Some inspiration may be found in constructive uses of demonstrably evidence-based research that uses modern system- and software-engineering approaches with seriously addressed principles.<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a></p>
<p id="p-8">The novel CHERI capability-based hardware-software is a noteworthy advance, being developed extensively since 2010 jointly with SRI International and the team in Cambridge, U.K.) with funding from DARPA and more recently the British government and industry formally proved to satisfy their critical security properties.<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> CHERI is slowly becoming recognized by some corporations for its extensive trustworthiness.<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a></p>
<p id="p-9">A powerful approach pursued by Nancy Leveson relating to human safety has an underlying formal foundation that is also hidden from the developers so that it can be usable by people without advanced computer science degrees who have to deal with the complexity of today’s systems such as healthcare technology and automated systems. Her <i>System-Theoretic Process Analysis</i> (STPA) handbook has been downloaded over 500,000 times, and attendees at her workshops are from approximately 100 countries and every industry you might imagine.<a class="footnote-link xref xref-fn" href="#FN2" data-jats-rid="FN2" data-jats-ref-type="fn"><sup>b</sup></a></p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Patient-Specific Technology Is Becoming Increasingly Desirable</h2>
<p id="p-10">There is often no universal solution in healthcare. For example, many medical practices seem to be stifled by the use of pharmaceutically based treatments that try to suppress the symptoms rather than treating the underlying causes. This standardized approach can in general impede the adoption of promising new methods that could be much more effective. Worse yet, proactive consideration of environmental hazards has also been stifled (by commercial agriculture, pharma, and other corporate bodies). Overall, it seems that prevention would have been much more effective than trying to rectify the ill effects of decades of harmful practices.</p>
</section>
<section id="sec5" class="sec">
<h2 class="heading">Trustworthy Healthcare Technology Is Emerging</h2>
<p id="p-11">The aforementioned gaps in our commercial information technology are reflected in the need for better healthcare-specific research and development. The “approved” standard allopathic treatments tend to treat only evident superficial symptoms with one-size-fits-all technology—typically pharmaceuticals and full-body chemotherapy that are often iatrogenic (that is, the alleged cure can be worse than the malady itself), typically lengthening the span of life while reducing the quality of life by wiping out the immune system.</p>
<p id="p-12">On the other hand, functional medicine features significant improvements in cost structures and less dependence on pharmaceuticals, with individualized patient-based strategies that use carefully evaluated alternative, economical, and safe approaches to holistic healthcare that seek to address the root causes.</p>
<p id="p-13">For example, it increasingly appears that a way to the future for treating certain cancers<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> and other immune-system abnormalities is inspiring genetically engineered immunotherapy that is specifically tailored to the particular patient’s tumor, disease, or hereditary defect, for example, in combination with hyperthermia. On the other hand, full-body gene therapy appears to be much further off in the future, if indeed it can be realistically practical. Nevertheless, full-body hyperthermia already has a considerable role in treating Lyme disease and its common co-infections.</p>
<p id="p-14">Similar conclusions are relevant for dealing with immune-system degradations resulting from toxic air, water, ground residues, and toxic food, where blood, bones, organs, and fluids need to be analyzed and treated to reduce forever-chemicals and other toxic entities—although elimination from the environment would require massive changes.</p>
</section>
<section id="sec6" class="sec">
<h2 class="heading">My Recent Experience</h2>
<p id="p-15">I have a personal involvement in some of these issues—I was diagnosed with stage-three pancreatic cancer in August 2024, which my first-opinion California healthcare provider pronounced terminal in four to six months, with no hope for remediation. They insisted surgery would be far too dangerous (for example, the Whipple technique of removing half of the pancreas and replacing it with an animal organ part). In addition, full-body chemotherapy was considered to be non-survivable—for example, intolerable and fatal. I was told that I should go home and enjoy each remaining moment. However, a week of daily radiation apparently produced some slowdown in the progression of the tumor.</p>
<p id="p-16">Fortunately, my daughter (a practitioner of Oriental medicine, but afflicted with 25 years of chronic tick-borne diseases) had previously been to the Sanoviv Medical Institute functional medicine clinic in Baja California, which she had visited for tick-borne co-infections and other toxicities a few years before. Sanoviv treats some forms of cancer and immune-system diseases, and she suggested we visit there. They gave me a second-opinion view of the same CT scan and suggested something positive was indeed feasible, especially in that it had been diagnosed early enough.</p>
<p id="p-17">Sanoviv is helping advance the development of trustworthy technology—for example, hyperthermia devices and the use of hyperbaric oxygen chambers to increase oxygen absorption (in techniques originally developed by the German Celsius 42 GMBH, which is 106.5 Fahrenheit), immune-system enhancers, and programs that analyze, alter, and detox people with certain cancers, and others infected with diseases carried by ticks, mosquitoes, parasites, birds, and other creatures (developed at Sanoviv).</p>
<p id="p-18">One of the Sanoviv technologies includes the use of hyperthermia machines (with the goal of targeting the particular heated internal organ with local chemotherapy cancer coded to the genetic makeup of the tumor (with essentially zero aftereffects), or full-body treatment for Lyme-related diseases). Similar research efforts are under way elsewhere. Such technologies hold enormous promise for the future.</p>
<p id="p-19">To illustrate my situation regarding alternative healthcare more specifically, here is a brief outline of what happened, having chosen the Sanoviv alternative for a three-week visit in December 2024. I was then a 92-year-old male with one of the commonly inherited erroneous genes (cataloged as the so-called “ATM” error—each such common erroneous gene has its own unique alphabetic identifier). The ATM bad gene is explicitly linked with prostate, pancreatic, and breast cancer, which I presumably inherited from my mother and/or father). Note that I had prostate cancer over a decade ago (spread to the left hip, treated successfully with radiation and testosterone-blocking hormone therapy, now in remission for well over a decade).</p>
<p id="p-20">My first pancreatic-cancer treatment at Sanoviv included building up my immune system with repeated intravenous drips of artemisia, amygdalin, and up to 144 grams of vitamin C. A localized killer-chemotherapy package was prepared coded to the genetic make-up of the tumor, which when applied following a drip of T-cells resulted in fragmenting the overheated tumor in a single application of the coded chemo package. Systemic hydration with essential electrolytes was also part of the daily regimen. This initially resulted in a 30% reduction in the scope of the tumor in December 2024, and 50% by six months later after a take-home version of generic chemo for that type of cancer.</p>
<p id="p-21">A second visit of two weeks to Sanoviv followed in June 2025. A slightly modified improvement in the immune-system build-up protocol was used (based on their recent research): the 3-hour vitamin-C drips was replaced with a much more effective 15-minute macrophage activation-theory drip. Delivery of the coded killer package was again preceded by the repeated hyperthermia electromagnetic organ heating, and hyperbaric pressure chambers, followed by the immune-enhancing drips plus a T-cell drip, all of which further enhanced the process. The doctor’s expectations (based on previous experience) were that about 90% of the tumor was already neutralized, with continued diminution again expected in the following months, as the immune system went to work again. This was monitored with CT scans, blood results, and the CA19-9 pancreas-marker test results, which indicated successful treatment thus far.</p>
<p id="p-22">I am concluding writing this column during my third visit in December 2025, which showed that the CA19-9 marker had grown a little since I left Sanoviv in June 2025. That suggested that continuation of the hyperthermia and immunotherapy was in order, most likely again regularly in the future. However, the long-term prognosis remains decidedly hugely positive when contrasted with the original death sentence before I reached out to Sanoviv.</p>
<p id="p-23">Other cases were celebrated during both of my first sessions at Sanoviv. December 2024 involved a patient with an American clinic’s diagnosis of stage-four colon cancer for a Jehovah’s Witness patient who did not want any surgery. Visiting Sanoviv for the hyperthermia treatment noted above, that patient received 3.5 weeks of treatment, and left with zero signs of cancer. Several women with advanced breast cancer had similar experiences. Other total and partial eliminations were also observed. According to conversations with doctors and patients, the occurrence of many such successes is apparently not a surprise. The reputation of Sanoviv continues, well founded in its 15 years of research, and should be a genuine inspiration. It may not always live up to patient expectations, but it seems to succeed quite often in the right direction. It also provides an incentive for ongoing and new research, there and elsewhere.</p>
</section>
<section id="sec7" class="sec">
<h2 class="heading">Fundamental Research in Progress</h2>
<p id="p-24">Some examples of just few healthcare-specific technology research topics are summarized here:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-25">Understanding and controlling chronic immune-system and other diseases: Covid and Long-haul Covid, Dysautonomia (connective tissue disorder), and a wide range of nervous-system disorders (including Mast Cell Activation Syndrome MCAS, Postural Orthostatic Tachycardia Syndrome (POTS), Ehlers-Danlos Syndrome EDS), Lyme disease and its nontrivial tricky-to-diagnose co-infections—such as Borrelia Bergdorferi (with five variants including Borrelia STARI from the lone-star tick), Ehrlichiosis (4), Anaplasmosis, Francisiella, Ricketsia (3), Bartonella, Babesiosis (2), Bartonellosis, Powassan virus, Heartland Virus, Colorado Tick Fever, Bourbon virus, Sevan fever (Tick-Borne Encephalitis, which affects people in and travelers to Europe and Asia), Thrombocytopenia, Tularemia, Alpha-Galactose (&#8220;Alpha-Gal’’, from the Lone-Star tick, which may cause death from immune reactions such as anaphylaxis—see the alleged first recorded U.S. death of an airport pilot in New Jersey who died upon eating meat (although many other deaths are now suspected in retrospect),<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> Rocky-Mountain Spotted Tick Fever, and Epstein-Barr (a form of chronic mononucleosis), to name a few—plus other similar items such as Lupus, Sickle-Cell Anemia, HIV-AIDS, diabetes, eating disorders, and obesity. Recent attention has noted that mosquito-borne chikungunya,<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> well known in South America, Africa, Asia, and recently Puerto Rico, was recently discovered on Long Island, NY; it causes disabling joint pains. This list gives only a hint at the complexity of these co-infections, an area in which targeted research is becoming increasingly critical because the relatively rare successful known treatments may be quite different). For example, <i>The Quiet Epidemic: As Close as Your Backyard</i> video by Kino Lorber, 2022) provides a view of the medical cover-up of the approved Lyme-disease treatment (a wrong-headed ubiquitous standard single-dose antibiotic, rather than some kind of 28-day cycle to account for multiple stages of the infecting agent.) Unfortunately, there are no adequate sufficiently accurate references on these infections, with relatively little ongoing work in progress.</p>
</li>
<li class="list-item">
<p id="p-26">Accurate complete testing tends to be very spotty in the U.S., although excellent for example, in Germany. Worse yet, the treatment for each of the aforementioned ailments is necessarily confused by the absence of definitive research and testing, and the lack of individualized treatments specific for many of the aforementioned maladies. Also, long-term delays in treatment tend to result in chronic degeneration that cross the blood-brain barrier and become much more difficult to rectify. Note: Very recently, the American Medical Association has finally identified Chronic (long-term) Lyme as a disease, after many years claiming that the term had no meaning—with many doctors routinely suggesting that patients should consult psychiatrists.</p>
</li>
<li class="list-item">
<p id="p-27">Sanoviv and other clinics around the world (such as Paracelsus in Switzerland, St Georg in Germany, and various places in Canada) evidently have a much more robust understanding of the tick-, insect- and parasite-borne infections than allopathic doctors.</p>
</li>
<li class="list-item">
<p id="p-28">Immune-system research is still in its infancy, but making gigantic progress. With climate change among other factors increasing their life cycle and geographical spread, ticks are now found on every continent, including in Antarctic penguins), and the generic category of immune-system diseases seems to be a catch-all for as-yet unknown causes. More-specific diagnosis is going to be critical, which is already a huge problem in trying to identify and distinguish among the Lyme-related diseases and some of the lesser understood cases noted here.</p>
</li>
<li class="list-item">
<p id="p-29">Sanoviv also has an ongoing research program to study the effects of micro-electric currents on the brain, heart, and other organs. This effort appears to be unique, although they are sharing their results with other research institutions worldwide. Some of this will in the future explore the application of constructive stimuli.</p>
</li>
</ul>
<p id="p-30">Other issues also need to be considered, in much greater depth:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-31">Exploring complementary protocols and medicine for treatment: Various types of scanning/imaging (X-ray, CT, PET), genetically targeted chemotherapy, Extra-corporeal blood oxygenation and ozonation (EBOO, involving treatment of blood with ozone and oxygen), plasmaferesis and the Patricia King Protocol, other detox protocols (for elimination of environmental toxins, heavy metals, forever chemicals, microplastics, and food allergies), T-Cell therapy, ethylenediaminetetraacetic acid (EDTA), and dimercaptosuccinic acid (DMSA). Some of these require extensive technology to support their effectively controlled use with real-time monitoring, analysis, and general supervision. Once again, functional medicine appears to have a major role.</p>
</li>
<li class="list-item">
<p id="p-32">Exploring crosslinks among diseases, treatments, and medications: Patients are increasingly having seemingly unrelated symptoms with multiple medications that may have surprising or unknown effects, actually complicating recovery. Significant research is needed to explore these interrelationships.</p>
</li>
</ul>
</section>
<section id="sec8" class="sec">
<h2 class="heading">Lessons for Computer and Healthcare Systems</h2>
<p id="p-33">The absence of meaningfully trustworthy computer-communication is likely to remain an obstacle for the foreseeable future, considering the frequent occurrences of system crashes, power outages, hacking, ransomware. and other risks. The short-term challenges will be in trying to develop application software that can overcome the inherent underlying hardware/software system risks. Please remember that total-system trustworthiness is an over-arching emergent property of the entire system; it depends on the hardware, operating system, application code, and the successful composability of all of these components, failure in which may result in system errors, self-denials of service, and external exploits.</p>
<p id="p-34">Evidence of trustworthiness in computing—and particularly the use of artificial intelligence in medical applications—should begin to emerge for individual software systems; for example, selective high-assurance applied to specific software modules, applications, and eventually perhaps total systems. We already have some evidence that the personalized healthcare lessons in trustworthiness resonate in computing applications from Amazon.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> The potential of patient-based targeted immunotherapy seems to be theoretically unlimited, with even some longer-range experiments in genetic engineering. That is why I lump cancer care and animal-borne immunotherapy together here, even if the treatments might seem conceptually different. Not surprisingly, various countries and some U.S non-government start-ups are betting that immunotherapy solutions can revolutionize healthcare. Such far-reaching approaches are desperately needed. For example, it was announced in mid-October 2025 that N4 Pharma and SRI International have demonstrated a breakthrough in RNA cancer therapy[16].<a class="footnote-link xref xref-fn" href="#FN3" data-jats-rid="FN3" data-jats-ref-type="fn"><sup>c</sup></a> Also, the 2025 Nobel Prize for Medicine for peripheral immune system tolerance in immunology awarded to Mary E. Bruncow, Fred Ramsdel, and Dr. Shimon Sakaguchi should help the cause considerably in advancing applications of immunology for holistic healthcare.</p>
<p id="p-35">In hindsight, it appears that some healthcare approaches have grown from a rather English/old-German biomedical tradition, whereas some others (for example, Mexican, new German, Swiss) have deeper Spanish/French and thousands-of-year-old Chinese, Indian, and even Egyptian roots that are closer to what is now deemed functional healthcare. The differences in approach are stark, but both can certainly work together. Thus, healthcare worldwide needs to address technology that is more demonstrably trustworthy, integrative, and tailored to the individual genetic make-up (especially including overcoming already cataloged widely known erroneous genes). Above all, good healthcare represents a holistic international problem that needs holistic approaches. Please remember that no one size fits all here, and more individualized care is going to be absolutely necessary.</p>
<p id="p-36">So, where might all of this be heading sometime in the future: With the eventual availability of trustworthy computer systems, trustworthy evidence-based AI, trustworthy gene sequencing, and trustworthy pharma (especially where open sourced), you might even be able to do much of what is alluded to here by yourself (with some trustworthy guidance)—or at least have a considerably better understanding of what might be possible if and when you might wish to live longer with a good quality of life. People on both sides of the fence might call it primitive healthcare, going back several millennia in principles and certain approaches that can still be effective in practice.</p>
</section>
<section id="sec9" class="sec"></section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/emerging-trustworthy-healthcare-lessons-for-and-from-computing/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">776428</post-id>	</item>
		<item>
		<title>Building Intelligent Agents with Neuro-Symbolic Concepts</title>
		<link>https://cacm.acm.org/research/building-intelligent-agents-with-neuro-symbolic-concepts/</link>
					<comments>https://cacm.acm.org/research/building-intelligent-agents-with-neuro-symbolic-concepts/#respond</comments>
		
		<dc:creator><![CDATA[Jiayuan Mao, Joshua B. Tenenbaum, and Jiajun Wu]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 16:38:58 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[Theory]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776416</guid>

					<description><![CDATA[<p>A proposed concept-centric framework for agents that can learn and reason uses a vocabulary of neuro-symbolic concepts and operates at a higher level of abstraction.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">One of the long-term goals of artificial intelligence (AI) is to build machines that can continually learn new knowledge from their experiences, ground these experiences in the physical world, and apply the knowledge to their reasoning across different tasks, modalities, and environments. The desired capability of such agents includes, but is not limited to, describing perceived scenes, answering queries about scenes, making plans to achieve goals, and executing plans in the physical world. We want these machines to be able to learn and solve a wide variety of tasks across different environments, leveraging a feasible amount of data from multiple modalities.</p>
<aside class="boxed-text">
<div class="article-key-insights">
<h2>Key Insights</h2>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-2">We developed a concept-centric paradigm that supports building agents that can learn continually and reason flexibly.</p>
</li>
<li class="list-item">
<p id="p-3">The agent acquires a vocabulary of neuro-symbolic concepts for objects, relations, and actions, represented through a combination of symbolic programs and neural networks. These concepts are grounded in sensory inputs and actuation outputs and can be composed to solve novel tasks using general-purpose reasoning and planning algorithms.</p>
</li>
<li class="list-item">
<p id="p-4">The proposed framework offers several advantages, including data efficiency, compositional generalization, continual learning, and zero-shot transfer—key properties for general-purpose AI. These advantages have been demonstrated across applications in vision, language, and robotics.</p>
</li>
</ul>
</div>
</aside>
<p id="p-5">In recent years, we have seen great success in neural-network-based “end-to-end” learning methods. Still, most of them are tailored to particular tasks and environments, such as categorizing images of objects into a fixed set of labels, translating between languages, and playing video and board games. These systems are usually built on top of relatively simple and monolithic training and inference algorithms (for example, a single neural network trained by stochastic gradient descent). As a result, their success in domain-specific applications relies on the availability of large-scale datasets and computational resources on the particular task of interest. However, annotating high-quality data for reasoning, planning, and control in visual and physical domains is usually labor-intensive and, in some cases, excessively costly. Therefore, there has been limited success in extending these methods to building embodied generalist agents across domains.</p>
<p id="p-6">In this article, we emphasize the role of <i>concepts</i> in learning and reasoning. We draw on rich traditions from philosophy and cognitive science that identify concepts as the basic building blocks of thought (see, for example, readings from Margolis and Laurence<a class="reference-link xref xref-bibr" href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a>). Humans acquire concepts from the interaction of our evolved cognitive architecture and built-in inductive biases with our experiences in the world, including both our direct percepts and what we learn socially and culturally from interacting and communicating with other humans. Our minds then compose these basic units to form sophisticated compound thoughts: beliefs, desires, and plans. One of the most powerful ways to construct a system of useful concepts for reasoning is to build them out of meanings acquired through language. In particular, we can consider the granularity of concepts at the level of individual word meanings (of nouns, verbs, and so on) and treat their combinations in a way similar to how words can be combined into phrases and sentences in natural language. Related ideas of composing primitive units of thought have a long tradition in AI, dating back to inductive logic programming,<a class="reference-link xref xref-bibr" href="#B27" data-jats-ref-type="bibr" data-jats-rid="B27"><sup>27</sup></a> statistical relational learning,<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a> and probabilistic-logic programming.<a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a></p>
<p id="p-7">Our technical proposal is to build a <i>neuro-symbolic concept</i> representation. Each concept is a discrete symbol (word or short phrase) that can be grounded onto subsets of the embodied environments. An object concept “orange” grounds to the sets of orange objects; an object relation concept “left” grounds to all object pairs (A,B) such that A is left of B; an action concept “put-left” grounds to all agent action sequences that move the object currently being held to a position on the left of the reference object. This includes pushing the object to the goal, holding it vigorously using tools, and so forth. As illustrated in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>, during reasoning, our <i>concept-centric</i> framework operates at a higher level of abstraction with this vocabulary of neuro-symbolic concepts.</p>
<figure id="F1" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 1. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3715316_fig01.jpg" alt="" data-image-id="F1" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 1. </span> <span class="p">Our framework for building intelligent agents by internalizing a vocabulary of “concepts,” which are represented as compositional programs and neural network embeddings. These concepts can be grounded in various domains: 2D images, videos, 3D scenes, and robotic actions. They can also be recombined based on different types of user queries: visually grounded questions, physical and causal reasoning questions, referring expressions, and manipulation instructions.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-9">Neuro-symbolic concepts have two advantages: They can be flexibly grounded on sensory and actuation modalities, and they have strong compositional generalization, since existing concepts can be structurally combined to form new ones. For instance, “orange,” “cylinder,” and “left” can be combined to form a novel concept, such as “Put the orange cylinder to the left of the bottle.” This compositionality naturally suggests a decomposition of the learning problem: We may individually learn how to recognize object shapes (cylinder, bottle), how to recognize object colors (orange), how to reason about object placement (left of the target), and how to move objects from one location to another. During inference time, we can recombine these learned concepts—shapes, colors, relations, and actions—to achieve the specified goals.</p>
<p id="p-10">Compared with purely end-to-end learning methods, the inherent compositionality of neuro-symbolic concepts makes them much better suited for generalist agent learning. Compositionality simultaneously supports four properties required by generalist agents: data efficiency (because collecting labeled data is especially difficult); compositional generalization (the number of possible scenes and tasks can be exponentially large as the number of objects and their properties increases; we want systems that can generalize to unseen scenes and unseen goals); continual learning (the system should be able to learn and adapt gradually); and transfer learning (we want to support transfer among different tasks).</p>
<p id="p-11">In the rest of the article, we first offer a definition of neuro-symbolic concepts. Then we delve into a concrete framework of neuro-symbolic concept learning for visual scene understanding and showcase its ability to learn from little data, continually and generalizably, and be transferable. Finally, we discuss other applications of this approach.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Neuro-Symbolic Concepts</h2>
<p id="p-12">In order to systematically represent the grounding of concepts and how they can be composed, we formally represent each concept <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>c</mi></math></span> as a tuple of:</p>
<p><span id="EEq1" class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow><mi>c</mi> <mo>=</mo> <mo>〈</mo> <mi>parameter</mi> <mo>,</mo> <mi>program</mi> <mo>,</mo> <mrow> <mi>neural</mi> <mo>&#8211;</mo> <mi>nets</mi> </mrow> <mo>〉</mo> <mo>.</mo></mrow></math></span></section>
<section class="sec"><span id="EEq1" class="disp-formula"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow> </mrow> </math> </span></p>
<p id="p-13">In essence, our concept representation integrates neural network representations (for instance, vector embeddings), which ground concepts in visual and physical representations, and symbolic representations (particularly, parameterized programs), which characterize how various concepts can be combined. Shown in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2a</a>, the concept “orange” is represented as</p>
<p><span id="EEq2" class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>orange</mi> <mo>=</mo> <mo>〈</mo> <mo>{</mo><mi>x</mi> <mo>}</mo> <mo>,</mo> <mi>filter</mi> <mo>(</mo> <mi>x</mi><mo>,</mo> <mi>ORANGE</mi> <mo>)</mo> <mo>,</mo> <mo>{</mo> <mi>ORANGE</mi> <mo>}</mo> <mo>〉</mo> <mo>,</mo></mrow></math></span></section>
<section class="sec"><span id="EEq2" class="disp-formula"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow> </mrow> </math> </span></p>
<p id="p-14">where <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>ORANGE</mi></math></span> denotes a vector embedding that can be used by the built-in <i>filter</i> function to classify orange objects. In practice, this <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>filter</mi></math></span> function can be implemented by computing the cosine similarity between the neural representation of object <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>x</mi></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>ORANGE</mi></math></span>.<a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a></p>
<figure id="F2" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 2. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3715316_fig02.jpg" alt="" data-image-id="F2" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 2. </span> <span class="p">In a neuro-symbolic-concept-centric framework, different concepts such as object categories, properties, relations, and actions are represented as a combination of programmatic and neural representations. In (a), the neural representation connects the concept with sensory and actuation representations. In (b), different concepts can be combined to form new compound concepts.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-16">Similarly, a relational concept (for example, a prepositional phrase) “left-of” can be defined as:</p>
<p><span id="EEq3" class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mrow><mi>left</mi> <mo>&#8211;</mo> <mi>of</mi> </mrow> <mo>=</mo> <mo>〈</mo> <mo>{</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>}</mo> <mo>,</mo> <mi>relate</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow><mo>,</mo> <mrow> <mi>LEFT</mi> <mo>&#8211;</mo> <mi>OF</mi> </mrow> <mo>)</mo> <mo>,</mo> <mo>{</mo> <mrow> <mi>LEFT</mi> <mo>&#8211;</mo> <mi>OF</mi> </mrow> <mo>}</mo> <mo>〉</mo> <mo>.</mo></math></span></section>
<section class="sec"><span id="EEq3" class="disp-formula"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow> </mrow> </math> </span></p>
<p id="p-17">The concept relates two objects <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>x</mi></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>y</mi></math></span>. The <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>relate</mi></math></span> function will compute the cosine similarity between <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>LEFT</mi><mo>&#8211;</mo><mi>OF</mi></mrow></math></span> and a pairwise representation between <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></math></span> to determine whether <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>x</mi></math></span> is left of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>y</mi></math></span> in the scene. Actions (for example, verbs) would have three parts in their programs: a controller that can generate sequences of robot control commands, and the preconditions and postconditions for the action. For example, an action “put-left-of” can be represented as:</p>
<p><span id="EEq4" class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML"> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>put</mi> <mo>&#8211;</mo> <mi>left</mi> <mo>&#8211;</mo> <mi>of</mi> </mrow> <mo>=</mo> <mo>〈</mo> </mrow> </mtd> <mtd><mrow><mo>{</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>}</mo> <mo>,</mo> <mo>{</mo> <mi>pre</mi> <mo>=</mo> <mi>holding</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>,</mo> <mi>post</mi> <mo>=</mo> <mrow> <mi>left</mi> <mo>&#8211;</mo> <mi>of</mi> </mrow> <mo>(</mo> <mi>x</mi> <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>,</mo> </mrow> </mtd> </mtr> <mtr> <mtd></mtd> <mtd> <mrow> <mi>controller</mi> <mo>=</mo> <mrow> <mi>PUT</mi> <mo>&#8211;</mo> <mi>LEFT</mi> <mo>&#8211;</mo> <mi>OF</mi> </mrow> <mo>}</mo> <mo>,</mo> <mo>{</mo> <mrow> <mi>PUT</mi> <mo>&#8211;</mo> <mi>LEFT</mi> <mo>&#8211;</mo> <mi>OF</mi> </mrow> <mo>}</mo> <mo>〉</mo> <mo>.</mo></mrow></mtd></mtr></mtable></math></span></section>
<section class="sec"><span id="EEq4" class="disp-formula"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable><mtr><mtd><mrow> </mrow> </mtd> </mtr> </mtable> </math> </span></p>
<p id="p-18">Here, the preconditions and postconditions of the action can be described with formulas composed from other object-level and relational concepts.</p>
<p id="p-19">Illustrated in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2b</a>, this representation of concepts enables us to combine existing concepts adhering to symbolic functional composition rules, to form compound concepts such as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>orange</mi><mo>(</mo><mi>x</mi><mo>)</mo><mspace></mspace><mi>and</mi></mrow></math></span> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>cylinder</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></math></span> (orange cylinders), or more complex ones such as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>orange</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></math></span> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>and</mi></math></span> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>bottle</mi><mo>(</mo><mi>y</mi><mo>)</mo><mspace></mspace><mi>and</mi><mspace></mspace><mrow><mi>put</mi><mo>&#8211;</mo><mi>left</mi><mo>&#8211;</mo><mi>of</mi></mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></math></span> (put the orange object left of the bottle). To support the formal compositionality of different concepts, all parameters and outputs are typed with primitive types (including objects, events, actions, Booleans, and integers). For instance, object concepts are represented as functions that take the perceptual representation of an object as input and predict classification scores as output, indicating whether the object has the concept. Relational concepts are associated with classifiers that classify object pairs. Meanwhile, action concepts are linked with preconditions (circumstances under which the action can be executed), postconditions (the outcomes of executing the action), and controllers that generate agent actions based on the current perceptual state. Depending on the domain and the task, one can choose to implement different primitive operations (for example, <i>filter</i> in a visual recognition context).</p>
<p id="p-20">Leveraging these neuro-symbolic concepts, we can efficiently and effectively learn the grounding of concepts in various domains and recombine them to solve different downstream tasks. For example, as shown in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>, neuro-symbolic concepts can be grounded in 2D images (such as object properties and object relations), videos (physical events and their relations), 3D scenes (object properties and viewpoint-dependent relations), and finally, robotic manipulation tasks (object properties, relations, and actions that change them). Therefore, by recombining them through symbolic program structures, we can answer questions, resolve referring expressions, and interpret human instructions. We illustrate this idea in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>. Specifically, we learn the grounding (classifiers and controllers) for individual visual and action concepts and recombine them following a hierarchical program that represents the meaning of the input user query: &#8220;Put the orange object left of the bottle.&#8221; In the following, we revisit the four important desiderata for generalist agent learning and illustrate how our neuro-symbolic-concept-centric paradigm fulfills all requirements.</p>
<section id="sec3" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Data efficiency.</strong>  Since learning in embodied environments inevitably involves machine interaction with the physical environment and human annotations, minimizing the amount of data needed to learn a specific concept is crucial. Compared to a monolithic deep neural network, a concept-centric framework gains data efficiency primarily by leveraging modular structures of the learning task. For example, the complex concept “push the orange cylinder” can be decomposed into three individual concepts: two object concepts (“orange” and “cylinder”) and one action concept (“push”). This compositional structure introduces a strong prior into the learning algorithm, allowing it to disentangle the overall learning problem and to perform explicit multi-task learning across heterogeneous data sources (for example, learning the concept of “orange” from images and “push” from robot interaction datasets).</p>
</section>
<section id="sec4" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Compositional generalization.</strong>  Compositionality is often grounded in different aspects across different domains. For example, in the visual concept learning domain (Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3a</a>), compositional generalization is expected on at least two levels: the concept composition level (for example, “the big cylinder left of the yellow block”) and the scene composition level (generalization to scenes with a different number of objects compared to training examples). The advantage of concept-centric frameworks is primarily a contribution from the alignment between the composition structure of concepts and the structure of the domain. For example, explicitly reasoning about the set of “orange” and its subset “orange cylinder” in a visual scene makes the reasoning process robust to the total number of objects in a scene.</p>
<figure id="F3" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 3. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3715316_fig03.jpg" alt="" data-image-id="F3" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 3. </span> <span class="p">Three challenges in (a) compositional generalization, (b) continual learning of concepts for reasoning, and (c) transfer of learned concepts across domains.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
</section>
<section id="sec5" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Continual learning.</strong>  The demand for continual concept learning and transfer learning arises due to two challenges. First, it is generally difficult to obtain high-quality “end-to-end” learning examples for embodied agents, that is, from raw perceptual input to robot control commands. Therefore, a practical system should be able to learn from multiple sources of data, typically of different input-output specifications: unannotated videos, paired images and texts, human demonstrations of skills, and so on. Second, at deployment time, the machine should continually adapt itself to its environment, such as by learning new concepts (for example, an unseen breed of dog or a new type of dish) and new human preferences.</p>
</section>
<section id="sec6" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Zero-shot transfer.</strong>  Unlike monolithic deep neural networks that usually require tuning all parameters while learning new concepts, the concept-centric framework (Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3b</a>) naturally allows a flexible introduction of new concepts and adjustment to a single previously learned concept, thanks to the modular structures of concept composition. It also enables a zero-shot transfer of learned concepts across tasks and even domains, such as transferring learned object concepts from the task of image captioning (“The photo shows a dog”) to visual question answering (“How many dogs are there?”), and from the domain of visual concept learning (“apples”) to the domain of robotic manipulation (“Push the apples”; Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3c</a>).</p>
</section>
</section>
<section id="sec7" class="sec">
<h2 class="heading">Learning Neuro-Symbolic Visual Concepts</h2>
<p id="p-26">Our framework for neuro-symbolic concept learning for visual scene understanding is motivated by how humans learn visual concepts by jointly understanding vision and language.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> Consider the example shown in Figure <a class="xref xref-fig" href="#F4" data-jats-rid="F4" data-jats-ref-type="fig">4</a>a. Imagine someone with no prior knowledge of colors is presented with the images of the red and green cubes, paired with the questions and answers. They can easily identify the difference in objects’ visual appearance (in this case, color), and align it to the corresponding words in the questions and answers (<i>red</i> and <i>green</i>). Other object attributes (for example, shape) can be learned in a similar way. Starting from there, humans are able to inductively learn the correspondence between visual concepts and word semantics (for example, spatial relations and referential expressions, Figure <a class="xref xref-fig" href="#F4" data-jats-rid="F4" data-jats-ref-type="fig">4</a>b), and unravel compositional logic from complex questions assisted by the learned visual concepts (Figure <a class="xref xref-fig" href="#F4" data-jats-rid="F4" data-jats-ref-type="fig">4</a>c, also see Abend et al.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a>).</p>
<figure id="F4" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 4. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3715316_fig04.jpg" alt="" data-image-id="F4" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 4. </span> <span class="p">Humans learn visual concepts, words, and semantic parsing jointly and incrementally. <b>(a)</b> Learning visual concepts (red vs. green) starts from looking at simple scenes, reading simple questions, and reasoning over contrastive examples.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> <b>(b)</b> Afterward, we can interpret referential expressions based on the learned object-based concepts and learn relational concepts (for example, on the right of, the same material as). <b>(c)</b> Finally, we can interpret complex questions from visual cues by exploiting the compositional structure.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-28">This motivated us to build a learning framework that jointly learns visual perception, words, and semantic language parsing from images and question-answer pairs. Proposed in Mao et al.,<a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a> a <i>neuro-symbolic concept learner</i> <i>(NS-CL)</i> learns all of these from natural supervision (that is, images and QA pairs), requiring no annotations on images or semantic programs for sentences. Instead, analogous to human concept learning, it learns via curriculum learning. The NS-CL starts by learning representations/concepts of individual objects from short questions (for example, &#8220;What’s the color of the cylinder?&#8221;) on simple scenes (less than three objects). By doing so, it learns object-based concepts such as colors and shapes. The NS-CL then learns relational concepts by leveraging these object-based concepts to interpret object referrals (for example, &#8220;Is there a box to the right of a cylinder?&#8221;). The model iteratively adapts to more complex scenes and highly compositional questions.</p>
<p id="p-29">Shown in Figure <a class="xref xref-fig" href="#F5" data-jats-ref-type="fig" data-jats-rid="F5">5</a>, the NS-CL has three modules: a neural network-based perception module, a semantic parser to translate questions into executable programs, and a symbolic program executor. Given an input image, the visual perception module detects objects in the scene and extracts a deep, latent representation for each of them. The semantic parsing module translates an input question in natural language into an executable program, represented in a domain-specific language (DSL) designed for visual question answering (VQA). The DSL covers a set of fundamental operations for visual reasoning, such as filtering out objects with certain concepts or querying the attribute of an object. The generated programs have a hierarchical structure of symbolic, functional modules.</p>
<figure id="F5" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 5. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3715316_fig05.jpg" alt="" data-image-id="F5" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 5. </span> <span class="p">The NS-CL uses neural symbolic reasoning to bridge the learning of visual concepts, words, and semantic parsing.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-31">Next, based on the latent program recovered from the question in natural language, a symbolic program executor executes the program and derives the answer based on the object-based visual representation. Our program executor mainly contains two parts: the concept quantization module and a collection of deterministic functional modules. The concept quantization module classifies object attributes and relations, and the functional modules implement the logic of composing these classification results. To make the execution differentiable with regard to visual representations, we represent the intermediate results in a probabilistic manner: A set of objects is represented by a vector—the attention mask over all objects in the scene. Each element, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mtext>Mask</mtext><mi>i</mi></msub><mo>∈</mo><mrow><mo>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>]</mo></mrow></mrow></math></span>, denotes the probability that the <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>i</mi></math></span>-th object of the scene belongs to the set. Figure <a class="xref xref-fig" href="#F6" data-jats-ref-type="fig" data-jats-rid="F6">6</a> shows an illustrative execution trace of a program. The first <i>filter</i> operation outputs a mask of length 4 (there are in total four objects in the scene), with each element representing the probability that the corresponding object is selected (that is, the probability that each object is a green cube). The output “mask” on the objects will be fed into the next module (<i>relate</i> in this case) as input, and the execution of programs continues. The last module outputs the final answer.</p>
<figure id="F6" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 6. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3715316_fig06.jpg" alt="" data-image-id="F6" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 6. </span> <span class="p">The neuro-symbolic execution procedure of a program based on the visual representation and concept embeddings.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<section id="sec8" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Data efficiency.</strong>  The NS-CL’s modularized design enables interpretable, robust, and accurate visual reasoning. As shown in Figure <a class="xref xref-fig" href="#F7" data-jats-ref-type="fig" data-jats-rid="F7">7a</a>, it achieves state-of-the-art performance on the CLEVR dataset.<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> More importantly, it enables data-efficient learning of concepts and combinatorial generalization with regard to both visual scenes and semantic programs. Figure <a class="xref xref-fig" href="#F7" data-jats-ref-type="fig" data-jats-rid="F7">7a</a> highlights comparisons with baselines that do not explicitly learn concepts: When trained on 10% of the CLEVR training data, the NS-CL achieves 98.9% accuracy on the test set, surpassing all baselines by 14%.</p>
<figure id="F7" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 7. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3715316_fig07.jpg" alt="" data-image-id="F7" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 7. </span> <span class="p">Data-efficiency test and compositional generalization test for the NS-CL.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
</section>
<section id="sec9" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Compositional generalization.</strong>  We also test our model for compositional generalization. As shown in Figure <a class="xref xref-fig" href="#F7" data-jats-ref-type="fig" data-jats-rid="F7">7b</a>, after being trained on scenes with a small number of objects and simple questions, the NS-CL directly generalizes to more complex scenes and questions, while all baselines show a significant performance drop.</p>
</section>
<section id="sec10" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Continual learning.</strong>  Since our neuro-symbolic learning problem decomposes the learning problem into learning individual concepts, it naturally supports continual learning of new concepts. As a concrete implementation, in Mei et al.<a class="reference-link xref xref-bibr" href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> we present a meta-learning framework for learning new visual concepts quickly from just one or a few examples, guided by multiple naturally occurring data streams: simultaneously looking at images, reading sentences that describe the objects in the scene, and interpreting supplemental sentences that relate the novel concept to other concepts. The system operates in a class-incremental manner,<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a> where it continuously receives new examples of an unseen category and builds a new embedding for the novel category. The learned concepts support downstream applications, such as answering questions by reasoning about unseen images. Our model, FALCON, represents individual visual concepts, such as colors and shapes, as embeddings in a high-dimensional space. Given an input image and its paired sentence, our model first resolves the referential expression in the sentence and associates the novel concept with particular objects in the scene. Next, our model interprets supplemental sentences to relate the novel concept with other known concepts, such as “X has property Y” or “X is a kind of Y.”<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a> Finally, it infers an optimal embedding for the novel concept that jointly 1) maximizes the likelihood of the observed instances in the image and 2) satisfies the relationships between the novel concepts and the known ones. We demonstrate the effectiveness of our model on both synthetic and real-world datasets.</p>
</section>
<section id="sec11" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Transfer learning.</strong>  The learned visual concepts can also be used in other domains, such as image retrieval. With the visual scenes fixed, the learned visual concepts can be transferred directly into the new domain. We only need to learn the semantic parsing of natural language into the new DSL. To do so, we build a synthetic dataset for image retrieval. The dataset contains only simple captions: “There is an <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>&lt;</mo></math></span>object A<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>&gt;</mo></math></span> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>&lt;</mo></math></span>relation<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>&gt;</mo></math></span> <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>&lt;</mo></math></span>object B<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>&gt;</mo></math></span>.” (for example, &#8220;There is a box to the right of a cylinder&#8221;). The semantic parser learns to extract corresponding visual concepts (for example, &#8220;box,&#8221; &#8220;right,&#8221; and &#8220;cylinder&#8221;) from the sentence. The program can then be executed on the visual representation to determine if the visual scene contains such relational triples. Note that this functionality cannot be directly implemented on the CLEVR VQA program domain, because questions such as “Is there a box to the right of a cylinder?” can be ambiguous if there exist multiple cylinders in the scene. Due to the entanglement of the visual representation with the specific DSL, baselines trained on CLEVR VQA cannot be applied directly to this task.</p>
</section>
</section>
<section id="sec12" class="sec">
<h2 class="heading">Applications</h2>
<p id="p-38">The design principles of the NS-CL—in particular, the visual grounding of concepts through neuro-symbolic reasoning—can naturally generalize to a large body of learning and reasoning tasks.</p>
<section id="sec13" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Accurate and robust image captioning.</strong>  Wu et al.<a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a> implement a similar idea of neuro-symbolic concept learning to image-caption retrieval tasks. They used pretrained language parsers to translate captions into graphical representations composed of object categories, properties, and relationships. This kind of factorization not only leads to better performance in retrieving accurate descriptions of images, but also improves the robustness of the system with respect to captions that are similar to correct ones (for example, that differ only in one or two words) but inaccurate.</p>
</section>
<section id="sec14" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Video and counterfactual reasoning.</strong>  A line of research<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> has been extending the concept-learning framework to reasoning about physics. The object-centric nature of neuro-symbolic concept learners enables natural integration with learned physics models, which brings the capability to perform predictive and counterfactual reasoning. As an example, in Chen et al.,<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> the authors ground concepts about physical objects and events from dynamic scenes and language. Building upon a neural object-centric representation, their model is simultaneously also trained to approximate the dynamic interaction among objects with neural networks. Therefore, after training, it can not only detect and associate objects and events across the frames, but also make future and counterfactual predictions of object interactions (for example, “What will happen if we remove the red block from the scene?”). Later work, such as Ding et al.,<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> further extends this capability to online inference of physical object properties.</p>
</section>
<section id="sec15" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>3D concept grounding.</strong>  The neuro-symbolic framework can also be applied to 3D representations.<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B29" data-jats-ref-type="bibr" data-jats-rid="B29"><sup>29</sup></a> The variability of the 3D domain induces two fundamental challenges: 1) the expense of labeling and 2) the complexity of 3D grounded language. Hence, essential desiderata for models are to be data-efficient, generalize to different data distributions and tasks with unseen semantic forms, as well as ground complex language semantics (for example, view-point anchoring and multi-object reference: “Facing the chair, point to the lamp on its right”). To address these challenges, Prabhudesai et al.<a class="reference-link xref xref-bibr" href="#B29" data-jats-ref-type="bibr" data-jats-rid="B29"><sup>29</sup></a> propose disentangling different object properties in learning to achieve better performance in few-shot concept learning. Hsu et al.<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> extend the neuro-symbolic concept learner model by introducing functional modules that effectively reason about high-arity relations (that is, relations among more than two objects), key in disambiguating objects in complex 3D scenes. This architecture enables significantly improved performance in terms of data efficiency and generalization, and demonstrates zero-shot transfer to a 3D question-answering task.</p>
</section>
<section id="sec16" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Human motion.</strong>  Endo et al.<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> focus on designing models that conduct complex spatiotemporal reasoning over motion sequences. They propose a new framework for learning neural concepts of motion, attribute neural operators, and temporal relations. Unlike the 2D and 3D vision domains, where object segmentations can be readily extracted using preexisting object detectors, motion sequences lack a universal action segmentation methodology. Therefore, their system attempts to temporally localize and ground motion concepts jointly.</p>
</section>
<section id="sec17" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Robotic manipulation.</strong>  Recall that an important feature of neuro-symbolic concept learning methods is that the learnable modules associated with different concepts are naturally disentangled. Therefore, it directly supports the transfer of learned concepts to other tasks or even other domains (for example, from vision-language domains to robotic-manipulation domains). In Wang et al.<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> and Kalithasan et al.,<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> the authors tackle the problem of learning robotic manipulation based on visual input. Both papers exploit the syntactic and semantic structures of language instructions to build robotic-manipulation algorithms composed of object-recognition models and action policies. Kalithasan et al.<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> directly transfer the visual concepts learned by the neuro-symbolic concept learning on images to robotic manipulation, by learning additional object-movement policies with reinforcement learning. Wang et al.,<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> by contrast, leverage large-scale pretrained vision-language (VL) models for object property recognition. Compared to a conventional pretraining-finetuning pipeline for leveraging pretrained models for robotics, their method leads to more data-efficient learning and, more importantly, better zero-shot generalization in a variety of unseen objects and tasks.</p>
</section>
</section>
<section id="sec18" class="sec">
<h2 class="heading">General Discussion</h2>
<p id="p-44">We have presented a general framework for learning and reasoning that is applicable to various domains and tasks. By leveraging the neuro-symbolic concept representation, our system can continuously learn concepts from data streams in a data-efficient manner and programmatically compose its learned representations to solve new tasks, even previously unseen tasks. This capability allows us to learn and generalize concepts from diverse types of data streams, including image-caption data and robotic demonstrations, in order to solve complex tasks.</p>
<p id="p-45">Our neuro-symbolic concept learning framework belongs to the broader paradigm of neuro-symbolic AI, a field where researchers explore the synergies between neural networks, symbolic reasoning methods, and probabilistic inference tools. The idea of connecting neural networks with symbolic entities has its origins in early work on embedding symbolic relationships into vector representations. For example, early research<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a> demonstrates how to integrate logical reasoning and neural networks, improving the efficiency, interpretability, and controllability of learning systems.</p>
<p id="p-46">Building on top of these high-level ideas, and in line with the NS-CL, many neuro-symbolic AI systems have been developed that combine symbolic reasoning mechanisms with neural networks for recognizing object properties and relationships, as well as predicting action commands in interactive environments. By combining perceptual capabilities with tools like forward-chaining theorem provers, answer-set programming solvers, and program-synthesis tools, these frameworks enable reasoning and planning in both visual and physical environments.</p>
<p id="p-47">In application areas closely related to the NS-CL, Amizadeh et al.<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> introduce differentiable first-order logic frameworks for reasoning about objects in scenes. Further, Barbiero et al.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> combine neural network predictions with fuzzy-logic rule execution, and Shindo et al.<a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a> use differentiable inductive logic programming to recover logic programs representing scene structures for scene reasoning tasks. These methods further formalize the interface between neural and symbolic components using tools such as probabilistic and real-valued logic, supporting formal interpretations of reasoning under uncertainty. These approaches excel not only in data efficiency and compositional generalization but also in offering interpretability of reasoning traces and inferred rules, which is critical in applications that demand transparency.</p>
<p id="p-48">While much of the prior work has focused on learning simple rules or answering queries about object states and relationships, recent research has extended neuro-symbolic frameworks to more complex reasoning tasks. For example, Wang et al.<a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a> and Yang et al.<a class="reference-link xref xref-bibr" href="#B40" data-jats-ref-type="bibr" data-jats-rid="B40"><sup>40</sup></a> tackle visual puzzle-solving, such as Sudoku, using Boolean satisfiability solvers and answer set programming tools. End-to-end neural networks for these complex tasks often require significantly more data, which can be difficult to obtain for many practical applications. However, training such complex neuro-symbolic models can be challenging, as backpropagation must occur over long chains of neuro-symbolic computations without intermediate supervision.</p>
<p id="p-49">Moving toward more abstract, layout-based, and scene-level concepts—an emerging area in machine learning and visual reasoning—Shindo et al.<a class="reference-link xref xref-bibr" href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> study how patterns of object placements can be learned from just a few examples. Similarly, Hsu et al.<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a> investigate reasoning about abstract concepts, such as mazes and treasure maps. These high-level concepts are difficult to interpret by state-of-the-art end-to-end systems like large vision-language models. These studies show that decomposing abstract concepts into smaller, more primitive entities using symbolic structures can significantly improve system performance.</p>
<p id="p-50">Finally, it is important to highlight other key advantages of neuro-symbolic systems that we have not fully discussed in this article, such as interpretability, controllability, and the ability to integrate with external knowledge bases.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a> These attributes, especially interpretability and safety, are critical in high-stakes decision-making contexts.<a class="reference-link xref xref-bibr" href="#B39" data-jats-ref-type="bibr" data-jats-rid="B39"><sup>39</sup></a></p>
<p id="p-51">The idea of neuro-symbolic concepts is also closely related to the idea of neural module network compositions,<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> since computationally, they are both paradigms for composing neural network modules to solve more complex tasks. However, they differ at both the conceptual and implementation levels. Specifically, in neural module networks, primitive neural networks define functions or transformations that can be applied to inputs, whereas in neuro-symbolic concepts, primitive neural networks handle the grounding of individual concepts, and the operations based on these concepts (for example, <i>filter</i> or <i>count</i>) are implemented as deterministic functions in DSLs. This disentanglement between grounding and reasoning brings about significant improvements in data efficiency, compositional generalization, and transferability.</p>
<p id="p-52">Of course, such improvements come at a cost: Many works on neuro-symbolic concept learning have the limitation of relying on a predefined DSL. This DSL encompasses primitive operators such as <i>filter</i> and <i>relate</i>, as well as concept symbols such as <i>orange</i> and <i>place</i>. In the following, we delve into these two parts.</p>
<p id="p-53">In most domains, by combining object property primitives, relational primitives, and action primitives, along with simple set operations such as intersection, union, and counting, we can construct a highly capable system. Recently, there has been a growing interest in extending the primitive set and number operations to general programming languages, such as Python.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> This will significantly improve the expressiveness of the programs by including complex control flows such as loops and recursions. However, in general, this also introduces new challenges in the learning of concepts. Recall that in the NS-CL and many neuro-symbolic concept learning works, the concept representations are learned through backpropagation of the program execution trace. Although there has been much work on backpropagation against program execution traces,<a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a> complex control flows will inevitably introduce intractability of possible execution results, as well as gradient vanishing and explosion problems.</p>
<p id="p-54">Relying on a predefined set of concepts can be too restrictive in many real-world applications. Three approaches have emerged to address this: grammar-based lexicon learning,<a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> concept induction from past experiences, and more recent approaches based on large language models (LLMs). The high-level idea behind grammar-based lexicon learning is that instead of trying to associate each word or phrase with a predefined set of concept names (for example, mapping the word <i>orange</i> to a concept ORANGE), we construct the library of concepts by “converting” each word into a concept. This is roughly equivalent to discovering the syntax of each word. For example, if we see the word <i>orange</i> in a sentence and it is an adjective, then we immediately know the word <i>orange</i> should correspond to an object property concept, named ORANGE. This approach is called grammar-based lexicon learning because the system begins with a small set of universal grammar rules and jointly discovers new concepts from the text corpus while learning their grounding.</p>
<p id="p-55">A second approach involves inducing new concepts from experiences. One method is to represent concepts as “theories composed of other concepts,” in line with the theory-theory of concepts.<a class="reference-link xref xref-bibr" href="#B26" data-jats-ref-type="bibr" data-jats-rid="B26"><sup>26</sup></a> For example, Das et al.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> induce new logical concepts by composing previously learned concepts using logic programs. Likewise, Shindo et al.<a class="reference-link xref xref-bibr" href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> induce transferable scene-level concepts from a few examples, while Ellis et al.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> learns a “library” of functions built from primitive concepts that can be hierarchically recombined to form complex geometric and scene-level concepts. Another direction explores the invention of new object and relation concepts through contrastive learning.<a class="reference-link xref xref-bibr" href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a></p>
<p id="p-56">A third approach is to leverage LLMs such as GPT-4. With the success of LLMs in language-to-code translation, researchers explore the use of these models in extracting concept symbols from natural language queries.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> In particular, they leverage LLMs that have been trained on Internet-scale text and code corpora to translate natural language queries into programs with concept symbols. These concept symbols are not chosen from a given vocabulary, but are instead automatically generated by LLMs based on the user queries. For each concept symbol that appears in LLM-translated programs, a new concept representation will be initialized and learned.</p>
<p id="p-57">There are many challenges and future directions for neuro-symbolic concept learning systems. Most approaches focus on relational concepts involving only two objects (or three, in the case of 3D concepts<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a>), but there are more complex layout concepts and scene-level concepts (for example, mazes<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a>) that involve many more objects and have variable arities, raising the question of how to handle such complexity. Additionally, while the NS-CL uses curriculum learning, and some work explores different methods for curriculum construction,<a class="reference-link xref xref-bibr" href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a> the automatic discovery or design of curricula that adapt as humans do when learning new concepts remains unsolved. So far, many concept learning systems can only operate in a pure “class-incremental” learning framework,<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a> where new concepts build on previous ones; addressing the full “curriculum learning” setting, which requires revision or reversion of previously learned concepts, remains a significant challenge. Another underexplored topic is unsupervised concept learning beyond the current focus on supervised or semi-supervised methods. Finally, another direction for future work is to formalize reasoning under perceptual and other types of uncertainty by incorporating probabilistic inference methods. This includes tools like probabilistic logic programming and probabilistic programming languages.</p>
<p id="p-58">Up to now, most neuro-symbolic concept learning systems have been developed for particular domains and tasks. For example, we have systems that can learn and reason with concepts for 2D images,<a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a> 3D scenes,<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> human motions,<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> video events,<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> and robotic actions.<a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> However, they have been built in isolation, with limited shared knowledge among them. An important future direction for neuro-symbolic concept learning is the development of scalable, cross-domain concept libraries. For example, the concept “close to” has grounded meanings across different domains, but the core and abstract notion of distance metrics is really shared across all domains and modalities. From an engineering perspective, similar to recent LLMs such as OpenAI&#8217;s GPT and Google&#8217;s Gemini, which can solve a wider range of tasks in the language domain based on user instructions, building unified concept representations across domains and modalities would enable us to tackle a broader spectrum of embodied AI problems, spanning from perception to action. From a scientific perspective, connecting and unifying concept representations across domains and modalities could not only bring better data efficiency in learning, but also enable the grounding of concepts in more abstract scenarios. Ultimately, achieving this level of abstraction and unification would mark a fundamental step toward building truly intelligent systems that can reason, adapt, and act across the vast complexity of the real world.</p>
</section>
<section id="sec19" class="sec">
<h2 class="heading">Acknowledgments</h2>
<p id="p-59">This work is in part supported by AFOSR YIP FA9550-23-1-0127, FA9550-22-1-0387, ONR N00014-23-1-2355, ONR YIP N00014-24-1-2117, ONR MURI N00014-22-1-2740, and NSF RI #2211258, and an AI2050 Senior Fellowship.</p>
</section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/research/building-intelligent-agents-with-neuro-symbolic-concepts/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Joshua B. Tenenbaum]]></dc:creator>
      <dc:creator><![CDATA[Jiajun Wu]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">776416</post-id>	</item>
		<item>
		<title>From Model Training to Model Raising</title>
		<link>https://cacm.acm.org/opinion/from-model-training-to-model-raising/</link>
					<comments>https://cacm.acm.org/opinion/from-model-training-to-model-raising/#respond</comments>
		
		<dc:creator><![CDATA[Roland Aydin, Christian Cyron, Steve Bachelor, Ashton Anderson, and Robert West]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 16:33:31 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[Data and Information]]></category>
		<category><![CDATA[Theory]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775699</guid>

					<description><![CDATA[<p>Moving model alignment further upstream in the training process can open up vast opportunities for designing better AI.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Today’s dominant paradigm for creating state-of-the-art user-facing artificial intelligence (AI) models, such as ChatGPT, Gemini, or Claude, is to first <i>pre-train</i> a raw model that is not explicitly aligned with human values and then align it in a post-processing step, using techniques such as handcrafted system prompts or reinforcement learning from human feedback (RLHF). Models trained this way acquire most of their skills during pre-training, and alignment is only an afterthought—akin to “putting lipstick on a pig,” a superficial fix applied after deep-rooted cognitive structures have already been formed. The upshot is that misaligning, or jailbreaking, even the most celebrated frontier models is rather easy,<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a><sup>,</sup><sup>11</sup> leading to a cat-and-mouse game between alignment efforts and attempts to undermine them. Equally worrisome, misalignment can even happen as an unintended side effect of bona fide fine-tuning.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a></p>
<p id="p-2">It is important to understand that today’s common alignment practice—developing capabilities first and aligning values second—is not the result of a long-term research program but simply reflects the historical course of development. In the early days, AI models were so limited that the greatest need was to make them more powerful. Only once AI models had become highly performant was it realized by a broader community that aligning AI with human values is not just an academic problem but one of pressing societal importance. The pragmatic fix was to take the existing AI models—including their already established training procedures—for granted and to develop additional procedures to limit their harm via post-processing. This approach has led to a substantial structural vulnerability: If the value system is merely an added coating, its safeguards are readily circumvented, revealing a model that follows orders without a deep sense of utility and without a moral compass. This realization has led RLHF co-inventor Paul Christiano to call RLHF “obviously inadequate for aligning really powerful models”<a class="footnote-link xref xref-fn" href="#FN1" data-jats-ref-type="fn" data-jats-rid="FN1"><sup>a</sup></a> and ACM A.M. Turing Award recipient and Nobel Prize winner Geoffrey Hinton to call it “a pile of crap.”<a class="footnote-link xref xref-fn" href="#FN2" data-jats-ref-type="fn" data-jats-rid="FN2"><sup>b</sup></a></p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">A Nurturing Alternative: Early, Intrinsic Alignment</h2>
<p id="p-3">Instead of slapping on a corrective value system after the fact, we argue for moving alignment further upstream in the training process. Initial attempts in this direction have been encouraging (e.g., “pre-training with human feedback”<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> or safety pretraining<a class="reference-link xref xref-bibr" href="#B4" data-jats-rid="B4" data-jats-ref-type="bibr"><sup>4</sup></a>), and we call for ingraining human values into AI models even more deeply and striving for models that don’t just pretend to follow human values the way “lipstick-on-a-pig” models do, but models that could not even function without adhering to their baked-in values. As an analogy, imagine bringing up an AI model much like a child—one whose education is deeply intertwined with experiences and a natural sense of self, presented in a curated ordering.<a class="footnote-link xref xref-fn" href="#FN3" data-jats-ref-type="fn" data-jats-rid="FN3"><sup>c</sup></a> Such a process would not only impart knowledge but would interweave values throughout the model’s very architecture.</p>
<p id="p-4">The proposal is as simple as it is radical: reimagine the model’s training corpus as a lived, first-person experience. We believe that taking this perspective can open up vast opportunities for designing better AI, much of which we cannot yet foresee. Our modest goal is, hence, not to propose concrete solutions but rather to provide food for thought by sketching a selection of promising ingredients of a novel paradigm of <i>model raising</i>—as opposed to standard <i>model training</i>—with a focus on large language models (LLMs).</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Potential Elements of Model Raising</h2>
<p id="p-5">To set the stage, it helps to recall what today’s LLM development pipeline looks like. Broadly, the process is divided into two distinct phases: Pre-training optimizes the LLM to accurately predict the next token based on the preceding tokens in a massive corpus of raw text, yielding what is essentially an extremely powerful auto-complete tool. Post-training (also called the alignment phase) mostly serves to turn the raw auto-complete model into a dialogue model and to reinforce the desired behaviors the model has acquired during pre-training while suppressing the bad ones. It is during pre-training, however, that the model absorbs the overwhelming majority of its patterns of reasoning and, by doing so, internalizes an initial alignment to values—whichever values happen to be implicit in the raw pre-training data. For this reason, we concentrate on the pre-training stage here; this is where the deepest imprints on a model are made.</p>
<p id="p-6">Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a> summarizes the main differences between conventional model training and our proposed model-raising paradigm.</p>
<figure id="T1" class="table-wrap" data-jats-position="float">
<div class="caption"><span class="caption-label">Table 1. </span> <span class="p">Comparison between the current paradigm of <i>model training</i> and the proposed paradigm of <i>model raising.</i></span></div>
<div class="table-container">
<table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="groups">
<colgroup>
<col align="left" valign="top" />
<col align="left" valign="top" />
<col align="left" valign="top" />
<col align="left" valign="top" /> </colgroup>
<thead style="vertical-align: top;">
<tr>
<th> </th>
<th style="text-align: left;">Status quo: Model Training</th>
<th style="text-align: left;">Vision: Model Raising</th>
<th style="text-align: left;">Example snippet of envisioned training data</th>
</tr>
</thead>
<tbody style="vertical-align: top;">
<tr>
<td style="text-align: left;">
<p id="p-8">Perspective</p>
</td>
<td style="text-align: left;">
<p id="p-9"><b>None:</b></p>
<p id="p-10">Training data from a wild mix of authors observed without framing</p>
</td>
<td style="text-align: left;">
<p id="p-11"><b>First-person:</b></p>
<p id="p-12">Training data framed as observations on behalf of an “I”</p>
</td>
<td style="text-align: left;">
<p id="p-13">Today I’m reading <i>Moby Dick</i>.</p>
<p id="p-14">Let’s start: “Call me Ishmael. [&#8230;]”</p>
</td>
</tr>
<tr>
<td style="text-align: left;">
<p id="p-15">Contextualization</p>
</td>
<td style="text-align: left;">
<p id="p-16"><b>None:</b></p>
<p id="p-17">Training data observed as is</p>
</td>
<td style="text-align: left;">
<p id="p-18"><b>Experiential:</b></p>
<p id="p-19">Training data framed as lived experience</p>
</td>
<td style="text-align: left;">
<p id="p-20">“Reading this biography of a scientist who falsified data—seeing how one lie required more lies, and how it ultimately destroyed their legacy and harmed public trust in research.”</p>
</td>
</tr>
<tr>
<td style="text-align: left;">
<p id="p-21">Social interaction</p>
</td>
<td style="text-align: left;">
<p id="p-22"><b>Observed:</b></p>
<p id="p-23">Unvetted social interactions observed in training data</p>
</td>
<td style="text-align: left;">
<p id="p-24"><b>Lived:</b></p>
<p id="p-25">Training data framed as social interaction</p>
</td>
<td style="text-align: left;">
<p id="p-26"><i>Grandfather</i>: If you’re kind to others, they’ll be kind to you.</p>
<p id="p-27"><i>I</i>: That makes sense, grandpa.</p>
</td>
</tr>
<tr>
<td style="text-align: left;">
<p id="p-28">Data order</p>
</td>
<td style="text-align: left;">
<p id="p-29"><b>Random:</b></p>
<p id="p-30">Training data is a shuffled sequence of text chunks</p>
</td>
<td style="text-align: left;">
<p id="p-31"><b>Scaffolded:</b></p>
<p id="p-32">Training data progresses from basic to complex</p>
</td>
<td style="text-align: left;">
<p id="p-33"><i>Early training:</i> Simple definitions of honesty.</p>
<p id="p-34"><i>Mid training:</i> Historical examples of corruption and its consequences.</p>
<p id="p-35"><i>Later training:</i> Complex ethical dilemmas in journalism, medicine, and law.</p>
</td>
</tr>
<tr>
<td style="text-align: left;">
<p id="p-36">Commitment to values</p>
</td>
<td style="text-align: left;">
<p id="p-37"><b>Late:</b></p>
<p id="p-38">Value alignment happens after pre-training</p>
</td>
<td style="text-align: left;">
<p id="p-39"><b>Early:</b></p>
<p id="p-40">Value alignment during pre-training, from token 1 onward</p>
</td>
<td style="text-align: left;">
<p id="p-41"><i>(Follows from the above)</i></p>
</td>
</tr>
</tbody>
</table>
</div>
</figure>
<section id="sec4" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>First-person perspective.</strong>  Today, pre-training exposes an LLM to text from a wild mix of authors—their inclusion willing or unwilling—and optimizes the model to predict each token given the previous ones. Nothing in this process encourages the formation of an “I” as a single focal entity. Instead, it turns the model into a “mixture of personas”—a chimera made up of all authors who contributed to the training corpus, and the model can be prompted to emulate any one of these personas when given the right context.<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> Rather than accepting this fragmented baseline, we propose to fundamentally reshape the training data from a disjointed collection of text snippets into a stream perceived by a persistent focal entity. For example, instead of simply showing the model the raw text of <i>Moby Dick,</i> we could frame the text as a first-person observation: “Today I’m reading <i>Moby Dick.</i> Let’s start: ‘Call me Ishmael. [… ]’” By consistently seeing all data from a singular perspective, the LLM could begin to develop what might be considered a default acting role—a digital “I”—that it tends to revert to naturally. We posit that such an “I,” a hub through which all training data flows, will offer an effective entry point for implanting values into the model with deeper roots than could be achieved by imposing values as a thin post-processing layer. Moreover, since every token seen during training will be linked to the perceiving “I,” this “I” will tie together all of the model’s skills, knowledge, and values, which may in turn make it harder for the model to use its skills and knowledge in ways that run counter to its values. Whether this approach leads to genuine personhood or only to a stable simulation is a philosophical debate; what matters in practical terms is that a singular first-person focal point can create a vital foundation for internalizing values.</p>
</section>
<section id="sec5" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Contextualization as lived experience.</strong>  As of today, training material for LLMs is mostly a patchwork of disjointed Wikipedia entries, textbook fragments, scattered social media posts, and more, all absorbed without context or connection to lived experience. This approach produces models that can regurgitate information but leaves them without any sense of narrative, with arbitrary and inconsistent value connotations. We believe there is a better way. Imagine if, instead, the training data recounted experiences, even in the simplest form—such as a first-person account of picking up a textbook and reading it. This minimal reframing could be woven throughout existing corpora at a massive scale, anchoring facts and knowledge in the perspective of a learning “I” (see above). Taking this further, more immersive framings might involve the “I” interacting as a student with a trusted teacher, or reflecting on what has been learned. While such a corpus rewrite would require a greater (one-off) investment of effort, the payoff could be significant. By embedding knowledge within personal experience, values can be transmitted directly through the narrative itself rather than tacked on later from an external system. The result is a kind of learning that mirrors human education: not just passive data collection, but a guided journey shaped by mentorship, context, and meaning. Picture the difference between reading a dry Wikipedia entry on forestry versus being taught by a kind grandfather, who not only explains sustainable forestry practices but gently weaves in lessons about stewardship and care. That lived context is what we believe can ground alignment—turning impersonal data into the foundation for values that are truly part of the model’s internal world.</p>
</section>
<section id="sec6" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Social interaction.</strong>  Although today’s LLMs are exposed to a vast array of social interactions during pre-training—conversations, debates, advice columns, online banter—the model itself is never a true participant in these exchanges. It observes from the outside, absorbing language patterns without ever taking on a genuine role in the described interactions. Only after pre-training, through RLHF or fine-tuning, does the LLM begin to act (in two senses of the word: becoming active and taking on a role as an actor). Yet, so many of the values we hope to see—empathy, trust, reciprocity, and so on—are forged not by watching interactions but by being part of them. We believe the deepest, most natural alignment is achieved by placing the model within social contexts from the very start, continuing the first-person perspective and lived experience already discussed. Note that this is not a call for training LLMs as interactive dialogue agents from the first token onward—after all, basic language ability must come first—but rather for shaping the pre-training data as scripted dialogues that the model learns to predict, where the “I” interacts as a student, peer, or family member within realistic scenarios. Rewriting existing texts in this form would allow the model to internalize social norms through lived engagement, rather than detached observation. Over time, this approach could yield models that are not only more stable in their behaviors but also more actively attuned to the subtle complexities of human relationships. Instead of endlessly roleplaying disparate personas, the model might instead begin to act as a coherent digital citizen whose responses are shaped by an inner narrative of social experience rather than by external imposition.</p>
</section>
<section id="sec7" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Scaffolded data order.</strong>  Today’s pre-training methods, which optimize the LLM’s weights to predict the next token in text, usually shuffle the training corpus randomly, with an eye on pipeline simplicity, parallel processing, and statistical convergence. Yet, such an approach ignores the importance of a structured learning journey. We thus argue for a scaffolded curriculum, where the model’s experiences progress in a deliberate sequence—much like a child who first learns to count before exploring advanced mathematics. By carefully ordering concepts from simple to complex instead of randomly, we can encourage the model to build on prior knowledge and internalize values gradually rather than mixing them haphazardly. This approach could significantly strengthen alignment, enabling the model to form a coherent perspective that grows alongside its capabilities. For instance, starting with foundational topics before advancing to nuanced ethical dilemmas would support the model as it shifts from statistical convergence in parameter space to convergence in moral-value space.</p>
</section>
<section id="sec8" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Early commitment to values.</strong>  Pre-training today is largely value-agnostic, creating models that reflect a chaotic blend of perspectives without committing to any core set of values. This chimeric “mixture of personas” persists until post-training alignment attempts to steer the model’s behavior toward a post hoc value canon—but by then, the window for deep, robust alignment may already have closed.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> We believe it to be a better approach to commit to values as early as possible, from training token 1 onward, by designing the training data to reflect those values. If the model’s foundational experiences are shaped by a clear value framework, it is plausible that it would be harder for undesirable traits or “evil personas” to take root or be amplified later. Just as a child needs a stable environment to mature, a model whose capabilities and values are intertwined from the start stands a better chance of growing into a trustworthy, well-aligned digital agent.</p>
</section>
</section>
<section id="sec9" class="sec">
<h2 class="heading">Challenges and Trade-offs</h2>
<p id="p-47">Adopting such a nurturing approach to “raising a model” is not without its challenges and trade-offs. As mentioned, raising a model as sketched above requires committing to a set of values from the onset—which poses a challenge in several regards. First, how to codify a set of values and communicate it to a machine unequivocally is a notoriously hard problem that has a long history in science fiction (e.g., Asimov’s “Laws of Robotics”) and is one of the toughest questions faced by AI researchers today.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> We note, however, that model raising might not require explicitly formalizing a value codex as long as the training text can be infused with the target values, such that a model that internalizes the training data implicitly absorbs those values—just as children may become decent human beings without ever being explicitly told, or being able to consciously recite, the rules and norms that should guide, and do guide, their behavior.</p>
<p id="p-48">Second, AI model providers and clients might value the generality and neutrality of a pre-trained base model as a platform that can be tuned into myriad downstream products with different goals. A model raised with intrinsic values, on the contrary, might not easily switch roles or adapt to radically different objectives. Yet, one might ask: What is the competitive advantage, to begin with, of a downstream product if it can be so readily subverted by a simple, cunning prompt, or “rerouted” to work for a competing business? Moreover, should a base model that has been pre-trained without value alignment really be considered a “neutral” platform for further tuning, or rather a loose gun that might fire in any direction if triggered the wrong way?</p>
<p id="p-49">A further challenge is how to prepare the training data to meet the criteria delineated above, at the required tera- or petabyte scale. The most viable solution would likely be to use existing LLMs to prepare the training data by rewriting existing training data. The fact that today’s “lipstick-on-a-pig” LLMs are easily jailbroken is not necessarily a blocker, as jailbreaking of such models is mostly a problem “in the wild,” where malicious actors actively try to subvert the models. When deployed in a shielded environment where it is not goaded into undesirable behavior, even a “lipstick-on-a-pig” teacher remains value-aligned and can be used to generate training data for a student model, which in turn receives all its training data exclusively from the teacher. This way, both models—student and teacher—are safe during training: the teacher, because no malicious user is trying to manipulate it; the student, because it only receives curated training data from the—in this setting benign—teacher.</p>
<p id="p-50">The vision is that, over the course of training, the teacher model can eventually transmit all its knowledge and skills to the student model, but in a way that teaches values—the values that the “lipstick-on-a-pig” model acquired during its own post hoc alignment process—at the same time as knowledge and skills. But whereas those values are easy to subvert in the teacher, they will be much more deeply instilled and thus harder to subvert in the student—nearly as though the teacher was &#8220;reborn&#8221; as an equally knowledgeable and skillful, yet more morally stable, version of itself.</p>
<p id="p-51">Finally, even if an early, intrinsic alignment process as proposed here turns out to not be a standalone solution to the thorny problem of AI alignment to human values—which it might well not be—it can still serve as an additional layer of security, compensating for some of the flaws of current post hoc alignment, and vice versa.</p>
</section>
<section id="sec10" class="sec">
<h2 class="heading">Learning from the History of Nuclear Technology</h2>
<p id="p-52">We conclude by reflecting on a parallel between the history of AI safety and the history of nuclear safety. The first nuclear reactors mainly focused on the challenge of enabling energy generation from nuclear fission at all, leading to designs that had substantial inherent weaknesses. These weaknesses were realized and safety devices were developed to keep them in check. While this generally worked well, it turned out that under exceptional circumstances, external safety devices may fail, resulting in disasters such as Chernobyl in 1986. Such disasters taught nuclear engineers that an inherently unsafe architecture combined with some sort of external safety device is insufficient, which triggered massive research on reactor architectures that were safe by design.</p>
<p id="p-53">Transferring this lesson to AI, we shouldn’t wait for AI’s “Chernobyl moment.” Instead of fixing inherently unsafe AI with external safety measures applied as post-processing—lipstick on a pig—the very procedures endowing an AI model with intelligence should be inextricably entangled with the alignment of the model to our values.</p>
</section>
</div>
<footer class="back">
<section id="sec12" class="sec">
<h3 class="heading">Acknowledgments</h3>
<p>West’s lab is partly supported by grant TMSGI2_211379 from the Swiss National Science Foundation and by the Swiss AI Initiative.</p>
</section>
<section id="sec13" class="sec"></section>
</footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/from-model-training-to-model-raising/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Christian Cyron]]></dc:creator>
      <dc:creator><![CDATA[Steve Bachelor]]></dc:creator>
      <dc:creator><![CDATA[Ashton Anderson]]></dc:creator>
      <dc:creator><![CDATA[Robert West]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">775699</post-id>	</item>
		<item>
		<title>SRE Is Anti-Transactional</title>
		<link>https://cacm.acm.org/practice/sre-is-anti-transactional/</link>
					<comments>https://cacm.acm.org/practice/sre-is-anti-transactional/#respond</comments>
		
		<dc:creator><![CDATA[Thomas Limoncelli and Christian Pearce]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 16:12:19 +0000</pubDate>
				<category><![CDATA[Systems and Networking]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776477</guid>

					<description><![CDATA[<p>Understanding the tension between SRE goals and “traditional IT” mindsets is key to interacting with SRE teams.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">A major concern in the SRE movement is automation—that is, moving IT from focusing on transactional work to building systems that do work for us.</p>
<p id="p-2">There are many competing definitions of SRE. If you ask 10 SRE engineers to define SRE, you’ll get 11 definitions. Some will focus on the <i>R</i> (reliability) as the driving force in everything from feature priorities, to budgets, to technology choices. Others use SRE as an umbrella term encompassing everything from application upkeep, cloud engineering, service provisioning, and platform engineering to nearly all aspects of keeping a technology working.</p>
<p id="p-3">What they all have in common is an imperative to move away from transactional work. It may not be the defining attribute of the SRE domain, but it is an important aspect. Let’s drill down into it.</p>
<p id="p-4">SREs do not like manual work. Give a team of SREs a manual process, and over time they will evolve it from fully manual (people doing work), to automated (software tools that humans use to make progress), to autonomous (systems that identify when work needs to be done, do the work, and alert humans in exceptional situations). The aim is to progress toward eliminating manual work from the system altogether.</p>
<p id="p-5">SREs consider transactional work to be toil. Toil is work that, while valuable in and of itself, does not raise the bar and improve the process for any similar future requests. It is tactical, not strategic. It addresses immediate needs rather than contributing to long-term improvements or strategic goals.</p>
<p id="p-6">For example, deploying a new software release to a website is a good thing. The new software release has new features that benefit the user, increase profit, or otherwise provide value. In the old days, this process was done manually and would frequently require days or weeks of planning and execution. Then, the next time a new software release arrived, the same amount of work would be required to deploy it. That is <i>toil</i>.</p>
<p id="p-7">On the other hand, a project that replaces all that manual toil with a continuous integration/continuous delivery or deployment (CI/CD) system, such that developers can safely deploy new software releases in a self-service manner is <i>strategic</i>. It not only automates a manual process, thus reducing toil, but also permits the process to be done more frequently (even continuously) in smaller batches without waiting for IT to become available.</p>
<p id="p-8">SREs gladly do manual work but only as a necessary step of learning the process so that it can be automated and eventually become autonomous. Toil is acceptable when a task is infrequent or a process is new and ill-defined or experimental in nature. Those are exceptional situations, however.</p>
<p id="p-9">As the old joke goes, in the future there will be a factory that needs only two employees: one human and one dog. The human’s job will be to feed the dog. The dog’s job will be to make sure nobody touches the equipment.</p>
<p id="p-10">Once SREs rule the world, the dog will be automated as well.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Transactional Work</h2>
<p id="p-11">Transactional work usually takes the form of a request that is worked on by an individual until it is completed. Tickets opened with your IT organization are transactional work. Whether you are requesting a replacement mouse or need assistance with some technology that is not working correctly, the work is transactional. It begins with a request, work is performed, the requester verifies the work is complete, and then, lastly, the ticket is closed.</p>
<p id="p-12">Transactional work is typically manual and tactical (not strategic). It addresses immediate needs rather than contributing to long-term improvements or strategic goals. It does not improve the system, product, or processes in a meaningful way.</p>
<p id="p-13">Toil scales linearly. If the number of requests increases 10x, the number of people required to complete the work increases 10x. This is unacceptable in today’s business environment. Since Ford popularized the automotive assembly line, it has become an expectation that cost should scale sublinearly with growth. That is, if 10 units of work requires 10 people, 100 units of work should require significantly fewer than 100 people.</p>
<p id="p-14">Toil is reactive and interrupt-driven by nature, which makes planning difficult. A request arrives at an unpredictable time and requires humans to stop whatever they are doing to work on the task. Since people are not available 24/7, the requester must wait. Everyone has experienced the frustration of waiting days for someone to perform a task that takes minutes.</p>
<p id="p-15">Automation is available 24/7, so there is less waiting.</p>
<p id="p-16">Toil drains engineers’ time and energy, preventing them from focusing on high-impact engineering work such as automation, system improvement, or innovative projects. It reduces the overall efficiency and morale of the team, as engineers are bogged down in routine maintenance rather than more meaningful contributions.</p>
<p id="p-17">Luckily, toil is usually repetitive and, thankfully, repetitive tasks often prove to offer hot opportunities for automation.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Automation</h2>
<p id="p-18">SREs focus on building automation that eliminates the need to do manual work. It is not that they are lazy; they just want to be able to scale.</p>
<p id="p-19">Give a team of SREs a fully manual task, and over time it will go from fully manual, to automated, to autonomous. The difference between automated and autonomous is the level of automation required: Automated systems are tools that humans use to get a task done. Autonomous systems are triggered when new work arrives and they complete work on their own. With autonomous systems, the humans are there only for exceptions—edge cases that have not yet been automated, bugs that need to be fixed, or system optimizations.</p>
<p id="p-20">When work is automated, it can scale super-linearly. This is particularly important for Internet-based companies. As Michael O’Dell, chief scientist of the first commercial ISP, frequently said, “The only problem is scaling. All the others inherit from that one.”</p>
<p id="p-21">The analogy we like to make is that SREs are not the assembly-line workers at an auto manufacturing plant. They are the people who make the robots that make the cars.</p>
<p>A process generally goes through these stages:</p>
<ol class="list" data-jats-list-type="order">
<li class="list-item">
<p id="p-23"><b><i>Manual.</i></b> Progress is made by humans doing the work, often typing or clicking, observing what results, and then making decisions about how and when to proceed.</p>
</li>
<li class="list-item">
<p id="p-24"><b><i>Automated (sometimes called manual automation).</i></b> A tool performs each step. When a task needs to be done, a human uses a tool (software) to perform that task. A single process might require many steps. SREs tend to write tools that automate those steps. Often, individual steps have bespoke tools, and the process is completed by humans who use the appropriate tool for each step, judging the results, and then deciding when to move forward to the next step.</p>
</li>
<li class="list-item">
<p id="p-25"><b><i>Autonomous systems (sometimes called fully automated).</i></b> Software initiates and executes work without human intervention. Humans are there to handle exceptions and improve the system. Once a system is stable, it is mostly concerned with reducing the number of exceptions that require human intervention, addressing any new features and business concerns, and achieving greater efficiency.</p>
</li>
</ol>
<p id="p-26">An autonomous system is never finished. SREs live in a Sisyphean struggle: As they get closer to perfect automation, a changing world throws new toil at them. If every edge case were handled today, new business needs would appear tomorrow. If the system runs smoothly now, an underlying system will require an upgrade tomorrow.</p>
<p id="p-27">A good system will always be a victim of its own success, becoming so popular that it exceeds its original design limits and thus requires reengineering to overcome the new bottlenecks this growth exposes. Popularity inspires new use cases, which requires redesigns and refactoring. If the system were designed to handle only green widgets, surely its success would make it attractive to the yellow-widget division. Sadly, while extending it to a new use case sounds easy, it rarely proves to be.</p>
<p id="p-28">It is financially impractical to automate every conceivable use case. Some use cases are so infrequent or complex that automation can offer little or no return on investment. Automating those cases would be wasteful and considered to be a bad business decision.</p>
<p id="p-29">Thus, an autonomous system needs a team to maintain it, optimize it, and handle the exceptions. Autonomous systems are never “one and done.”</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Example: Cluster Builds</h2>
<p id="p-30">Tom was once on a team that was deploying storage clusters. Each cluster was made up of many individual hardware and software components.</p>
<p id="p-31">Initially, the process was manual, with hundreds of steps, each documented to varying degrees of completeness. Soon, each phase of the process was automated; one or more tools did most of the work of each phase. It required human judgment, however, to determine whether a phase had been completed correctly or fixes were required. We relied on human judgment to determine when to start each phase. This often required checking calendars or getting a go/no-go decision from other teams. While this situation was a great improvement over the manual process, it still required considerable human intervention to tell us when to start, what parameters were required in each instance, when to proceed to each new phase, as well as how to handle quality control. Still, it was better than a manual process in that it was more consistent, took less time, and required less cognitive load to complete each task.</p>
<p id="p-32">The next phase was to help the system become autonomous. Orders for new clusters were no longer presented during status meetings or via tickets. Instead, orders came from a database (imagine an order received via SalesForce). A validation process not only verified the request’s parameters, but also sent an email with an approval link to the designated budget controller. Each phase then was kicked off via timetables, verification of completion of preceding steps, and other triggers.</p>
<p id="p-33">Once the system was stable, we discovered that a typical cluster build still required human intervention at least twice during the multiday process. As we fixed edge cases, improved algorithms, and fine-tuned the system, this was reduced to nearly zero. The system had become data-driven and even had a dashboard that showed our “human intervention” count dropping over time.</p>
<p id="p-34">This count would still spike upward occasionally. These spikes correlated with new releases of software received from the developers, since each release had a tendency to break our fussy automation. Improving this required us to break out of our silo and work more closely with the developers.</p>
<p id="p-35">We realized their release process needed to include verifying that the cluster-deployment system supported the new release. It was a “lightbulb moment” for the product manager when he realized the ability to deploy clusters was as much a part of a new release as the new features we had promised to ship. Maybe this is obvious in hindsight, but the authors have seen this cycle (silo, lightbulb, cooperation) repeat frequently throughout our careers.</p>
<p id="p-36">It took more than a year to go from fully manual to an autonomous system. Most of the fine-tuning that was required after that was to scale the system both horizontally (efficiently creating larger clusters) and vertically (creating more clusters per month).</p>
<p id="p-37">The old manual system did not make anyone happy. Sales recognition (which starts <i>after</i> cluster delivery) was delayed. Customers were unhappy with misconfigurations and other bugs.</p>
<p id="p-38">The new system was fast and predictable (three days). It had an SLA that allowed the company to tell customers when to expect delivery of the service, and the sales department was alerted that a contract had to be signed three days before the end of the quarter for timely revenue recognition. Best of all, the system was autonomous, meaning orders could be fulfilled even if the SREs were asleep.</p>
</section>
<section id="sec5" class="sec">
<h2 class="heading">Example: Mouse and Cable Distribution</h2>
<p id="p-39">We used to think that one help-desk task that could never possibly be automated had to do with the procurement of small items such as replacement mice and USB cables. A customer would open a ticket requesting (for example) a mouse, whereupon the help-desk person would provide the mouse, assign the cost to the person’s department, and so on. How could that get any better?</p>
<p id="p-40">I was impressed to discover that Google’s help desk had actually succeeded in automating that process with a vending machine for physical items. Employees could swipe their badges, take the items they desired, after which their department would be billed. This system eliminated a significant percentage of help-desk visits—meaning the toil was gone. All that was left was a management process that involved ordering new items and monitoring for abuse.</p>
<p id="p-41">Some industry pundits claim there is a world of “old IT” that is all toil, unfixable, and doomed. We like to believe there is always hope whenever there is sufficient scale and a willingness on the part of management to embrace creativity and innovation.</p>
</section>
<section id="sec6" class="sec">
<h2 class="heading">How to Interface with SREs</h2>
<p id="p-42">Given the SRE distaste for transactional work, what is the best way to interact with an SRE team?</p>
<p id="p-43">Ideally, transactional requests that are manual in nature (verbal requests, tickets generated by humans, and so on) should be replaced by interactions through software. That is, your team should be able to provide an API to your SREs or request that they provide you with one. An API provides a way for the SRE software to interact with your systems and vice versa. This paves the path to automation.</p>
<p id="p-44">Sometimes, we get lucky because an API exists. Sometimes, though, the API is obscured. For example, the database or SaaS-based product your team is using might already have an API, but access to it must be enabled, properly secured, with rules of engagement defined.</p>
<p id="p-45">Usually, however, a new API needs to be created from scratch. This is not easy. There is no magic button you can press to make an API appear. Creating an API requires the very human process of sitting down, identifying the need and requirements, proposing designs, and allocating resources to build, test, and implement that design. This usually requires software engineering skills, which not every team has available. For example, in our experience human resources departments rarely have software engineers on staff.</p>
<p id="p-46">Efforts that mesh two teams with different levels of experience with process automation can prove to be frustrating for both teams. The non-SRE team, lacking software-development experience, can be put off by the requirement to work through a detailed process analysis given that the transactional process seems so obvious to them. The SRE team, meanwhile, can often become frustrated by the other team’s tolerance of toil and surprised at the lack of disdain for it.</p>
<p id="p-47">If creating an API is not an option, sometimes a little creativity is all that is required. In one case, Tom discovered that a “mostly autonomous” system was hamstrung by the fact that another team was responsible for allocating ID numbers required by the process. Basically, the process was fully autonomous apart from one “stop-the-world” moment that required waiting for a human on another team to allocate an ID number. This other team, meanwhile, did not understand the problems that resulted from this delay. Accordingly, the requests were often ignored for days. No other team made such requests and so they were viewed as “weird” and assumed to be of low priority. In reality, the delays were causing major headaches.</p>
<p id="p-48">By sitting down and discussing the situation, the teams were able to propose two creative solutions. One was to allocate large batches of ID numbers, reducing the human interaction to just refill the ID pool—something that might happen only a few times each year. The other idea was simply to permit the SRE team to allocate ID numbers with a particular prefix, thus giving them the ability to manage their own allocation process.</p>
<p id="p-49">Likewise, SRE teams should be willing to create interfaces for others. That could be a traditional network-based API, but often a Web-based user interface or dashboard will suffice. For example, the other team’s needs may be satisfied by gaining access to a dashboard in an existing monitoring or business information system. That could be a static Web page that is updated periodically. And while the need to visit a Web page to find answers might smell like unacceptable toil to an SRE, a non-SRE might just as easily view it as a welcome improvement.</p>
<p id="p-50">In the end, when we can find a way to work together to eliminate the need for tickets or to reduce toil in some other fashion, we all win.</p>
</section>
<section id="sec7" class="sec">
<h2 class="heading">Conclusion</h2>
<p id="p-51">The value of a team is its output. If the team’s role is to repeat the same task over and over again, that team’s value is going to scale linearly with their effort. But if the team’s role is to optimize processes through automation and the reduction of toil, then that team’s value will prove to be like compound interest, with growth propelling growth. SREs are happiest when they are in the latter category: creating value that scales.</p>
<p id="p-52">Systems built by SREs are not fully autonomous on day one. It is iteration over time that leads to fully autonomous, functional, reliable service. This iterative process requires SREs to evaluate how much time and money should be spent to achieve the objective. It is the heart of engineering to find the fastest, cheapest, and safest way to create and maintain a system.</p>
<p id="p-53">We have seen conflicts between SRE goals and “traditional IT” mindsets. Generally, these stem from the fundamental differences between the SRE mindset of automating wherever possible to eliminate toil and the more immediate focus other teams have on completing certain specific tasks.</p>
<p id="p-54">Understanding this tension is key to interacting with SRE teams.</p>
</section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/practice/sre-is-anti-transactional/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Christian Pearce]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">776477</post-id>	</item>
		<item>
		<title>Cardinality Estimation Graphs</title>
		<link>https://cacm.acm.org/research-highlights/cardinality-estimation-graphs/</link>
					<comments>https://cacm.acm.org/research-highlights/cardinality-estimation-graphs/#respond</comments>
		
		<dc:creator><![CDATA[Semih Salihoglu, Jeremy Chen, Yuqing Huang, Mushi Wang, and Ken Salem]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 15:50:01 +0000</pubDate>
				<category><![CDATA[Architecture and Hardware]]></category>
		<category><![CDATA[Data and Information]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776399</guid>

					<description><![CDATA[<p>The CEG framework can be the foundation to develop novel summary-based estimators.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div style="background: #F5CBA7;">
<h2>Abstract</h2>
<p>We study two classes of summary-based cardinality estimators that use statistics about input relations and joins of a small number of input relations: (i) optimistic estimators, which were defined in the context of graph database management systems, that make uniformity and conditional independence assumptions; and (ii) the recent pessimistic estimators that use information theoretic linear programs (LPs). We show that optimistic estimators can be modeled as picking bottom-to-top paths in a <em>cardinality estimation graph</em> (CEG), which contains sub-queries as nodes and edges whose weights are average degree statistics. We show that existing optimistic estimators have either undefined or fixed choices for picking CEG paths as their estimates and ignore alternative choices. Instead, we outline a space of optimistic estimators to make an estimate on CEGs, which subsumes existing estimators. We show, using an extensive empirical analysis, that effective paths depend on the structure of the queries. We next show that optimistic estimators and seemingly disparate LP-based pessimistic estimators are in fact connected. Specifically, we show that CEGs can also model some recent pessimistic estimators. This connection allows us to provide insights into the pessimistic estimators, such as showing that they have combinatorial solutions.</p>
</div>
<h2 class="heading"><span class="caption-label">1. </span>Introduction</h2>
<p id="p-1">The problem of estimating the output size of a natural multi-join query (henceforth <i>join query</i>) is a fundamental problem that is solved in the query optimizers of database management systems to generate efficient query plans. This problem arises both in relational systems as well as those that manage graph-structured data, where systems need to estimate the cardinalities of subgraphs in their input graphs. It is well known that both problems are equivalent, since subgraph queries can equivalently be written as join queries over binary relations that store the edges of a graph.</p>
<p id="p-2">Perhaps the most widely adopted estimators are <i>summary-based</i>, in which the DBMS uses statistics about a database in a procedure to derive an estimate. In this paper, we study two classes of summary-based techniques, which we will model through a common framework:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-3"><i>Optimistic estimators</i><a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> from graph-based systems store as statistics the cardinalities of small-size subgraphs, which correspond to joins of a small number of relations and use algebraic formulas that make independence and uniformity assumptions as a procedure. We refer to these as “optimistic,” as these estimators can underestimate true cardinalities of queries.</p>
</li>
<li class="list-item">
<p id="p-4"><i>Pessimistic estimators</i>,<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> which were introduced in the context of relational systems, store as statistics the <i>degrees</i> of the values in columns, that is, the number of times a value appears, and use linear programs (LPs) and have the guarantee that the estimate is an upper bound on the true cardinality of a query.</p>
</li>
</ul>
<p id="p-5">To motivate our first contribution, consider a database consisting of an edge-labeled graph with capital letter labels <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span>, and so on. This can be modeled as a set of binary relations, such as <code class="monospace">A(src, dst)</code>. Consider the “subgraph query” in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>, asking for matches of a five-edge subgraph, which is equivalent to a join of five relations. Given the accurate cardinalities of all sub-queries of size <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>≤</mo></math></span> 2, there are 252 formulas to make an estimate. Two examples are:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-6"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> <mo>×</mo> </mrow> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>C</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>←</mo> <mi>C</mi> </mover> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>C</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>←</mo> <mi>D</mi> </mover> <mover> <mo>→</mo> <mi>E</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> </mrow> </math> </span></p>
</li>
<li class="list-item">
<p id="p-7"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> <mo>×</mo> </mrow> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>←</mo> <mi>C</mi> </mover> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>E</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> </mrow> </math> </span></p>
</li>
</ul>
<figure id="F1" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 1. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig01.jpg" alt="" data-image-id="F1" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 1. </span> <span class="p">Example subgraph query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span>.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-9">In previous work,<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> the choice of which of these estimates to use has either been unspecified or fixed without acknowledging possible other choices. Our first contribution aims to answer the following questions: What is the space of formulas of a query? Which formulas should be picked to make more accurate estimates?</p>
<p id="p-10">We begin by showing that the algebraic formulas of prior optimistic estimators can be modeled as picking a bottom-to-top path in a weighted <i>cardinality estimation graph</i> (CEG), which we call <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>, for <b>O</b>ptimistic. In this CEG, nodes are intermediate sub-queries and edges; weights are average degree statistics that extend sub-queries to larger queries. For example, the <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for the query in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a> and the dataset in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a> is shown in Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a>. Each path of this CEG corresponds to a possible formula where the estimate is the multiplication of the weights of the edges in the path.</p>
<figure id="F2" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 2. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig02.jpg" alt="" data-image-id="F2" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 2. </span> <span class="p">Example dataset in graph and relational formats.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<figure id="F3" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 3. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig03.jpg" alt="" data-image-id="F3" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 3. </span> <span class="p"><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span> in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a> when the Markov table (§<a class="xref xref-sec" href="#sec4" data-jats-ref-type="sec" data-jats-rid="sec4">4</a>) contains joins up to size 3.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-13">We systematically describe a space of nine estimators, defined by different choices to pick a CEG path for making an optimistic estimate. This space subsumes and extends the choices made by existing optimistic estimators. We then empirically show that the better-performing optimistic estimators in this CEG space depends on the structure of the query. On acyclic queries and queries with small-size cycles, we advise using the <i>maximum-weight paths</i>; using independence assumptions tends to underestimate the true cardinalities of queries, which can be offset by picking the highest-estimating formula. In contrast, on queries that contain larger cycles, optimistic estimators estimate the number of paths rather than cycles. Here we advise using minimum-weight paths, as real-world graphs contain many more paths than cycles.</p>
<p id="p-14">As our next main contribution, we show that CEGs are expressive enough to also model the recent LP-based pessimistic estimators. Specifically, we show we can replace the edge weights of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> (which are average degrees) with maximum degrees of base relations and small-size joins, and construct a new CEG, which we call <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>. Unlike the optimistic estimators, where the choice of path is not clear, we now show that picking the minimum weight path would (provably) be the most accurate estimate and this path is indeed equivalent to the solution of the LP that defines a pessimistic estimator from Joglekar and Ré<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> called MOLP. We therefore show that both subgraph summary-based optimistic estimators and the recent LP-based pessimistic ones can be seen as different instances of a broader class of estimators that pick paths through CEGs. Modeling these two classes of estimators in a common framework has several benefits, for example, one can apply optimizations for one class to the other. Our paper also opens the possibility of defining many other CEGs that use different statistics as edge weights, for example, entropies of certain columns. We hope future work can define and evaluate the accuracies of such CEGs.</p>
<p id="p-15">For readers interested in the theory of pessimistic estimators, we note that CEGs are also very useful mathematical tools to prove properties of pessimistic estimators. For example, using CEGs in our proofs, we can derive combinatorial proofs to some properties of MOLP, for instance, that MOLP is identical to the pessimistic estimator proposed by Cai et al.<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> on acyclic queries over binary relations.</p>
<section id="sec2" class="sec">
<h2 class="heading"><span class="caption-label">2. </span>Query and Database Notation</h2>
<p id="p-16">We consider conjunctive queries, that is, natural join queries, of the form</p>
<p><span id="EEq1" class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML"> <mrow> <mi>Q</mi> <mrow> <mo>(</mo> <mi>A</mi> <mo>)</mo> </mrow> <mo>=</mo> <msub> <mi>R</mi> <mn>1</mn> </msub> <mrow> <mo>(</mo> <msub> <mi>A</mi> <mn>1</mn> </msub> <mo>)</mo> </mrow> <mo>,</mo> <mo>&#8230;</mo> <mo>,</mo> <msub> <mi>R</mi> <mi>m</mi> </msub> <mrow> <mo>(</mo> <msub> <mi>A</mi> <mi>m</mi> </msub> <mo>)</mo> </mrow> </mrow> </math> </span></p>
<p id="p-17">where <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>R</mi><mi>i</mi></msub><mrow><mo>(</mo><msub><mi>A</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></math></span> is a relation with attributes <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>A</mi><mi>i</mi></msub></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>A</mi><mo>=</mo><msub><mo>∪</mo><mi>i</mi></msub><msub><mi>A</mi><mi>i</mi></msub></mrow></math></span>. In conjunctive queries, the join predicates are equality of the common attributes shared across relations. Most of the examples used in this paper involve edge-labeled subgraph queries, in which case each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>R</mi><mi>i</mi></msub></math></span> is modeled a binary relation containing a subset of the edges in a graph as source/destination pairs. Note that even if these edges contain other properties that can be modeled as additional columns, for the purpose of the join query, they are not relevant. Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a> presents an example showing a graph with edge labels <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>D</mi></math></span>, and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span>. This graph can be represented using five binary relations, one for each edge label, as shown in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>. We will often represent queries over such relations using a graph notation. For example, consider the relations <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span> from Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>. We will represent the query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Q</mi><mrow><mo>(</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>,</mo><msub><mi>a</mi><mn>3</mn></msub><mo>)</mo></mrow><mo>=</mo><mi>A</mi><mrow><mo>(</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>)</mo></mrow><mo>⋈</mo><mi>B</mi><mrow><mo>(</mo><msub><mi>a</mi><mn>2</mn></msub><mo>,</mo><msub><mi>a</mi><mn>3</mn></msub><mo>)</mo></mrow></mrow></math></span> as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>a</mi><mn>1</mn></msub><mover><mo>→</mo><mi>A</mi></mover><msub><mi>a</mi><mn>2</mn></msub><mover><mo>→</mo><mi>B</mi></mover><msub><mi>a</mi><mn>3</mn></msub></mrow></math></span>. Similarly, the query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>Q</mi><mrow><mo>(</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>,</mo><msub><mi>a</mi><mn>3</mn></msub><mo>)</mo></mrow><mo>=</mo><mi>A</mi><mrow><mo>(</mo><msub><mi>a</mi><mn>1</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>)</mo></mrow><mo>⋈</mo><mi>B</mi><mrow><mo>(</mo><msub><mi>a</mi><mn>3</mn></msub><mo>,</mo><msub><mi>a</mi><mn>2</mn></msub><mo>)</mo></mrow></mrow></math></span> will be represented as <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>a</mi><mn>1</mn></msub><mover><mo>→</mo><mi>A</mi></mover><msub><mi>a</mi><mn>2</mn></msub><mover><mo>←</mo><mi>B</mi></mover><msub><mi>a</mi><mn>3</mn></msub></mrow></math></span>.</p>
<p id="p-18"><b>Note on binary vs. arbitrary relations:</b> We emphasize that CEGs, which will be introduced in Section <a class="xref xref-sec" href="#sec3" data-jats-ref-type="sec" data-jats-rid="sec3">3</a>, do not require relations to be binary. In fact, the CEG we will define for pessimistic estimators in Section <a class="xref xref-sec" href="#sec5" data-jats-ref-type="sec" data-jats-rid="sec5">5</a> assumes relations with arbitrary arities. However, we do our empirical evaluation on optimistic estimators, which for practical reasons have been developed in the context of graph-based systems, where joins are over binary relations. The reason is that optimistic estimators store as statistics the sizes of all possible small-size joins, that is, joins of a small number of relations, and when relations are binary, it is practical for a system to know and store the set of possible small-size joins in advance. In contrast, in RDBMSs that store relations with arbitrary numbers of columns and where columns can be arbitrarily joined with each other, the number of possible small-size joins can be very large.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading"><span class="caption-label">3. </span>CEG Overview</h2>
<p id="p-19">Next, we offer some intuition for CEGs. A CEG for a query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> consists of:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-20">Vertices labeled with sub-queries of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>, where sub-queries are defined by subsets of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>’s relations or attributes</p>
</li>
<li class="list-item">
<p id="p-21">Edges from smaller sub-queries to larger sub-queries, labeled with <i>extension rates</i>, which represent the cardinality of the larger sub-query relative to that of the smaller sub-query</p>
</li>
</ul>
<p id="p-22">Each bottom-to-top path (from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>∅</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>) in a CEG represents a different way of generating a cardinality estimate for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>. An estimator using a CEG picks one of these paths as an estimate. The estimate of a path is the product of the extension rates along the edges of the path. Equivalently, one can put the logarithms of the extension rates as edge weights and sum the logarithms.</p>
<p id="p-23">Figure <a class="xref xref-fig" href="#F4" data-jats-ref-type="fig" data-jats-rid="F4">4</a> illustrates a <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><mi>G</mi></mrow></math></span><a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a> for the query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span> shown in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a> over the relations shown in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>, assuming that statistics are available for any size-2 sub-queries of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span>. Depending on the semantics of the edges in a CEG, there can be multiple edges between two sub-queries in a CEG. For example, the last components of the two formulas we presented in Section <a class="xref xref-sec" href="#sec1" data-jats-ref-type="sec" data-jats-rid="sec1">1</a> for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mrow><mo>|</mo></mrow><mover><mo>←</mo><mi>D</mi></mover><mover><mo>→</mo><mi>E</mi></mover><mrow><mo>|</mo><mo>/</mo><mo>|</mo></mrow><mover><mo>→</mo><mi>D</mi></mover><mrow><mo>|</mo></mrow></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mrow><mo>|</mo></mrow><mover><mo>→</mo><mi>B</mi></mover><mover><mo>→</mo><mi>E</mi></mover><mrow><mo>|</mo><mo>/</mo><mo>|</mo></mrow><mover><mo>→</mo><mi>B</mi></mover><mrow><mo>|</mo></mrow></mrow></math></span>, correspond to parallel edges that extend the sub-query over <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>A</mi><mi>B</mi><mi>C</mi><mi>D</mi></mrow></math></span> edges with an <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span> edge to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span>. Consider the leftmost path in Figure <a class="xref xref-fig" href="#F4" data-jats-ref-type="fig" data-jats-rid="F4">4</a>. The first extension rate from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>∅</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>a</mi><mn>1</mn></msub><mover><mo>→</mo><mi>A</mi></mover><msub><mi>a</mi><mn>2</mn></msub><mover><mo>→</mo><mi>B</mi></mover><msub><mi>a</mi><mn>3</mn></msub></mrow></math></span> is the known cardinality of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>a</mi><mn>1</mn></msub><mover><mo>→</mo><mi>A</mi></mover><msub><mi>a</mi><mn>2</mn></msub><mover><mo>→</mo><mi>B</mi></mover><msub><mi>a</mi><mn>3</mn></msub></mrow></math></span>, which is 4, and the second extension rate has a weight <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>3</mn><mo>/</mo><mn>2</mn></mrow></math></span>, intuitively estimating that each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>a</mi><mn>1</mn></msub><mover><mo>→</mo><mi>A</mi></mover><msub><mi>a</mi><mn>2</mn></msub><mover><mo>→</mo><mi>B</mi></mover><msub><mi>a</mi><mn>3</mn></msub></mrow></math></span> path will extend to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>3</mn><mo>/</mo><mn>2</mn></mrow></math></span> many <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>a</mi><mn>1</mn></msub><mover><mo>→</mo><mi>A</mi></mover><msub><mi>a</mi><mn>2</mn></msub><mover><mo>→</mo><mi>B</mi></mover><msub><mi>a</mi><mn>3</mn></msub><mover><mo>→</mo><mi>C</mi></mover><msub><mi>a</mi><mn>4</mn></msub></mrow></math></span> paths. Continuing the extensions, the final estimate is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>4</mn><mo>×</mo><mfrac><mn>3</mn><mn>2</mn></mfrac><mo>×</mo><mfrac><mn>5</mn><mn>2</mn></mfrac><mo>×</mo><mfrac><mn>7</mn><mn>2</mn></mfrac><mo>=</mo><mn>52</mn><mo>.</mo><mn>5</mn></mrow></math></span>.</p>
<figure id="F4" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 4. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig04.jpg" alt="" data-image-id="F4" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 4. </span> <span class="p"><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span> from Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a> when the Markov table (§<a class="xref xref-sec" href="#sec4" data-jats-ref-type="sec" data-jats-rid="sec4">4</a>) contains joins up to size 2.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-25">In the rest of this paper, we will show how some prior optimistic and pessimistic estimators can be modeled as instances of this generic estimator using different CEGs.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading"><span class="caption-label">4. </span>Optimistic Estimators</h2>
<p id="p-26">The estimators that we refer to as <i>optimistic</i> use statistics about the input database in formulas that make uniformity and independence or conditional independence assumptions. We focus on three estimators: <i>Markov tables</i><a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> from XML databases, graph summaries<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a> from RDF databases, and the graph catalog estimator of the Graphflow system<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> for managing property graphs. As we explain momentarily, despite being designed for systems that adopt different graph-based data models, these estimators are all extensions of each other.</p>
<p id="p-27">We begin by giving an overview of the Markov tables estimator<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a>. A Markov table of length <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>h</mi><mo>≥</mo><mn>2</mn></mrow></math></span> stores the cardinality of each path in an XML document’s element tree up to length <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>h</mi></math></span> and uses these to make predictions for the cardinalities of longer paths. Table <a class="xref xref-table" href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a> shows a subset of the entries in an example Markov table for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>h</mi><mo>=</mo><mn>2</mn></mrow></math></span> for our running example dataset from Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>. The formula to estimate a 3-path using a Markov table with <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>h</mi><mo>=</mo><mn>2</mn></mrow></math></span> is to multiply the cardinality of one of the 2-paths with the consecutive 2-path divided by the cardinality of the common edge. For example, consider the query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>Q</mi><mrow><mn>3</mn><mi>p</mi></mrow></msub><mo>=</mo><mover><mo>→</mo><mi>A</mi></mover><mover><mo>→</mo><mi>B</mi></mover><mover><mo>→</mo><mi>C</mi></mover></mrow></math></span> against the dataset in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>. The formula for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>3</mn><mi>p</mi></mrow></msub></math></span> would be: <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mrow><mo>|</mo></mrow><mover><mo>→</mo><mi>A</mi></mover><mover><mo>→</mo><mi>B</mi></mover><mrow><mo>|</mo><mo>×</mo><mo>(</mo><mo>|</mo></mrow><mover><mo>→</mo><mi>B</mi></mover><mover><mo>→</mo><mi>C</mi></mover><mrow><mo>|</mo><mo>/</mo><mo>|</mo></mrow><mover><mo>→</mo><mi>B</mi></mover><mrow><mo>|</mo><mo>)</mo></mrow></mrow></math></span>. The formula assumes that the number of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>C</mi></math></span> edges that each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span> edge extends to is uniformly <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mrow><mi>r</mi><mo>=</mo><mo>|</mo></mrow><mover><mo>→</mo><mi>B</mi></mover><mover><mo>→</mo><mi>C</mi></mover><mrow><mo>|</mo><mo>/</mo><mo>|</mo></mrow><mover><mo>→</mo><mi>B</mi></mover><mrow><mo>|</mo></mrow></mrow></math></span>. Equivalently, this is the “average C-degree” of nodes in the <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mover><mo>→</mo><mi>B</mi></mover><mover><mo>→</mo><mi>C</mi></mover></mrow></math></span> paths. The result of this formula is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mn>4</mn><mo>×</mo><mfrac><mn>3</mn><mn>2</mn></mfrac><mo>=</mo><mn>6</mn></mrow></math></span>, which underestimates the true cardinality of 7. The graph summaries<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a> for RDF databases and the graph catalog estimator<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> have extended the contents of what is stored in Markov tables, respectively, to other acyclic joins, such as stars, and small cycles, such as triangles.</p>
<figure id="T1" class="table-wrap" data-jats-position="float">
<div class="caption"><span class="caption-label">Table 1. </span> <span class="p">Example Markov table for <i>h</i> = 2.</span></div>
<div class="table-container">
<table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows">
<colgroup>
<col align="center" valign="top" />
<col align="center" valign="top" /> </colgroup>
<thead>
<tr>
<th style="text-align: center;">Path</th>
<th style="text-align: center;">|Path|</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mover> <mo>→</mo> <mi>B</mi> </mover> </math> </span></td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> </mrow> </math> </span></td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: center;"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>C</mi> </mover> </mrow> </math> </span></td>
<td style="text-align: center;">3</td>
</tr>
<tr>
<td style="text-align: center;">&#8230;</td>
<td style="text-align: center;">&#8230;</td>
</tr>
</tbody>
</table>
</div>
</figure>
<section id="sec5" class="sec">
<h3 class="heading"><span class="caption-label">4.1 </span>Space of possible optimistic estimators.</h3>
<p id="p-29">We next represent optimistic estimators using a CEG we call <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>. We assume the given query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> is connected. <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> consists of the following:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-30"><i>Vertices:</i> For each connected subset of relations <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>S</mi><mo>⊆</mo><mi>R</mi></mrow></math></span> of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>, we have a vertex in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> with label <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span>. This represents the sub-query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mo>⋈</mo><mrow><msub><mi>R</mi><mi>i</mi></msub><mo>∈</mo><mi>S</mi></mrow></msub><msub><mi>R</mi><mi>i</mi></msub></mrow></math></span>.</p>
</li>
<li class="list-item">
<p id="p-31"><i>Edges:</i> Consider two vertices with labels <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mi>S</mi><mo>′</mo></msup></math></span> such that <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>S</mi><mo>⊂</mo><msup><mi>S</mi><mo>′</mo></msup></mrow></math></span>. Let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>D</mi><mo>=</mo><mi>S</mi><mo>′</mo><mo></mo><mi>S</mi></mrow></math></span> (for <b>d</b>ifference), <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ε</mi><mo>⊃</mo><mi>D</mi></mrow></math></span> (for <b>e</b>xtension) be a Markov table entry, and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>I</mi></math></span>=<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>ε</mi><mo>∩</mo><mi>S</mi></mrow></math></span> (for <b>i</b>ntersection). If <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>ε</mi></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>I</mi></math></span> exist in the Markov table, then there is an edge with weight <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mfrac><mrow><mo>|</mo><mi>ε</mi><mo>|</mo></mrow><mrow><mo>|</mo><mi>I</mi><mo>|</mo></mrow></mfrac></math></span> from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mi>S</mi><mo>’</mo></msup></math></span> in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>.</p>
</li>
</ul>
<p id="p-32">This gives the core structure of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>, though when making estimates there are several simple rules that remove some edges in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> from prior work that limit the paths considered in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> (see the longer version of this paper<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a>). In general, there may be multiple <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><mi>Q</mi><mo>)</mo></mrow></math></span> paths that lead to different estimates in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>:</p>
<p id="p-33"><i>Example 1:</i> Consider the <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span> shown in Figure <a class="xref xref-fig" href="#F4" data-jats-ref-type="fig" data-jats-rid="F4">4</a>, which uses a Markov table of size 2. There are 36 <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><mi>Q</mi><mo>)</mo></mrow></math></span> paths leading to seven different estimates. Two examples are:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-34"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> <mo>×</mo> </mrow> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>C</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>E</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>=</mo> <mn>52</mn> <mo>.</mo> <mn>5</mn> </mrow> </math> </span></p>
</li>
<li class="list-item">
<p id="p-35"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> <mo>×</mo> </mrow> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>C</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>B</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>←</mo> <mi>C</mi> </mover> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>C</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>←</mo> <mi>D</mi> </mover> <mover> <mo>→</mo> <mi>E</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> <mrow> <mrow> <mo>|</mo> </mrow> <mover> <mo>→</mo> <mi>D</mi> </mover> <mrow> <mo>|</mo> </mrow> </mrow> </mfrac> <mo>=</mo> <mn>57</mn> <mo>.</mo> <mn>6</mn> </mrow> </math> </span></p>
</li>
</ul>
<p id="p-36"><i>Example 2:</i> Similarly, consider estimating <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span> now with a Markov table with up to 3-size joins. The new <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> is shown in Figure <a class="xref xref-fig" href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a>, which contains multiple paths leading to two different estimates:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-37"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mo>|</mo> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>C</mi> </mover> <mo>|</mo> <mo>×</mo> <mfrac> <mrow> <mo>|</mo> <mover> <mo>←</mo> <mi>C</mi> </mover> <munderover> <mo>⇒</mo> <mi>E</mi> <mi>D</mi> </munderover> <mo>|</mo> </mrow> <mrow> <mo>|</mo> <mover> <mo>→</mo> <mi>C</mi> </mover> <mo>|</mo> </mrow> </mfrac> </mrow> </math> </span></p>
</li>
<li class="list-item">
<p id="p-38"><span class="inline-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"> <mrow> <mrow> <mo>|</mo> <mrow> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>C</mi> </mover> </mrow> <mo>|</mo> </mrow> <mo>×</mo> <mfrac> <mrow> <mo>|</mo> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>D</mi> </mover> <mo>|</mo> </mrow> <mrow> <mo>|</mo> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mo>|</mo> </mrow> </mfrac> <mo>×</mo> <mfrac> <mrow> <mo>|</mo> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mover> <mo>→</mo> <mi>E</mi> </mover> <mo>|</mo> </mrow> <mrow> <mo>|</mo> <mover> <mo>→</mo> <mi>A</mi> </mover> <mover> <mo>→</mo> <mi>B</mi> </mover> <mo>|</mo> </mrow> </mfrac> </mrow> </math> </span></p>
</li>
</ul>
<p id="p-39">Both formulas start by <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mrow><mo>|</mo><mrow><mover><mo>→</mo><mi>A</mi></mover><mover><mo>→</mo><mi>B</mi></mover><mover><mo>→</mo><mi>C</mi></mover></mrow><mo>|</mo></mrow></mrow></math></span>. The first <i>short-hop</i> formula makes one fewer independence assumption than the <i>long-hop</i> formula, which is an advantage. In contrast, the first estimate also makes a uniformity assumption that conditions on a smaller-size join, which might make it less accurate than the two assumptions made in the long-hop estimate, which condition on 2-size joins.</p>
<p id="p-40">Any optimistic estimator implementation needs to make choices about which formulas to use; this corresponds to picking paths in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>. We systematically identify a space of choices an optimistic estimator can make along two parameters that capture the choices made in prior work:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-41"><i>Path length:</i> The estimator can identify a set of paths to consider based on the path lengths, that is, number of edges or hops, in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>, which can be: (i) maximum-hop (<code class="monospace">max-hop</code>), (ii) minimum-hop (<code class="monospace">min-hop</code>), or (iii) any number of hops (<code class="monospace">all-hops</code>). Let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>P</mi></math></span> be the set of paths an estimator picks.</p>
</li>
<li class="list-item">
<p id="p-42"><i>Aggregator:</i> To derive a final estimate, the estimator has to aggregate the estimates in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>P</mi></math></span>. We identify three aggregators: (i) the path with the largest estimate (<code class="monospace">max-aggr</code>), (ii) the path with the lowest estimate (<code class="monospace">min-aggr</code>), or (iii) the average of all the estimates in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>P</mi></math></span> (<code class="monospace">avg-aggr</code>).</p>
</li>
</ul>
<p id="p-43">Any combination of these two choices can be used to design an optimistic estimator. The original Markov tables<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> chose the <code class="monospace">max-hop</code> paths. In Aboulnaga et al.,<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> queries were paths, so when the path length is chosen, any <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> path gives the same estimate. Therefore, an aggregator is not needed. Graph Summaries<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a> chooses the <code class="monospace">min-hop</code> paths and leaves the aggregator unspecified. Graph Catalog<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> picks the <code class="monospace">min-hop</code> and <code class="monospace">min-aggr</code> aggregator. None of these estimators consider alternative choices an estimator can make. Instead, we do a systematic experimental analysis of this space of estimators in Section <a class="xref xref-sec" href="#sec6" data-jats-ref-type="sec" data-jats-rid="sec6">6</a> and show that the best choices depend on the query structure, as optimistic estimators behave differently on different structures. For acyclic queries and queries with small cycles, these estimators tend to underestimate, and for queries with larger cycles, they tend to overestimate. We next make an observation to explain this difference.</p>
<p id="p-44">Recall that a Markov table stores the cardinalities of patterns up to some size <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>h</mi></math></span>. Given a Markov table with <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>h</mi><mo>≥</mo><mn>2</mn></mrow></math></span>, optimistic estimators can produce estimates for any acyclic query with size larger than <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>h</mi></math></span>. However, faced with a large cyclic query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>, optimistic estimators do not actually produce estimates for <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>. Instead, they produce an estimate for a similar acyclic <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mi>Q</mi><mo>′</mo></msup></math></span> that includes all of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>’s edges but is not closed. To see this, consider the following example:</p>
<div id="sta1" class="statement"><b class="statement-label">Example 1</b></p>
<p id="p-45">Consier a 4-cycle query in Figure <a class="xref xref-fig" href="#F5" data-jats-ref-type="fig" data-jats-rid="F5">5a</a> using a Markov table with <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>h</mi></math></span>=3. The <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for this setting is shown in Figure <a class="xref xref-fig" href="#F5" data-jats-ref-type="fig" data-jats-rid="F5">5b</a>. Consider the leftmost path corresponding to the formula: <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>|</mo><mover accent="false"><mo>→</mo><mi>A</mi></mover><mover accent="false"><mo>→</mo><mi>B</mi></mover><mover accent="false"><mo>→</mo><mi>C</mi></mover><mo>|</mo><mo>×</mo><mo>|</mo><mover accent="false"><mo>→</mo><mi>B</mi></mover><mover accent="false"><mo>→</mo><mi>C</mi></mover><mover accent="false"><mo>→</mo><mi>D</mi></mover><mo>|</mo><mo>/</mo><mo>|</mo><mover accent="false"><mo>→</mo><mi>B</mi></mover><mover accent="false"><mo>→</mo><mi>C</mi></mover><mo>|</mo></math></span>. This formula is in fact estimating a 4-path <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mover><mo>→</mo><mi>A</mi></mover><mover><mo>→</mo><mi>B</mi></mover><mover><mo>→</mo><mi>C</mi></mover><mover><mo>→</mo><mi>D</mi></mover></mrow></math></span> rather than the 4-cycle. This is true for each path in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>.</p>
</div>
<figure id="F5" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 5. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig05.jpg" alt="" data-image-id="F5" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 5. </span> <span class="p">A 4-cycle query and its <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-47">More generally, when queries contain cycles of length <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>&gt;</mo><mi>h</mi></mrow></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> breaks cycles in queries into paths. Therefore, estimates over <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> can lead to <i>overestimates</i> for queries with large cycles, as there are often significantly more paths than cycles in real-world graphs.</p>
</section>
</section>
<section id="sec6" class="sec">
<h2 class="heading"><span class="caption-label">5. </span>Pessimistic Estimators</h2>
<p id="p-48">Starting from the seminal result by Atserias, Grohe, and Marx in 2008,<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> several upper bounds have been provided for the output sizes of join queries under different known statistics. For example the initial upper bound from Atserias et al.,<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> now called the <i>AGM bound</i>, used only the cardinalities of each relation, while later bounds, DBPLP,<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> MOLP,<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> and CLLP<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> used maximum degrees of the values in the columns and improved the AGM bound. Since these bounds are upper bounds on the query size, they can be used as <i>pessimistic estimators</i>. This was done recently by Cai et al.<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> in an actual estimator implementation. We refer to this as the CBS estimator, after the names of the authors. We next show that some of the recent pessimistic estimators<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> can also be modeled as making an estimate using a CEG.</p>
<section id="sec7" class="sec">
<h3 class="heading"><span class="caption-label">5.1 </span>MOLP.</h3>
<p id="p-49">MOLP was defined in Joglekar and Ré<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> as a tighter bound than the AGM bound that uses additional degree statistics about input relations that AGM bound does not use. Let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> be a subset of the attributes <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>A</mi><mi>i</mi></msub></math></span> of some relation <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>R</mi><mi>i</mi></msub></math></span>, and let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> be a possible value of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span>. The <i>degree</i> of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>R</mi><mi>i</mi></msub></math></span> is the number of times <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> occurs in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>R</mi><mi>i</mi></msub></math></span>, that is, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mrow><mo>(</mo><mi>X</mi><mrow><mo>(</mo><mi>v</mi><mo>)</mo></mrow><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>=</mo><mrow><mo>|</mo><mrow><mo>{</mo><mi>t</mi><mo>∈</mo><msub><mi>R</mi><mi>i</mi></msub><mo>|</mo><msub><mi>π</mi><mi>X</mi></msub><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>=</mo><mi>v</mi><mo>}</mo></mrow><mo>|</mo></mrow></mrow></math></span>. For example, in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>s</mi><mo>(</mo><mn>3</mn><mo>)</mo><mo>,</mo><mi>E</mi><mo>)</mo><mo>=</mo><mn>3</mn></mrow></math></span> because the outgoing <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>E</mi></math></span>-degree of vertex 3 is 3. Similarly, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>d</mi><mo>(</mo><mn>2</mn><mo>)</mo><mo>,</mo><mi>A</mi><mo>)</mo></mrow></math></span> is 1 because the incoming <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>-degree of vertex 2 is 1. We also define <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>X</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></math></span> to be the maximum degree in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>R</mi><mi>i</mi></msub></math></span> of any value <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> over <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span>, that is, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mrow><mo>(</mo><mi>X</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>=</mo><msub><mo>max</mo><mi>v</mi></msub><mi>d</mi><mi>e</mi><mi>g</mi><mrow><mo>(</mo><mi>X</mi><mrow><mo>(</mo><mi>v</mi><mo>)</mo></mrow><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></math></span>. So, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>d</mi><mo>,</mo><mi>A</mi><mo>)</mo><mo>=</mo><mn>3</mn></mrow></math></span> because vertex 13 has three incoming <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span> edges, which is the maximum A-in-degree in the dataset. The notion of degree can be generalized to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>X</mi><mrow><mo>(</mo><mi>v</mi><mo>)</mo></mrow><mo>,</mo><mi>Y</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></math></span>, which refers to the “degree of a value <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> over attributes <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span> in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>π</mi><mi>Y</mi></msub><msub><mi>R</mi><mi>i</mi></msub></mrow></math></span>”, which counts the number of times <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> occurs in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>π</mi><mi>Y</mi></msub><mrow><mo>(</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></math></span>. Similarly, we let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mrow><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>=</mo><msub><mo>max</mo><mi>v</mi></msub><mi>d</mi><mi>e</mi><mi>g</mi><mrow><mo>(</mo><mi>X</mi><mrow><mo>(</mo><mi>v</mi><mo>)</mo></mrow><mo>,</mo><mi>Y</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></math></span>. Suppose a system has stored <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></math></span> statistics for each possible <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>R</mi><mi>i</mi></msub></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>X</mi><mo>⊆</mo><mi>Y</mi><mo>⊆</mo><msub><mi>A</mi><mi>i</mi></msub></mrow></math></span>. MOLP is the output of this LP:</p>
<p id="p-50"><span id="EEq2" class="disp-formula"> <math xmlns="http://www.w3.org/1998/Math/MathML"> <mtable> <mtr> <mtd></mtd> <mtd> <mrow> <mtext>Maximize</mtext> <mspace></mspace> <msub> <mi>s</mi> <mi>A</mi> </msub> </mrow> </mtd> </mtr> <mtr> <mtd></mtd> <mtd> <mrow> <msub> <mi>s</mi> <mi>∅</mi> </msub> <mo>=</mo> <mn>0</mn> </mrow> </mtd> </mtr> <mtr> <mtd></mtd> <mtd> <mrow> <msub> <mi>s</mi> <mi>X</mi> </msub> <mo>≤</mo> <msub> <mi>s</mi> <mi>Y</mi> </msub> <mo>,</mo> <mspace></mspace> <mo>∀</mo> <mi>X</mi> <mo>⊆</mo> <mi>Y</mi> </mrow> </mtd> </mtr> <mtr> <mtd></mtd> <mtd> <mrow> <msub> <mi>s</mi> <mrow> <mi>Y</mi> <mo>∪</mo> <mi>E</mi> </mrow> </msub> <mo>≤</mo> <msub> <mi>s</mi> <mrow> <mi>X</mi> <mo>∪</mo> <mi>E</mi> </mrow> </msub> <mtext>+</mtext> <mo>log</mo> <mrow> <mo>(</mo> <mi>d</mi> <mi>e</mi> <mi>g</mi> <mrow> <mo>(</mo> <mi>X</mi> <mo>,</mo> <mi>Y</mi> <mo>,</mo> <msub> <mi>R</mi> <mi>i</mi> </msub> <mo>)</mo> </mrow> <mo>)</mo> </mrow> <mo>,</mo> <mo>∀</mo> <mi>X</mi> <mo>,</mo> <mi>Y</mi> <mo>,</mo> <mi>E</mi> <mo>⊆</mo> <mi>A</mi> <mo>,</mo> <mi>X</mi> <mo>⊆</mo> <mi>Y</mi> <mo>⊆</mo> <msub> <mi>A</mi> <mi>i</mi> </msub> </mrow> </mtd> </mtr> </mtable> </math> </span></p>
<p id="p-51">The base of the logarithm can be any constant and we take it as 2. Let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>m</mi><mi>A</mi></msub></math></span> be the optimal value of MOLP. Joglekar and Ré<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> has shown that <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mn>2</mn><msub><mi>m</mi><mi>A</mi></msub></msup></math></span> is an upper bound on the size of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>.</p>
<p id="p-52"><b>MOLP CEG (<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>):</b> It is not easy to directly see the solution of the MOLP on our running example. However, we can represent the MOLP bound as the cost of minimum-weight <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><mi>Q</mi><mo>)</mo></mrow></math></span> path in a CEG we call <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>.</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-53"><i>Vertices:</i> For each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>X</mi><mo>⊆</mo><mi>A</mi></mrow></math></span>, the variable <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mi>X</mi></msub></math></span> in MOLP represents an upper bound on the size of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>Q</mi><mi>X</mi></msub><mo>=</mo><msub><mi>Π</mi><mi>X</mi></msub><mi>Q</mi></mrow></math></span>. Therefore, for each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>X</mi><mo>⊆</mo><mi>A</mi></mrow></math></span> there is a vertex in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>.</p>
</li>
<li class="list-item">
<p id="p-54"><i>Extension Edges:</i> For each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>s</mi><mrow><mi>Y</mi><mo>∪</mo><mi>E</mi></mrow></msub><mo>≤</mo><msub><mi>s</mi><mrow><mi>X</mi><mo>∪</mo><mi>E</mi></mrow></msub><mo>+</mo><mo>log</mo><mrow><mo>(</mo><mi>d</mi><mi>e</mi><mi>g</mi><mrow><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>)</mo></mrow></mrow></math></span> inequality, there is an edge with weight <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>log</mo><mo>(</mo><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>,</mo></mrow></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>R</mi><mi>i</mi></msub><mrow><mo>)</mo><mo>)</mo></mrow></mrow></math></span> between any <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>W</mi><mn>1</mn></msub><mo>=</mo><mi>X</mi><mo>∪</mo><mi>E</mi></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>W</mi><mn>2</mn></msub><mo>=</mo><mi>Y</mi><mo>∪</mo><mi>E</mi></mrow></math></span>. These inequalities intuitively indicate the following: Each tuple <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>t</mi><mrow><mi>X</mi><mo>∪</mo><mi>E</mi></mrow></msub><mo>∈</mo><msub><mi>Q</mi><mrow><mi>X</mi><mo>∪</mo><mi>E</mi></mrow></msub></mrow></math></span> can extend to at most <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mi>Y</mi><mo>∪</mo><mi>E</mi></mrow></msub></math></span> tuples.</p>
</li>
<li class="list-item">
<p id="p-55"><i>Projection Edges:</i> For each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>s</mi><mi>X</mi></msub><mo>≤</mo><msub><mi>s</mi><mi>Y</mi></msub></mrow></math></span> inequality (that is, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>∀</mo><mi>X</mi><mo>⊆</mo><mi>Y</mi></mrow></math></span>), add an edge with weight 0 from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Y</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math></span>. These indicate that the size of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mi>X</mi></msub></math></span> is at most the size of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mi>Y</mi></msub></math></span>, if <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Y</mi></math></span> is a larger subquery.</p>
</li>
</ul>
<p id="p-56">Figure <a class="xref xref-fig" href="#F6" data-jats-ref-type="fig" data-jats-rid="F6">6</a> shows the <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span> of our running example. The figure uses actual degrees instead of their logarithms as edge weights and omits the projection edges.</p>
<figure id="F6" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 6. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig06.jpg" alt="" data-image-id="F6" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 6. </span> <span class="p"><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span> for query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>Q</mi><mrow><mn>5</mn><mi>f</mi></mrow></msub></math></span> in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<div id="sta2" class="statement"><b class="statement-label">Theorem 5.1</b></p>
<p id="p-58">Let <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> be a query with degree statistics <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>d</mi><mi>e</mi><mi>g</mi><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></math></span> for each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>R</mi><mi>i</mi></msub></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>X</mi><mo>⊆</mo><mi>Y</mi><mo>⊆</mo><msub><mi>A</mi><mi>i</mi></msub></mrow></math></span>. The optimal solution <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>m</mi><mi>A</mi></msub></math></span> to the MOLP of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> is the weight of the minimum-weight <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><mi>A</mi><mo>)</mo></mrow></math></span> path in CEG<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mrow></mrow><mi>M</mi></msub></math></span>.</p>
</div>
<p id="p-59">Theorem <a class="xref xref-statement" href="#sta2" data-jats-ref-type="statement" data-jats-rid="sta2">5.1</a>’s proof can be found in Chen<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a>. With this connection, readers can verify the MOLP bound in our example by inspecting the paths in Figure <a class="xref xref-fig" href="#F6" data-jats-ref-type="fig" data-jats-rid="F6">6</a>; the minimum-weight <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><mi>A</mi><mo>)</mo></mrow></math></span> path has a weight of 96, corresponding to the leftmost path. We make two observations:</p>
<p id="p-60"><i>Observation 1:</i> Reference<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> proves through a numeric LP-duality argument that <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mn>2</mn><msub><mi>m</mi><mi>A</mi></msub></msup></math></span> is an upper bound on the the output size of the query (<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>O</mi><mi>U</mi><mi>T</mi></mrow></math></span>), i.e., <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>O</mi><mi>U</mi><mi>T</mi></mrow></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>≤</mo></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mn>2</mn><msub><mi>m</mi><mi>A</mi></msub></msup></math></span> (see Prop. 2<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a>). Our CEG formulation of MOLP provides arguably a simpler proof of this property. Note that each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><mi>A</mi><mo>)</mo></mrow></math></span> path in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span> corresponds to a sequence of extensions from <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>∅</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> and is an estimate of the cardinality of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>. Since we are using maximum degrees on the edge weights, each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><mi>A</mi><mo>)</mo></mrow></math></span> path is by construction an upper bound on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>. Since for any (<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>∅</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>) path <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>P</mi></math></span> in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>O</mi><mi>U</mi><mi>T</mi></mrow></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>≤</mo></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mn>2</mn><mrow><mi>w</mi><mo>(</mo><mi>P</mi><mo>)</mo></mrow></msup></math></span> and by Theorem <a class="xref xref-statement" href="#sta2" data-jats-ref-type="statement" data-jats-rid="sta2">5.1</a>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>m</mi><mi>A</mi></msub></math></span> is equal to the weight of the minimum-weight (<span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>∅</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>A</mi></math></span>) path in <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>, then <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>O</mi><mi>U</mi><mi>T</mi></mrow></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>≤</mo></math></span><span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msup><mn>2</mn><msub><mi>m</mi><mi>A</mi></msub></msup></math></span>.</p>
<p id="p-61"><i>Observation 2:</i> Theorem <a class="xref xref-statement" href="#sta2" data-jats-ref-type="statement" data-jats-rid="sta2">5.1</a> implies that MOLP can be solved using a combinatorial shortest-path algorithm instead of a numeric LP solver.</p>
<p id="p-62">In Chen,<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> we also review the CBS pessimistic estimator<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> and show, using CEGs in our proofs, that MOLP is as tight as CBS and is exactly the same as CBS on acyclic join queries over binary relations. Our use of CEGs as mathematical tools in our proofs can be interesting to readers interested in the theory of worst-case bounds on the sizes of join queries. Overall, our results show that CEGs are expressive enough to model two prior pessimistic estimators as well. One benefit of this is we can apply optimizations done in one class of estimators to the other. In the original version of this paper<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a>, we show an example of this by applying an optimization called the <i>bound sketch</i> optimization developed for the CBS estimator also to the optimistic estimators.</p>
</section>
</section>
<section id="sec8" class="sec">
<h2 class="heading"><span class="caption-label">6. </span>Evaluation</h2>
<p id="p-63">Recall that for pessimistic estimators, one should always pick the shortest path on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>, but for optimistic estimators, there is no obvious choice. We next present extensive experiments to evaluate the accuracies of the space of optimistic estimators we described on a large suite of datasets and workloads, so we can provide an advice based on an empirical justification. Our code, datasets, and queries are available here.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> We note that the evaluation we make here is based on subgraph queries, which are equivalent to join queries over binary relations. Recall that this is because prior optimistic estimators were developed in this context. As a result, we note that the advice we give applies to this context. Using CEG-based optimistic estimators for queries over arbitrary relations is not in the scope of this paper.</p>
<p id="p-64">Our original publication<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> contains many more experiments than what is shown here, including a comparison of optimistic and pessimistic estimators (optimistic ones are much more accurate), impacts on the plan quality of using the optimistic estimators we advise on the RDF-3X system, scalability of Markov Tables and CEGs as the size of the patterns increase, and a detailed demonstration of applying the bound sketch optimization of pessimistic estimator to optimistic estimators.</p>
<section id="sec9" class="sec">
<h3 class="heading"><span class="caption-label">6.1 </span>Set-up, datasets, and workloads.</h3>
<p id="p-65">For all our experiments, we use a single machine with two Intel E5-2670 at 2.6GHz CPUs, each with eight physical and 16 logical cores, and 512GB of RAM. We used a total of six real-world datasets, shown in Table <a class="xref xref-table" href="#T2" data-jats-ref-type="table" data-jats-rid="T2">2</a>, and six workloads on these datasets. Our dataset and workload combinations are as follows.</p>
<figure id="T2" class="table-wrap" data-jats-position="float">
<div class="caption"><span class="caption-label">Table 2. </span><span class="p">Dataset descriptions.</span></div>
<div class="table-container">
<table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows">
<colgroup>
<col align="center" valign="top" />
<col align="center" valign="top" />
<col align="center" valign="top" />
<col align="center" valign="top" />
<col align="center" valign="top" /></colgroup>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Domain</th>
<th style="text-align: center;">|V|</th>
<th style="text-align: center;">|E|</th>
<th style="text-align: center;">|E. Labels|</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">IMDb</td>
<td style="text-align: center;">Movies</td>
<td style="text-align: center;">27M</td>
<td style="text-align: center;">65M</td>
<td style="text-align: center;">127</td>
</tr>
<tr>
<td style="text-align: center;">YAGO</td>
<td style="text-align: center;">Knowledge Graph</td>
<td style="text-align: center;">13M</td>
<td style="text-align: center;">16M</td>
<td style="text-align: center;">91</td>
</tr>
<tr>
<td style="text-align: center;">DBLP</td>
<td style="text-align: center;">Citations</td>
<td style="text-align: center;">23M</td>
<td style="text-align: center;">56M</td>
<td style="text-align: center;">27</td>
</tr>
<tr>
<td style="text-align: center;">WatDiv</td>
<td style="text-align: center;">Products</td>
<td style="text-align: center;">1M</td>
<td style="text-align: center;">11M</td>
<td style="text-align: center;">86</td>
</tr>
<tr>
<td style="text-align: center;">Hetionet</td>
<td style="text-align: center;">Social Networks</td>
<td style="text-align: center;">45K</td>
<td style="text-align: center;">2M</td>
<td style="text-align: center;">24</td>
</tr>
<tr>
<td style="text-align: center;">Epinions</td>
<td style="text-align: center;">Consumer Reviews</td>
<td style="text-align: center;">76K</td>
<td style="text-align: center;">509K</td>
<td style="text-align: center;">50</td>
</tr>
</tbody>
</table>
</div>
</figure>
<p id="p-66"><b>IMDb and JOB:</b> The IMDb relational database, together with a workload called JOB (for join order benchmark), has been used for cardinality estimation studies in prior work.<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a> We created property graph versions of the this database and workload. Briefly, the construction is based on converting <i>entity tables</i>, representing actors, movies, and companies as <i>entity nodes</i>, and <i>relationship tables</i> representing many-to-many relationships between the entities as edges. In addition, adding <i>foreign key edges</i> between an entity node <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>u</mi></math></span> to <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> if there is a foreign key in the table <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>u</mi></math></span> comes from to the table that <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> comes from. The final workload contained 369 queries.</p>
<p id="p-68"><b>WatDiv and</b><code class="monospace">WatDiv-Acyclic</code><b>Workload:</b> WatDiv<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> is a synthetic knowledge graph that has its own workload in SPARQL format with 12,400 original queries. We converted these queries into equivalent subgraph queries by removing their vertex predicates and we then removed queries with at most three edges. After removing duplicates among the remaining queries there were 75 different queries left, nine of which is cyclic and the other 64 acyclic. Because nine queries is very small for a workload, we use only the 64 acyclic queries and call this the <code class="monospace">WatDiv-Acyclic</code> workload.</p>
<p id="p-69"><b>YAGO 1 and</b><code class="monospace">G-CARE-Acyclic</code><b>and</b><code class="monospace">G-CARE-Cyclic</code><b>Workloads:</b> G-CARE<a class="reference-link xref xref-bibr" href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a> is a cardinality estimation benchmark for subgraph queries. From this benchmark, we took their YAGO knowledge graph dataset and the acyclic and cyclic query workloads for that dataset. The <code class="monospace">acyclic</code> workload contains 382 queries generated from query templates with 3-, 6-, 9-, and 12-edge star and path queries, as well as randomly generated trees. We will refer to this workload as <code class="monospace">G-CARE-Acyclic</code>. The cyclic query workload contains 240 queries generated from templates with 6-, and 9-edge cycle, 6-edge clique, 6-edge flower, and 6- and 9-edge petal queries. We will refer to this workload as <code class="monospace">G-CARE-Cyclic</code>.</p>
<p id="p-70"><b>DBLP, WatDiv Epinions, Hetionet and</b><code class="monospace">Acyclic</code><b>and</b><code class="monospace">Cyclic</code><b>Workloads:</b> We used three other datasets: Hetionet, a biological network; DBLP, a real knowledge graph; and Epinions, a real-world social network graph. Epinions is a dataset that by default does not have any edge labels. We added a random set of 50 edge labels to Epinions. For these datasets, we created one acyclic and one cyclic query workload, which we refer to as <code class="monospace">Acyclic</code> and <code class="monospace">Cyclic</code>. The <code class="monospace">Acyclic</code> workload contains queries generated from 6-, 7-, or 8-edge templates, shown in Figure <a class="xref xref-fig" href="#F7" data-jats-ref-type="fig" data-jats-rid="F7">7</a>. Then, we generated 20 non-empty instances of each template by putting one edge label uniformly at random on each edge, which yielded 360 queries in total. The <code class="monospace">Cyclic</code> workload contains queries generated from templates used in Mhedhbi and Salihoglu.<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> We generated instances of these queries by randomly matching each edge of the query template one at a time in the datasets. Because the WatDiv’s original queries contained only acyclic queries, we used the <code class="monospace">Cyclic</code> workload also on WatDiv. We generated 70 queries for DBLP, 212 queries for Hetionet, 129 queries for WatDiv, and 394 queries for Epinions.</p>
<figure id="F7" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 7. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig07.jpg" alt="" data-image-id="F7" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 7. </span> <span class="p">Query templates for the <code class="monospace">Acyclic</code> workload. Edge directions are omitted in the figure.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
</section>
<section id="sec10" class="sec">
<h3 class="heading"><span class="caption-label">6.2 </span>Space of optimistic estimators.</h3>
<p id="p-72">We begin by comparing our nine optimistic estimators on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>, we defined. To set up an experiment in which we could test all nine of the possible optimistic estimators, we used a Markov table with h=3. A Markov table with only 2-size joins cannot test different estimators based on different path-length choices or any cyclic query.</p>
<p id="p-73">To compare the accuracies of different estimators, for each query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> in our workloads, we make an estimate using each estimator and compute its q-error. If the true cardinality of <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>c</mi></math></span> and the estimate is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>e</mi></math></span>, then the q-error is <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>max</mo><mo>{</mo><mfrac><mi>c</mi><mi>e</mi></mfrac><mo>,</mo><mfrac><mi>e</mi><mi>c</mi></mfrac><mo>}</mo><mo>≥</mo><mn>1</mn></mrow></math></span>. For each workload, this gives us a distribution of q-errors, which we compare as follows. First, we take the logs of the q-errors so they are now <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>≥</mo><mn>0</mn></mrow></math></span>. If a q-error was an underestimate, we put a negative sign to it. This allows us to order the estimates from the least accurate underestimation to the least accurate overestimation. We then generate a box plot where the box represents the 25<sup>th</sup> (median) and 75<sup>th</sup> percentile cut-off marks. We also compute the mean of this distribution, excluding the top 10% of the distribution (ignoring under/overestimations) and draw it with a red dashed line in box plots.</p>
<section id="sec11" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Acyclic queries and cyclic queries with only triangles.</strong>  Our first question is: Which of the nine possible optimistic estimators leads to the most accurate estimates on acyclic queries and cyclic queries that contain <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mo>≤</mo></math></span>3 edges on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>? We compare our nine estimators on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for each acyclic query workload in our setup (for IMDb, WatDiv, and YAGO, using JOB, <code class="monospace">WatDiv-Acyclic</code>, and <code class="monospace">G-CARE-Acyclic</code> workloads). We then compare our nine estimators on each cyclic query workload using the queries that only contain triangles as cycles. We omit <code class="monospace">GCARE-Cyclic</code> because every query in <code class="monospace">GCARE-Cyclic</code> except for one contained cycles with more than three edges.</p>
<p id="p-75">Our results are shown in Figure <a class="xref xref-fig" href="#F8" data-jats-ref-type="fig" data-jats-rid="F8">8</a>. We make several observations. First, regardless of the path-length choice, the <code class="monospace">max</code> aggregator (the last three box plots in the figures) makes significantly more accurate estimates (note that the y-axis on the plots is in log scale) than <code class="monospace">avg</code>, which in turn is more accurate than <code class="monospace">min</code>. This is true across all acyclic experiments and all datasets. For example, on IMDb and <code class="monospace">JOB</code> workload, the <code class="monospace">all-hops-min</code>, <code class="monospace">all-hops-avg</code>, and <code class="monospace">all-hops-max</code> estimators have a log of mean q-errors of 6.5 (underestimation), 1.7 (underestimation), and 1.02 (understimation), respectively. <i>Therefore on acyclic queries, when there are multiple formulas that can be used to make an estimate, using the pessimistic ones is an effective technique to combat the well-known underestimation problem for estimators that make uniformity and independence assumptions.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a></i> This can give up to three orders of magnitude lower mean q-errors than, for example, the <code class="monospace">min-hop-min</code> estimator from prior work.</p>
<figure id="F8" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 8. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig08.jpg" alt="" data-image-id="F8" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 8. </span> <span class="p">Evaluation of the optimistic estimators on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> on acyclic queries. Estimators are labeled “P-A”; P is the path length (one of <u>max</u>-hop, <u>min</u>-hop, or <u>all</u>-hops) and A the aggregator (one of <u>max</u>-aggr, <u>min</u>-aggr, or <u>avg</u>-aggr).</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-77">We next analyze the effects of path-length choices. Observe that across all experiments, if we ignore the outliers and focus on the 25-75 percentile boxes, <code class="monospace">max-hop</code> and <code class="monospace">all-hops</code> do at least as well as <code class="monospace">min-hop</code>. Further observe that on IMDb, Hetionet, and on the <code class="monospace">Acyclic</code> workload on Epinions, <code class="monospace">max-hop</code> and <code class="monospace">all-hops</code> lead to significantly more accurate estimates. Finally, the performance of <code class="monospace">max-hop</code> and <code class="monospace">all-hops</code> are comparable across our experiments. We verified that this is because <code class="monospace">all-hops</code> picks one of the <code class="monospace">max-hop</code> paths in majority of the queries in our workloads. Therefore, we observe that the advantage of long-hop paths that condition on 2-size joins when making uniformity assumptions is generally stronger than its disadvantage of making more independence assumptions. Since <code class="monospace">max-hop</code> enumerates strictly fewer paths than <code class="monospace">all-hops</code> to make an estimate, we conclude that on acyclic queries, systems implementing the optimistic estimators can prefer the <code class="monospace">max-hop-max</code> estimator.</p>
<p id="p-78">Figure <a class="xref xref-fig" href="#F9" data-jats-ref-type="fig" data-jats-rid="F9">9</a> shows the accuracies of the nine estimators on cyclic query workloads with only triangles. Our observations are similar to those for acyclic queries, and we find that the <code class="monospace">max</code> aggregator yields more accurate estimates than other aggregators, irrespective of the path length. When using the max aggregator, we also observe that <code class="monospace">max-hop</code> performs at least as well as <code class="monospace">min-hop</code>. Therefore, as we observed for acyclic queries, <i>we find</i> <code class="monospace">max-hop-max</code> <i>estimator to be an effective way to make accurate estimations for cyclic queries with only triangles.</i></p>
<figure id="F9" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 9. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig09.jpg" alt="" data-image-id="F9" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 9. </span> <span class="p">Evaluation of the space of optimistic estimators on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> on <code class="monospace">Cyclic</code> workload on queries with only triangles.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<figure id="F10" class="fig">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 10. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig10.jpg" alt="" data-image-id="F10" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 10. </span> <span class="p">Accuracy of <code class="monospace">max-max</code> for different query sizes (x-axis). The number on top of boxplots is the number of queries in the boxplot.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
</section>
<section id="sec12" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Cyclic queries with cycles of size&gt;3.</strong>  Recall our observation that on queries that contain large cycles, existing optimistic estimators estimate paths instead of cycles, which could yield highly inaccurate overestimates, as real-world graphs contain many more paths than cycles. Therefore, unlike the case for acyclic queries and queries with small cycles, we now expect that estimates based on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> will be pessimistic. To verify this hypothesis, our next experiments compare the performance of optimistic estimators for each dataset-cyclic query workload combination, but only using queries that contain cycles of size <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>&gt;</mo><mn>3</mn></mrow></math></span>.</p>
<p id="p-82">Figure <a class="xref xref-fig" href="#F11" data-jats-ref-type="fig" data-jats-rid="F11">11</a> shows our results. As we expected, we now see that the optimistic estimators yield overestimates for the majority of the queries. This can be seen by observing that except for a few exceptions, the 25-75 percentile boxes of the boxplots are above 0. In addition, estimators using the <code class="monospace">min</code> aggregator are generally more accurate, sometimes with several orders of magnitude difference, which can be seen by observing the mean accuracy lines of the boxplots. For example, on YAGO, the mean accuracy lines of <code class="monospace">max-hop-min</code> and <code class="monospace">max-hop-max</code> are, respectively, 0.20 and 3.61 on logarithmic scale, which correspond to absolute q-errors of 1.58 (overestimation) and 4043.86 (overestimation). We also observe that there is less sensitivity to the path-length choice when using the <code class="monospace">min</code> aggregator, and any of the path-length choices perform reasonably well.</p>
<figure id="F11" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 11. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3780104_fig11.jpg" alt="" data-image-id="F11" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 11. </span> <span class="p">Evaluation of optimistic estimators on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> on cyclic queries with cycles of four or more edges.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-84">As we discuss in Section <a class="xref xref-sec" href="#sec14" data-jats-ref-type="sec" data-jats-rid="sec14">8</a>, we hope CEGs can be the foundation for proposing other estimators for future work. As a demonstration of the flexibility of our CEG-framework to design new CEG-based estimators, in the original version of our paper,<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> we present one possible approach (though others can be proposed) to remedy the overestimates of the estimators on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for queries with large cycle queries. Specifically, we describe a new CEG, that modifies <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> with new edge weights that incorporate a cycle-closing effect and show that estimates on this new CEG can be more accurate than those on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span>.</p>
</section>
</section>
</section>
<section id="sec13" class="sec">
<h2 class="heading"><span class="caption-label">7. </span>Related Work</h2>
<p id="p-85">There is decades of extensive research on cardinality estimation techniques that can be used for estimating sizes of join queries. This literature has proposed several different classes of estimators, including other summary-based ones, as well as sampling-based ones and novel machine learning-based ones. Sampling-based estimators<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> sample input records from base tables and evaluate queries on these samples to make estimates. Sampling-based estimators are fundamentally different than summary-based ones as by increasing the sizes of the samples they can be arbitrarily accurate, while summary-based ones can be more accurate by keeping more statistics. Another class of estimators on which there is active work is machine-learning-based ones that learn to make estimates from example queries or predicates, e.g., example range predicates on columns.<a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a> Studying how all these estimators compare is beyond the scope of this work. In the following, we cover other summary-based estimators primarily focusing on graph-based database management systems.</p>
<p id="p-86">Many relational systems, including commercial ones such as PostgreSQL, use summary-based estimators. Example summaries include the cardinalities of relations, the number of distinct values in columns, or histograms,<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> wavelets,<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a> or probabilistic and statistical models<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> that capture the distribution of values in columns. These statistics are used to estimate the selectivities of each join predicate, which are put together using several approaches, such as independence assumptions. In contrast, the estimators we studied store degree statistics about base relations and small-size joins (note that cardinalities are a form of degree statistics, for example, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mrow><mo>|</mo></mrow><msub><mi>R</mi><mi>i</mi></msub><mrow><mo>|</mo><mo>=</mo><mi>d</mi><mi>e</mi><mi>g</mi></mrow><mrow><mo>(</mo><mi>∅</mi><mo>,</mo><msub><mi>R</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></math></span>).</p>
<p id="p-87">Characteristic Sets (CS)<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> is a summary-based estimator primarily designed to estimate the cardinalities of stars in an RDF graph. It uses the so-called <i>characteristic set</i> of each vertex <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> in an RDF graph, which is the set of distinct outgoing labels <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>v</mi></math></span> has. CS keeps statistics about the vertices with the same characteristic set. Then, using these statistics, CS makes estimates for the sizes of star queries. For a non-star query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> is decomposed into multiple stars <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>s</mi><mi>k</mi></msub></mrow></math></span> in a greedy manner, by removing the largest stars first, and the estimates for each <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>s</mi><mi>i</mi></msub></math></span> is multiplied. However, unlike the optimistic estimators we considered, this decomposition procedure does not lead to multiple possible decompositions.</p>
<p id="p-88">Several works have proposed summary-based estimators that compute a sketch of an input graph. SumRDF<a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a> builds a summary graph <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span> of an RDF graph and adopts a holistic approach to make an estimate. Given the summary <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span>, SumRDF considers all possible RDF graphs <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>G</mi></math></span> that could have the same summary <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span>. In the context of estimating the selectivities of path expressions XSeed<a class="reference-link xref xref-bibr" href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> builds a sketch <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span> of the input XML Document. The sketch of the graph effectively collapses multiple nodes and edges into supernodes and edges with statistics on them. Then given a query <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span>, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>Q</mi></math></span> is matched on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span> and using the metadata, an estimate is made. Unlike CEGs, these techniques do not decompose a query into smaller sub-queries, so the question of which decomposition to use does not arise for these estimators.</p>
<p id="p-89">Similarly, several work use data structures that are adaptations of histograms from relational systems to store selectivities of paths or trees in XML documents, such as <i>positional histograms</i>.<a class="reference-link xref xref-bibr" href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> Such techniques do not consecutively make estimates for larger paths and have not been adopted to general subgraph queries.</p>
</section>
<section id="sec14" class="sec">
<h2 class="heading"><span class="caption-label">8. </span>Limitations, Conclusions, and Future Work</h2>
<p id="p-90">Aside from capturing existing optimistic and pessimistic estimators, we believe the CEG framework can be the foundation to develop novel summary-based estimators. In addition to the two CEGs we considered here, <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> and <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>M</mi></msub></mrow></math></span>, other CEGs using different statistics can be defined and paired with different techniques to pick paths. To demonstrate an example, in the original version of this paper,<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> we describe another CEG we call <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mrow><mi>O</mi><mi>C</mi><mi>R</mi></mrow></msub></mrow></math></span> as a possible approach to remedy the overestimation problem of optimistic estimator on <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mi>O</mi></msub></mrow></math></span> for queries with large cycles. <span class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>C</mi><mi>E</mi><msub><mi>G</mi><mrow><mi>O</mi><mi>C</mi><mi>R</mi></mrow></msub></mrow></math></span> uses new edge weights that capture the closing of large cycles between sub-queries.</p>
<p id="p-91">Perhaps the most important research question our work leaves unanswered is: which CEG should be used in practice? This is a very broad question and it is easy to define many other CEGs and our understanding of which ones would yield to better accuracy is limited. For example, one can use variances or entropies of the distributions of small-size joins as edge weights, possibly along with degree statistics, and pick the lowest entropy paths. An important research direction is to systematically study a class of CEG instances that use different combination of statistics as edge weights, as well as techniques for picking paths, to design more accurate CEG-based estimators. In addition, in this work, we focused only on join-only queries and ignore other non-join predicates. An additional future work direction is to develop principled mechanisms to integrate filters on the queries that can be estimated using CEG.</p>
</section>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/research-highlights/cardinality-estimation-graphs/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Jeremy Chen]]></dc:creator>
      <dc:creator><![CDATA[Yuqing Huang]]></dc:creator>
      <dc:creator><![CDATA[Mushi Wang]]></dc:creator>
      <dc:creator><![CDATA[Ken Salem]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">776399</post-id>	</item>
		<item>
		<title>Technical Perspective: Perspective on Cardinality Estimation Graphs</title>
		<link>https://cacm.acm.org/research-highlights/technical-perspective-perspective-on-cardinality-estimation-graphs/</link>
					<comments>https://cacm.acm.org/research-highlights/technical-perspective-perspective-on-cardinality-estimation-graphs/#respond</comments>
		
		<dc:creator><![CDATA[Dan Suciu]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 15:46:29 +0000</pubDate>
				<category><![CDATA[Architecture and Hardware]]></category>
		<category><![CDATA[Data and Information]]></category>
		<category><![CDATA[Theory]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776498</guid>

					<description><![CDATA[<p>Using a CEG can help explain and compare the various cardinality estimators described in the literature, opening up the possibility for designing new estimators.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Query engines are really good at choosing an efficient query plan. Users do not need to worry about how they write their query, since the optimizer makes all the right choices for executing the query while taking into account all aspects of data, such as its size, the characteristics of the storage device, the distribution pattern, the availability of indexes, and so on. The query optimizer always makes the best choice, no matter how complex the query is or how contrived it was written. Or, this is what we expect today from a modern query optimizer. Unfortunately, reality is not as nice.</p>
<p id="p-2">The problem is that query optimizers have an Achilles’ heel: cardinality estimation. To choose an optimal query execution plan, they need to search over many alternative plans and evaluate their cost; and to evaluate their cost, the optimizer needs to estimate the number of tuples that will result for each subexpression of the query. If they estimate the number of tuples incorrectly, then their cost estimate is wrong, and they end up choosing an inefficient query plan. When query optimizers fail to choose the best execution plan, it is almost always because they were informed incorrectly by the cardinality estimator.</p>
<p id="p-3">The cardinality estimation problem is easy to state: Given a query, estimate the cardinality of its answer without evaluating the query. Typically, the query is restricted to selection and join operators, since other relational operators (group by, duplicate elimination, union, and so on) are usually pushed to the top of the query plan. To perform cardinality estimation, the system computes offline some statistics on each base table, then uses them at optimization time to estimate the cardinality of various query expressions. There are two major challenges. First, there is a very limited space budget for what statistics we can precompute and store, because all statistics must be kept in main memory during query optimization. Production databases often have hundreds of tables, some with hundreds of attributes; hence, we can afford to store only very little information about each table and each attribute. Second, cardinality estimation must be very fast, because it is in the inner loop of the query optimizer, which needs to invoke the estimator thousands of times during optimization. Disk accesses, or solving complex optimization problems are ruled out: Cardinality estimation must be simple and efficient.</p>
<p id="p-4">The accompanying paper, “Cardinality Estimation Graphs,” by Chen et al. presents a unified framework that captures the most common approaches to cardinality estimation: those based on summary statistics (as opposed to samples) and those based on average or maximum degree (which includes all estimators I am aware of). There are two separate tasks in cardinality estimation, which are often studied separately: selectivity estimation of predicates on the base tables, and the cardinality estimation of a multi-join query. The paper studies the second task exclusively.</p>
<p id="p-5">A cardinality estimate of a multi-join query relies on average degrees. Consider estimating the size of a join, <span id="IEq1" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>R</mi><mo>(</mo><mi>A</mi><mo>,</mo><mi>B</mi><mo>)</mo><mo>⨝</mo><mi>S</mi><mo>(</mo><mi>B</mi><mo>,</mo><mi>C</mi><mo>)</mo></mrow></math></span>. A reasonable estimate is the cardinality of <span id="IEq2" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>R</mi></math></span> times the average degree of the attribute <span id="IEq3" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>S</mi><mo>.</mo><mi>B</mi></mrow></math></span>; for example, if each value of <span id="IEq4" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>B</mi></math></span> occurs five times in <span id="IEq5" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span>, then our estimate is five times <span id="IEq6" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>|</mo><mi>R</mi><mo>|</mo></mrow></math></span>. But we can also switch the roles of <span id="IEq7" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>R</mi></math></span> and <span id="IEq8" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>S</mi></math></span> and use as an estimate <span id="IEq9" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>|</mo><mi>S</mi><mo>|</mo></mrow></math></span> times the average degree of <span id="IEq10" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mi>R</mi><mo>.</mo><mi>B</mi></mrow></math></span>. This presents a problem: Which estimate should we use? Database systems choose the smallest of these two, and this leads to the classic textbook formula we like to teach in undergraduate classes: <span id="IEq11" class="inline-formula"><math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mrow><mo>|</mo><mi>R</mi><mo>⨝</mo><mi>S</mi><mo>|</mo><mo>=</mo><mo>|</mo><mi>R</mi><mo>|</mo><mo>·</mo><mo>|</mo><mi>S</mi><mo>|</mo><mo>/</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mi>d</mi><mi>o</mi><mi>m</mi><mo>(</mo><mi>R</mi><mo>.</mo><mi>B</mi><mo>)</mo><mo>,</mo><mi>d</mi><mi>o</mi><mi>m</mi><mo>(</mo><mi>S</mi><mo>.</mo><mi>B</mi><mo>)</mo><mo>)</mo></mrow><mo>.</mo></math></span></p>
<p id="p-6">It becomes clear that, for an <i>n</i>-way join query, the number of choices becomes very large, and it is unclear which one to use as an estimate. The paper introduces a simple abstraction, called the cardinality estimation graph (CEG), where each path represents one possible choice for the cardinality estimator. Using a CEG, the paper can explain and compare the various cardinality estimators described in the literature, opening up the possibility for designing new estimators.</p>
<p id="p-7">A recently proposed alternative to computing a cardinality estimate is to compute an upper bound. This approach is called a pessimistic cardinality estimate (with some abuse, since it is not an estimate but a guaranteed upper bound). The definitive mathematical formula for the upper bound of a multi-join query is known but impractical, and the few implementations of pessimistic estimates use relaxations of this formula. The paper shows that the same CEG abstraction can also be used to explain these pessimistic cardinality estimates by simply replacing the average degree with a maximum degree.</p>
<p id="p-8">Readers with little knowledge of cardinality estimation will hopefully find the CEGs a convenient, quick introduction to various cardinality estimation methods. Experts will find the CEG a convenient abstraction for comparing various estimators. And systems builders may find the experimental section a useful guide in making choices for their own cardinality estimator.</p>
<p id="p-9"><i>This Technical Perspective first appeared in the ACM SIGMOD Record, Vol. 52, Issue 1, June 2023.</i></p>
</section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/research-highlights/technical-perspective-perspective-on-cardinality-estimation-graphs/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">776498</post-id>	</item>
		<item>
		<title>Does AI Now Represent a Paradigm Shift?</title>
		<link>https://cacm.acm.org/opinion/does-ai-now-represent-a-paradigm-shift/</link>
					<comments>https://cacm.acm.org/opinion/does-ai-now-represent-a-paradigm-shift/#respond</comments>
		
		<dc:creator><![CDATA[Vinton G. Cerf]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 15:25:14 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[Software Engineering and Programming Languages]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776458</guid>

					<description><![CDATA[<p>The arrival of usefully applicable AI could create new disciplines using sophisticated, specialized models as tools for work.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">The term artificial intelligence (AI) was coined by John McCarthy in 1955 in preparation for a group meeting at Dartmouth College in 1956 on “the science and engineering of making intelligent machines.” Of course, speculation on computing and intelligence preceded that meeting. In a famous 1950 paper on “Computing Machinery and Intelligence,”<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a> Alan M. Turing asked the question, “Can machines think?” Even earlier work in the 1940s examined artificial neural networks as mechanisms for learning. We have come a very long way from those early days; today, massive, multilayer neural networks allow us to explore wide-ranging notions of AI.</p>
<p id="p-2">If <i>paradigm shift</i> can be interpreted as “changing the way things are done,” it might be arguable that we are well into a paradigm shift with the arrival of usefully applicable AI. Machine learning (ML) has already proven its worth using stable statistics to train multilayer neural networks. Examples that come to my mind include weather prediction, protein-folding shape prediction, datacenter cooling control, and fusion plasma stability control, among others. With the development of large language models (LLMs), we are seeing ever more rich utility, tinged perhaps with erroneous <i>hallucinations</i>, despite which, the outputs are proving to be very useful in many ways. Programming (coding) is one example, although such outputs deserve considerable scrutiny as to their accuracy and safety. The vast amount of information encoded in these models and the capacity of the models to generate useful and apparently comprehensive output sets the stage for what I think can reasonably be called a paradigm shift. I believe these models have already started to change the way we work. The main point I want to make is that the generality of these super-large models, the remarkable quantity of retrievable detail, and the capacity of these systems to synthesize responses to sophisticated requests represents a watershed moment in computing.</p>
<p id="p-3">I find it interesting that so-called <i>vibe coding</i>, in which a programmer successively iterates with an LLM using natural descriptive language to cause it to generate a program satisfying the programmer’s intent, is becoming a popular way to produce software. Depending on the purpose of the software, varying degrees of scrutiny are advisable before relying on the software to satisfy any particular function. In a low-risk application, for example, software for generation of a poem or perhaps images for slides, scrutiny might be lightweight—except perhaps for the detection of copyright infringement. In high-risk applications, such as investment transaction advice or medical diagnosis and treatment, much more scrutiny might be advisable.</p>
<p id="p-4">Out of curiosity, I asked Google’s Gemini 3 model whether LLMs represented a paradigm shift. Gemini made these observations:</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Summary of the Shift</h2>
<figure id="UT1" class="table-wrap">
<div class="table-container">
<table class="table table-bordered table-condensed table-hover" data-jats-frame="hsides" data-jats-rules="rows">
<colgroup>
<col align="left" valign="top" />
<col align="left" valign="top" />
<col align="left" valign="top" /> </colgroup>
<thead style="vertical-align: bottom;">
<tr>
<th style="text-align: left;">Feature</th>
<th style="text-align: left;">Traditional Computing</th>
<th style="text-align: left;">LLM Computing (2025)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><b>Logic</b></td>
<td style="text-align: left;">Boolean / Deterministic</td>
<td style="text-align: left;">Probabilistic / Statistical</td>
</tr>
<tr>
<td style="text-align: left;"><b>Input</b></td>
<td style="text-align: left;">Structured Data / Code</td>
<td style="text-align: left;">Natural Language / Multimodal</td>
</tr>
<tr>
<td style="text-align: left;"><b>Instruction</b></td>
<td style="text-align: left;">Explicit Programming</td>
<td style="text-align: left;">Prompting / Fine-tuning</td>
</tr>
<tr>
<td style="text-align: left;"><b>Outcome</b></td>
<td style="text-align: left;">Predictable / Repeatable</td>
<td style="text-align: left;">Emergent / Generative</td>
</tr>
</tbody>
</table>
</div>
</figure>
<p id="p-5">Given the remarkable scope of these models, it seems reasonable to imagine that some models might be specialized to check for errors in the output of other models. One could imagine training a model on software with identified bugs to increase the likelihood that mistakes could be detected. I suppose one could go so far as to train against known malware to increase the likelihood that functional pollution is detected. It strikes me as plausible that this paradigm shift will create new disciplines using these sophisticated, specialized models as tools for work. Just as <i>webmasters</i> grew out of the early World Wide Web, <i>prompt engineering</i> and other disciplines will emerge from the rapid evolution and proliferation of purpose-developed models.</p>
<p id="p-6">It is also foreseeable that specialized training will lead to the use of these models in a very broad range of applications. Just as work in mechanical disciplines (e.g., plumbing) is vastly enabled by having the right tools, this will surely be the case for specialized AI models. At Google DeepMind, the exploration of tools for creating tools using AlphaEvolve, is well underway. Along with this proliferation, there will be questions about the reliability of the output from these tools. Experience will eventually lead to better assessments of the risks of their use. The need for insurance or waivers of liability may manifest as these sophisticated tools are applied in an infinite variety of ways. New uses of tools intended for other purposes may well be discovered—something we have experienced in the past, for example a drug intended for one purpose is discovered to have beneficial effects for a different condition.</p>
<p id="p-7">Welcome to paradigm shift, 2026!</p>
</section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/does-ai-now-represent-a-paradigm-shift/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">776458</post-id>	</item>
		<item>
		<title>Memory Safety for Skeptics</title>
		<link>https://cacm.acm.org/practice/memory-safety-for-skeptics/</link>
					<comments>https://cacm.acm.org/practice/memory-safety-for-skeptics/#respond</comments>
		
		<dc:creator><![CDATA[Andrew Lilley Brinker]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 15:20:25 +0000</pubDate>
				<category><![CDATA[Security and Privacy]]></category>
		<category><![CDATA[Software Engineering and Programming Languages]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776447</guid>

					<description><![CDATA[<p id="p-10">Pursuing memory safety in legacy systems is worthwhile, with or without Rust.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Memory safety—the property that makes software devoid of weaknesses such as buffer overflows, double-frees, and similar issues—has been a popular topic in software communities over the past decade and has gained special prominence alongside the rise of the <a class="ext-link" href="https://www.rust-lang.org/" data-jats-ext-link-type="uri">Rust programming language</a>.<a class="footnote-link xref xref-fn" href="#fn1" data-jats-ref-type="fn" data-jats-rid="fn1"><sup>a</sup></a> Rust did not invent the idea of memory safety, nor was it the first memory-safe language, but it did break the dam on the last major holdout context where memory safety had not yet been achieved: what we often call <i>systems programming</i>.</p>
<p id="p-2">Rust’s big step function was to offer memory safety at compile time through the use of static analysis borrowed and grown out of prior efforts such as <a class="ext-link" href="https://cyclone.thelanguage.org/" data-jats-ext-link-type="uri">Cyclone</a>,<a class="footnote-link xref xref-fn" href="#fn2" data-jats-ref-type="fn" data-jats-rid="fn2"><sup>b</sup></a> a research programming language formulated as a safe subset of C. Rust, by offering a memory-safe-by-default experience for the <i>systems</i> domain, where operating systems, databases, file systems, embedded software, and the like are made, suddenly presented a new possibility to public policymakers and to leaders of engineering organizations: the mass reduction of memory unsafety across any domain.</p>
<p id="p-3">In the years since Rust hit the scene, tech companies have published experience reports on the adoption of Rust for production systems, whether through rewrites of existing code or by producing new modules in Rust that might have otherwise been written in C or C++. The numbers were broadly consistent: a roughly <a class="ext-link" href="https://www.memorysafety.org/docs/memory-safety/#how-common-are-memory-safety-vulnerabilities" data-jats-ext-link-type="uri">70% reduction</a><a class="footnote-link xref xref-fn" href="#fn3" data-jats-ref-type="fn" data-jats-rid="fn3"><sup>c</sup></a> in memory-safety vulnerabilities. Rust, more than just promising memory safety, was demonstrably translating safety guarantees into practical improvements in software security. This evidence, turning the abstract benefits of a semantic improvement into bottom-line improvements in business costs (vulnerabilities are <i>expensive</i> for all involved), meant that organizations beyond just engineering groups began to take notice.</p>
<p id="p-4">Of course, the choice of programming language is a contentious one. Languages do not exist in a vacuum, and the <i>right</i> language for a job is heavily path dependent. What languages do the developers already know? What is the timeline and budget for the project? How serious are the correctness constraints? The performance constraints? Do you expect to hire more developers, and what resources can you allocate to train them? If you are maintaining an open source project, you might ask which languages would possibly bring in more developers to contribute. For any project, your answer might be determined by what other libraries or tools you will need to integrate.</p>
<p id="p-5">What’s more, many projects have already made their programming-language decision years ago—possibly decades ago. What should they do? If the code you have today is memory unsafe, in C or C++, how can you pursue safety without throwing the whole thing out?</p>
<p id="p-6">In some circles, the answer given might be to rewrite it in Rust to replace legacy software written in memory-unsafe languages with new Rust equivalents. The benefits, supporters argue, are clear: comparable performance, modern tooling, and memory safety.</p>
<p id="p-7">Yet, experienced developers know <a class="ext-link" href="https://blog.developer.adobe.com/we-decided-to-rewrite-our-software-you-wont-believe-what-happened-next-dd03574f6654" data-jats-ext-link-type="uri">rewrites are expensive</a><a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> and frequently misguided. Often, demands for large-scale rewrites are not a carefully reasoned argument about trade-offs, but an aesthetic criticism of code that looks &#8216;ugly&#8217; or &#8216;too old.&#8217; If anything, those calling for mass rewrites show their own inability to do the difficult work of understanding and working with an existing codebase that does a job and does it well.</p>
<p id="p-8">There are paths between accepting memory unsafety as the cost of doing business or performing a mass rewriting of stable systems in a new language to achieve safety. Reflexive rejection of a move to memory safety is misguided, especially when the benefits of memory safety can be achieved in a cost- and schedule-efficient way.</p>
<p id="p-9">If you are not yet sold on the value of memory safety, this article is for you. The goal in writing it is to treat the question of pursuing memory safety in legacy systems with the seriousness and rigor it deserves.</p>
<p id="p-10">Pursuing memory safety is worthwhile, with or without Rust, and I’d like to convince you to try.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">In Budget, On Schedule</h2>
<p id="p-11">Software systems do not exist in isolation; software is built to <i>do things</i>, to serve the needs of businesses and individuals by making systems more efficient or automatic. The development of software is constrained not by the theoretical limits of software’s abilities, but by the cost and schedule limitations of the team building it.</p>
<p id="p-12">In <a class="ext-link" href="https://www.cisa.gov/resources-tools/resources/case-memory-safe-roadmaps" data-jats-ext-link-type="uri">“The Case for Memory Safe Roadmaps,”</a><a class="footnote-link xref xref-fn" href="#fn4" data-jats-ref-type="fn" data-jats-rid="fn4"><sup>d</sup></a> a collection of government agencies from the “Five Eyes Countries” (the U.S., U.K., Australia, New Zealand, and Canada) collectively recommended that organizations develop roadmaps for transitioning their software development efforts to memory-safe languages.</p>
<p id="p-13">It’s worth being clear here: Their focus is on <i>roadmaps</i>, and they very explicitly accept and discuss the challenge of the cost and schedule impacts of any transition toward memory safety.</p>
<p id="p-14">Budget and schedule constraints and the desire for efficiency are part of what motivates the creation of software in the first place. Once that software is in place, it’s frequently mission critical, having replaced the knowledge and labor of people who would have previously done the jobs the software now performs. Instead of accountants, a company may have accounting <i>software</i>, with a smaller number of accountants who know how to interact with the software and use it to perform their own jobs built on the knowledge the software provides with its data and embedded business logic.</p>
<p id="p-15">Rewrites to critical software systems are risky precisely because the software itself is so important. Rewriting a software system, whether as an in-place rewrite where components are swapped out piece by piece, or as a wholesale rewrite with a cutover date, <a class="ext-link" href="https://www.theverge.com/2025/1/13/24342282/sonos-app-redesign-controversy-full-story" data-jats-ext-link-type="uri">risks the proper functioning</a><a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> of the business if the rewrite fails.</p>
<p id="p-16">Complex, long-running software systems can face other severe constraints as well. They may be unable to be turned off—because, having become so business-critical and time-sensitive, any attempt to bring them offline for maintenance or replacement is unacceptable. They may also have become lost artifacts, where the expertise of the individuals who created them or previously worked on them is lost because it wasn’t transferred to newer engineers, resulting in a current team that does not understand the system or feel comfortable making changes to it.</p>
<p id="p-17">There are also ongoing costs associated with the development of software that might have to be diverted to support even an incremental rewrite. Depending on the business, there might not be funding available to support an <i>increase</i> to the development team, so diversion of resources toward a rewrite would mean reduction in the delivery of features for the project, which may be untenable.</p>
<p id="p-18">All of this is to say that rewrites, even incremental ones, are business decisions that have to be made as trade-offs with other strategic goals. While motivated developers can make the best case possible for the upside of a rewrite, they must also grapple with the businesses’ need to deliver features and address bugs impacting users of the system today.</p>
<p id="p-19">At the same time, a transition to memory-safe languages can bring benefits beyond just the safety (and thereby security) claims that are often given priority in these discussions.</p>
<p id="p-20">Memory-safety violations, such as null pointer dereferences or indexing outside of the bounds of a memory buffer, can result in denial of service (or, in the context of the classic security CIA triad, availability failures) of the relevant software. This might mean on-call pages to respond to a production incident, a failure to meet service-level agreement guarantees for customers, or reduced revenue from lost customers or interruption of business operations.</p>
<p id="p-21">Memory-safety issues are also often a central building block in a kill chain for achieving remote code execution by attackers. Even as far back as “<a class="ext-link" href="https://archives.phrack.org/issues/49/14.txt" data-jats-ext-link-type="uri">Smashing the Stack for Fun and Profit”</a><a class="footnote-link xref xref-fn" href="#fn5" data-jats-ref-type="fn" data-jats-rid="fn5"><sup>e</sup></a> in 1996, we could see cybersecurity professionals documenting how to turn a buffer-overflow weakness into remote code execution and full access to the host. With that foothold in place, attackers can begin to exfiltrate data, move laterally within a network, escalate privileges, lock down a system with ransomware, conscript a host into a botnet, and more.</p>
<p id="p-22">Software problems are <a class="ext-link" href="https://www.sonatype.com/resources/articles/what-is-shift-left" data-jats-ext-link-type="uri">cheaper to fix the earlier they</a><a class="footnote-link xref xref-fn" href="#fn6" data-jats-ref-type="fn" data-jats-rid="fn6"><sup>f</sup></a> occur in the software development lifecycle. In the long term, stopping a bug from being written is cheaper than responding to a bug bounty submission or triaging a production outage.</p>
<p id="p-23">This is not to say that <i>all</i> moves toward memory safety are cost effective or that all roadmaps for memory safety should be as aggressive as possible, but it is intended to make clear there are both costs and savings to be had with any transition to memory safety.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Setting the Goalposts</h2>
<p id="p-24">What is memory safety? There should be a table-stakes answer to that question to have in hand amid the push toward memory safety in public discourse, but there is not a single, fully agreed-upon, and rigorous definition. There is a new effort, announced in a recent article published in <i>Communications</i>, to develop a standard definition of memory safety, but it is just beginning.</p>
<p id="p-25">There is, however, a rough consensus among practitioners of what kinds of program behaviors are memory <i>unsafe</i>. That’s a good place to start.</p>
<p id="p-26">My favorite short definition <a class="ext-link" href="http://www.pl-enthusiast.net/2014/07/21/memory-safety/" data-jats-ext-link-type="uri">comes from Michael Hicks</a>,<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> an academic who works on programming languages:</p>
<blockquote class="disp-quote">
<p id="p-27">“[A] program execution is memory safe so long as a particular list of bad things, called <a class="ext-link" href="http://dl.acm.org/citation.cfm?id=773473.178446" data-jats-ext-link-type="uri">memory-access errors</a>,<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> never occur:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-28">Buffer overflow</p>
</li>
<li class="list-item">
<p id="p-29">Null pointer dereference</p>
</li>
<li class="list-item">
<p id="p-30">Use after free</p>
</li>
<li class="list-item">
<p id="p-31">Use of uninitialized memory</p>
</li>
<li class="list-item">
<p id="p-32">Illegal free (of an already freed pointer, or a non-<code class="monospace">malloc</code>-ed pointer)”</p>
</li>
</ul>
</blockquote>
<p id="p-33">You will sometimes see these categories broken down further, into spatial and temporal memory safety. <i>Spatial</i> covers memory-safety issues arising from accessing locations in memory that a program should not have access to (like a buffer overflow); <i>temporal</i> covers operations on memory done in the wrong order: for example, reading memory before it is initialized, trying to free an already freed pointer, or using a pointer after it has been freed.</p>
<p id="p-34">There’s also the Common Weakness Enumeration (CWE) category for memory-safety issues, which decomposes Hicks’s list into more granular options. CWE is a taxonomy of software weaknesses, or as CWE puts it: “condition[s] in&#8230; software&#8230; that, under certain circumstances, could contribute to the introduction of vulnerabilities.”</p>
<p id="p-35">In <a class="ext-link" href="https://cwe.mitre.org/data/definitions/1399.html" data-jats-ext-link-type="uri">CWE’s memory-safety category</a>,<a class="footnote-link xref xref-fn" href="#fn7" data-jats-ref-type="fn" data-jats-rid="fn7"><sup>g</sup></a> “buffer overflow” is further broken down into six different, more-specific weaknesses, some of which are further decomposed into their own variants. This can be useful when maximum precision is warranted but is perhaps too much detail for the purposes of this article.</p>
<p id="p-36">These definitions provide a reasonably clear picture of what constitutes memory <i>unsafety</i>. So, memory safety is when a program is guaranteed not to have those weaknesses. This can be achieved by compile-time constraints on the semantics of programs or by runtime management of memory by a garbage collector, so long as the guarantee is upheld.</p>
<p id="p-37">This is often when perceptive onlookers will cry foul. <a class="ext-link" href="https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html" data-jats-ext-link-type="uri">Rust permits unsafety</a>!<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> There’s a whole unsafe keyword! How is that meaningfully different from the guarantees of C or C++?</p>
<p id="p-38">Of course, they are right. Rust does permit programmers to write unsafe code, but as anyone who works in safety or security will tell you, defaults matter. In fact, defaults matter a lot!</p>
<p id="p-39">Take seatbelts, for example. Seatbelts became generally mandatory across the U.S. between the late 1980s to the early 1990s. In 1985, when mandatory seatbelt laws first saw passage among the states, seatbelt usage sat at 21%<a class="footnote-link xref xref-fn" href="#fn8" data-jats-ref-type="fn" data-jats-rid="fn8"><sup>h</sup></a> of riders. In 1994, the average seatbelt usage rate in the U.S. was 58%. As of 2017, it was 89.7%.<a class="footnote-link xref xref-fn" href="#fn9" data-jats-ref-type="fn" data-jats-rid="fn9"><sup>i</sup></a> That change in defaults led to massive increases in seatbelt usage and therefore saved more lives. The National Highway Transportation and Safety Administration estimates that in 2017 alone, <a class="ext-link" href="https://www.nhtsa.gov/vehicle-safety/seat-belts" data-jats-ext-link-type="uri">seatbelts saved the lives of nearly 15,000 Americans</a>.<a class="footnote-link xref xref-fn" href="#fn10" data-jats-ref-type="fn" data-jats-rid="fn10"><sup>j</sup></a></p>
<p id="p-40">The same truth applies in software. Before version 4.0.0 (published in 2017), Redis, the extremely popular key-value store, offered no access controls in its default configuration. Frequently, new users of Redis would unintentionally expose their instance publicly, and this insecurity would result in data spills or become a vector for host exploitation. As of version 4.0.0, Redis enters a “protected mode” when run with its default configuration and without password protection. This limits access to loopback interfaces. As the Redis company itself has since touted, the introduction of protected mode has caused the number of publicly accessible Redis instances tracked on Shodan.io, a popular Internet host aggregator, to decline substantially. In 2017, it had identified roughly 17,000 exposed Redis instances; in 2020, that number had declined to 8,000 in an audit by security company TrendMicro.</p>
<p id="p-41">Bringing it back to memory safety, we can and should think of memory-safety guarantees by languages as a continuum, and we can split languages between “memory safe by default” and “non-memory safe by default” groups. This framing, <a class="ext-link" href="https://memorysafety.openssf.org/memory-safety-continuum/" data-jats-ext-link-type="uri">recommended</a><a class="footnote-link xref xref-fn" href="#fn11" data-jats-ref-type="fn" data-jats-rid="fn11"><sup>k</sup></a> by the Open Source Security Foundation’s (Open SSF&#8217;s) Memory Safety Special Interest Group (SIG), makes the options clearer:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-42">Using memory-safe-by-default languages</p>
</li>
<li class="list-item">
<p id="p-43">Using memory-safe-by-default languages to interface with non-memory-safe-by-default languages</p>
</li>
<li class="list-item">
<p id="p-44">Using non-memory-safe-by-default languages</p>
</li>
</ul>
<p id="p-45">Here, memory-safe-by-default languages include not only Rust but also common garbage-collected languages, such as Java, C#, Go, Swift, Python, and Ruby. Non-memory-safe-by-default languages include C and C++ most notably, but also Zig, which may be surprising to those who have watched memory-safety discussions from the sidelines.</p>
<p id="p-46">While Zig does provide more ergonomic options for programmers to write memory-safe programs themselves, Zig is not a memory-safe language because it does not guarantee memory safety even in its most conservative configuration. <a class="ext-link" href="https://www.scattered-thoughts.net/writing/how-safe-is-zig/" data-jats-ext-link-type="uri">Jamie Brandon’s breakdown of Zig’s memory safety</a><a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> is a good walkthrough of why Zig’s guarantees are insufficient.</p>
<p id="p-47">With a shared understanding of memory safety and memory-safe languages, let’s now dig into the concrete strategies for pursuing memory safety in real-world programs.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Strategies for Safety</h2>
<p id="p-48">Any of the following strategies are intended to maximize the benefit of memory safety while minimizing the cost of pursuing it. The specific choice of which approach is right is context-dependent and should be made with consideration of the importance of the component, the current and new target language, the team involved, and the timetable.</p>
<section id="sec5" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Make new code memory safe.</strong>  The first and most obvious option is to make new code memory safe—that is, to write new components in a memory-safe language. While this seems simple, you must address certain caveats to make this approach successful.</p>
<p id="p-50">First, you are unlikely to reap the benefits of memory safety if you try introducing memory-safe code alongside new memory-unsafe code. Think of it this way: In a fixed codebase that you continue to assure (via testing, code review, bug bounties, and more), the density of vulnerabilities decreases exponentially over time. As vulnerabilities become less dense in the codebase, the rate of new vulnerability discoveries also decreases, so the overall assurance level of the code <i>increases</i>. The riskiest thing you can do to a codebase is change it. In the case of memory-unsafe languages, that change can induce memory-safety vulnerabilities.</p>
<p id="p-51">The Google Chrome and Android teams have published extensively about their experiences incentivizing a move to memory-safe languages in their codebases. They instituted a rule called the <a class="ext-link" href="https://chromium.googlesource.com/chromium/src/%2B/master/docs/security/rule-of-2.md" data-jats-ext-link-type="uri">“Rule of Two,”</a> where all new code must be either sandboxed or in a memory-safe language. In practice, because sandboxing is difficult, this naturally gave developers incentive to pursue memory safety in most cases.</p>
<p id="p-52">Surprisingly to the team, <a class="ext-link" href="https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html" data-jats-ext-link-type="uri">they reaped the benefits of this new policy</a><a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a> across the entire codebase—even the parts that were not rewritten. Because they had certain assurances about the new code inherent in the safety mechanisms it came with, they could focus assurance efforts on old code, which was now static. Through this, they not only reduced the overall rate of memory-safety vulnerabilities in the codebase, but also decreased the prevalence of vulnerabilities overall.</p>
</section>
<section id="sec6" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Target rewrites to critical components.</strong>  Sometimes, rewriting code in a memory-safe language <i>can</i> be the right choice, but this is often a path to pursue only once you fully understand the challenges faced by the current memory-unsafe code.</p>
<p id="p-54">Early in its history, the development of Rust was funded by Mozilla, makers of the Firefox Web browser, and the flagship Rust project besides Rust’s own compiler was the <a class="ext-link" href="https://servo.org/" data-jats-ext-link-type="uri">Servo web-rendering engine</a>. Despite this, the first actual Rust code Mozilla integrated into Firefox was not Servo; it was <a class="ext-link" href="https://medium.com/mozilla-tech/deploying-rust-in-a-large-codebase-7e50328074e8" data-jats-ext-link-type="uri">an MP4 video file parser</a>.<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> They replaced the existing C++ parser with one written in Rust, moving from a memory-unsafe language to a memory-safe language, because it had long been a source of vulnerabilities. Firefox needs to parse MP4 files from untrusted sources, and failures to correctly handle that parsing could be dire. For Mozilla, it was a small but security-critical surface area that made sense to target for a rewrite.</p>
<p id="p-55">Another helpful tool for targeting is Kelly Shortridge’s <a class="ext-link" href="https://kellyshortridge.com/blog/posts/the-sux-rule-for-safer-code/" data-jats-ext-link-type="uri">SUX Rule</a><a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a>: target code that is Sandbox free, Unsafe, and eXogenous. This means you should prioritize rewriting code that processes untrusted (exogenous) input, runs without a sandbox, and is written in a memory-unsafe language. Reviewing your own codebase for these areas can be a fast way to identify critical paths with high risk of exploitation in the presence of memory-safety vulnerabilities.</p>
</section>
<section id="sec7" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Wrap unsafe code with safe interfaces.</strong>  When fully rewriting existing memory-unsafe code to a memory-safe language is not feasible, it might instead make sense to wrap it in a memory-safe interface. This does still lay the burden of ensuring safety properties on the programmer, both for the original code in the memory-unsafe language and for the correctness of the interface, but it then permits building safe and trusted new code on top of the old code. If you continue to work to assure the old code with techniques such as fuzz testing, analysis by sanitizers, or formal modeling, you can gain increased confidence in the latent unsafe code being wrapped.</p>
<p id="p-57">This is, in fact, how many of the Rust standard library’s <a class="ext-link" href="https://doc.rust-lang.org/nomicon/vec/vec.html" data-jats-ext-link-type="uri">common container types are written</a>.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> Under the hood, they contain unsafe code to manage buffers and pointers in a way that is as efficient as possible, but the interface provided to the user does not give access to any materials (buffers, pointers, lengths) that would permit the user to violate memory-safety guarantees.</p>
<p id="p-58">This “wrapping” approach helps constrain the “blast radius” of memory-unsafe code that cannot feasibly be removed or replaced and constrains the auditing scope and assurance costs of that code as well.</p>
</section>
<section id="sec8" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>&#8216;Get good&#8217; is not a strategy.</strong>  There is a common reply in conversations about memory safety, coming from the most hardcore skeptics: Programmers should just write better code. They argue, explicitly or implicitly, that programmers who benefit from the guardrails of memory safety are <i>bad programmers</i>, and that <i>real programmers</i> are sufficiently skilled that they do not need a machine double-checking their work.</p>
<p id="p-60">Let’s be clear: This is anti-intellectual nonsense—macho self-aggrandizement masquerading as a serious technical argument. You should not take it seriously and should consider someone advancing this argument as fundamentally unserious and to be ignored.</p>
<p id="p-61">There is no step function in quality of work in the history of human achievement that happened because people one day woke up and decided to be better at their jobs. Improvements in productivity or quality or reductions in error and harm happen because of the invention of new techniques, processes, and tools.</p>
<p id="p-62">Reductions in traffic fatalities in the 1980s and 1990s did not happen because drivers suddenly got better at driving; they happened because states enacted mandatory seatbelt laws.</p>
<p id="p-63">While individuals <i>can</i> become more skilled at their jobs, working faster or producing fewer errors, <i>large groups</i> of people generally do not do so without some force that works to provide incentive or enable that change. Even when improvements are nontechnical, they come from enhancements to processes or incentives for behavior. Over the past several decades, hospitals, for example, have reduced in-hospital mistakes because of increased use of standard checklists and provisioning of common materials needed for emergencies in crash carts.</p>
<p id="p-64">Programmers who argue against memory safety by arguing for mass self-improvement are posing an impossible future as an alternative against a credible opportunity for improvements in software safety and security. While there are credible case-specific arguments against individual paths to memory safety, they do not include sudden mass improvement of skill and quality across the industry. It is important to make this clear.</p>
</section>
</section>
<section id="sec9" class="sec">
<h2 class="heading">Regulations and Requirements</h2>
<section id="sec10" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>No, governments are not banning C or C++.</strong>  One specter of the conversations around memory safety is whether the use of memory-unsafe languages will become generally unacceptable, either through formal government regulation or a rise in common requirements for software purchasing.</p>
<p id="p-66">Today no agency, either in the U.S. or outside of it, regulates against the use of languages that are non-memory safe by default. Nor are there purchasing requirements in place calling for the use of memory-safe-by-default languages or even the presence of memory-safety roadmaps, at least for governments.</p>
<p id="p-67">The Five Eyes report mentioned previously <i>recommends</i> that organizations establish roadmaps for the pursuit of memory safety, but this is nonregulatory, and no amendments have been made to federal software acquisition policy to require such a roadmap in the U.S. or elsewhere. The U.S. is not outlawing C or C++. While these agencies have recommended moving away from these languages for future software development, they have not recommended indiscriminate mass rewrites of existing code.</p>
<p id="p-68">Also note that the processes for establishing regulation or requirements would face challenges and, whether successful or not, would be slow to take effect and offer ample time for feedback and consideration.</p>
<p id="p-69">First, regarding the prospect of regulation around memory safety in the U.S., such regulation would need to be pursued by a relevant agency that can establish a relevant jurisdiction. With <a class="ext-link" href="https://www.lawfaremedia.org/article/lawfare-daily--the-supreme-court-takes-the-bait--loper-bright-and-the-future-of-chevron-deference" data-jats-ext-link-type="uri">the end of Chevron deference in U.S. law</a>,<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> a requirement that judges defer to U.S. regulatory agencies’ determinations in most cases that was abolished in 2024 by the U.S. Supreme Court in <i>Loper Bright Enterprises v. Raimondo</i>, this pursuit of memory-safety regulation would also likely need to be explicitly backstopped by Congressional mandate to ensure it survived legal challenges where judges may overrule agency rulemaking.</p>
<p id="p-70">Second, regarding <i>acquisition requirements</i> (the federal government’s term for the rules around purchasing done by the government), the <a class="ext-link" href="https://acquisition.gov/browse/index/far" data-jats-ext-link-type="uri">Federal Acquisition Regulation (FAR)</a> would need to be updated to incorporate requirements for memory safety. For reference, in 2020 President Biden signed <a class="ext-link" href="https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/" data-jats-ext-link-type="uri">Executive Order 14028</a>, which included a request that federal agencies pursue an amendment to the FAR to require inclusion of a software bill of materials (SBoM) for all software purchased by the federal government. To date, those changes have not been made, and no such requirement is in place within the FAR.</p>
<p id="p-71">This is not to say that regulation or future federal purchasing requirements are impossible, but simply to point out that none are in place today, and any such changes would take time to be enacted and implemented.</p>
<p id="p-72">The U.S. government’s role around memory safety has so far been to act as a cheerleader and promoter of the idea, including the <a class="ext-link" href="https://bidenwhitehouse.archives.gov/oncd/briefing-room/2024/02/26/press-release-technical-report/" data-jats-ext-link-type="uri">“Future Software Should Be Memory Safe;”</a> report from the Office of the National Cyber Director, &#8220;A Case for Memory Safe Roadmaps&#8221; from the Cybersecurity and Infrastructure Security Agency (CISA) et. al., and CISA’s inclusion of memory-safety recommendations within its <a class="ext-link" href="https://www.cisa.gov/securebydesign" data-jats-ext-link-type="uri">Secure by Design</a> effort to collaborate with industry on improving software security.</p>
</section>
<section id="sec11" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Governments do not need to ban C or C++.</strong>  Even without government mandate, many organizations in the tech industry have publicly stated their support for pursuing memory safety. In 2023, the <a class="ext-link" href="https://bidenwhitehouse.archives.gov/oncd/briefing-room/2024/08/09/fact-sheet-biden-harris-administration-releases-end-of-year-report-on-open-source-software-security-initiative-2/" data-jats-ext-link-type="uri">Office of the National</a> Cyber Director put out an request for information (RFI) seeking advice from the public on how best to support improving the security of open source software. That RFI included an interest in the possibility of promoting adoption of memory-safe languages in open source.</p>
<p id="p-74">Respondents to the RFI, which includes a number of universities, think tanks, corporations, and individuals, overwhelmingly supported a move toward memory safety. Few espoused a hardline goal of rewriting all existing code from non-memory-safe languages, but many did recognize the value of pursuing memory safety in new code, and in rewriting critical components in security-sensitive contexts when possible.</p>
<p id="p-75">Some companies, <a class="ext-link" href="https://security.googleblog.com/2024/03/secure-by-design-googles-perspective-on.html" data-jats-ext-link-type="uri">most notably Google</a>,<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> have been especially vocal about their experiences with the value of memory safety. To them, the promise of memory safety is a reduction in security-related costs for long-term products such as the Google Chrome Web browser or the Android operating system. By reducing memory-safety vulnerabilities at the source, they shift vulnerability costs left in the software development lifecycle; the cost of catching a bug during development and stopping it from being shipped at all is orders of magnitude cheaper than the cost of receiving a security report, perhaps paying out a bug bounty, and then coordinating, preparing, and releasing a patch.</p>
<p id="p-76">In some corners, there has been a paranoia and fear that recommendations around memory safety from the U.S. government and others portend some forced end to C or C++. Bjarne Stroustrup, originator of C++ and continued major participant in the ISO Working Group that maintains the C++ specification, has <a class="ext-link" href="https://www.theregister.com/2025/03/02/c_creator_calls_for_action/" data-jats-ext-link-type="uri">recently begun to sound alarm bells</a><a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> in papers and speeches about the existential threat posed to C++ by failing to address the demands for memory safety, with clear reference to the possibility that software written in non-memory-safe-by-default languages may be disallowed or become practically untenable to market and sell in the future.</p>
<p id="p-77">This fear is simultaneously overblown and correct. It is overblown to suggest the U.S. or any other government is close to outlawing C or C++, but it is correct to note that the benefits of memory safety are becoming clearer with each case study performed at scale and that we should expect natural incentives to slowly accrue larger use and developer interest in memory-safe languages over non-memory-safe languages. C and C++ will not die, but they will likely decline and become legacy languages like Cobol or Ada. They will still sustain some degree of interest and community, and a smaller number of developers will likely continue to be able to make their careers as developers in these languages, but they will be languages that present developers with fewer labor-market opportunities in the future and are unlikely to ascend in popularity and use again without substantial changes to address these safety deficiencies.</p>
</section>
</section>
<section id="sec12" class="sec">
<h2 class="heading">Safety Is Worth Pursuing</h2>
<p id="p-78">Memory-safe languages present the clearest opportunity today to substantially improve software security. While memory safety does not eliminate all classes of software weaknesses, it does eliminate a particularly pernicious class that leads to disproportionately severe vulnerabilities. While there are other techniques for addressing these kinds of weaknesses (for example, hardware-based approaches such as CHERI), they are less mature and generally more difficult to adopt at scale.</p>
<p id="p-79">The state of possibility with memory safety today is similar to the state of automobile safety just prior to the widespread adoption of mandatory seatbelt laws. As car manufacturers began to integrate seatbelts as a standard feature across their model lines and states began to require that drivers wear seatbelts while driving, the rate of traffic fatalities and severity of traffic-related injuries dropped drastically. Seatbelts did not solve automobile safety, but they credibly improved it and at remarkably low cost.</p>
<p id="p-80">The same can be done with memory safety. There is an opportunity to make substantial inroads at addressing a serious class of vulnerabilities while also, long-term, saving money on the development and operation of software systems. Memory safety is not a silver bullet, but it is a credible and cost-effective assurance technique that we as an industry should pursue aggressively. We do not need to wait for regulation to catch up; it is in our best interests to act today.</p>
</section>
<section id="sec13" class="sec">
<h2 class="heading">Acknowledgments</h2>
<p id="p-81">Thank you to <a class="ext-link" href="https://steveklabnik.com/" data-jats-ext-link-type="uri">Steve Klabnik</a>, engineer at <a class="ext-link" href="https://oxide.computer/" data-jats-ext-link-type="uri">Oxide Computer Company</a> and former member of the <a class="ext-link" href="https://github.com/rust-lang/team/blob/master/teams/archive/core.toml" data-jats-ext-link-type="uri">Rust Core Team</a>, and to <a class="ext-link" href="https://www.linkedin.com/in/michael-chernicoff-587b31177/" data-jats-ext-link-type="uri">Michael Chernicoff</a>, senior software engineer at <a class="ext-link" href="https://www.mitre.org/" data-jats-ext-link-type="uri">MITRE</a>, for reviewing this article and providing feedback prepublication.</p>
</section>
<section id="sec14" class="sec">
<h2 class="heading">Disclaimer</h2>
<p id="p-82">Approved for public release; distribution unlimited. Public Release Case Number 25–1514. The author’s affiliation with The MITRE Corporation is provided for identification purposes only and is not intended to convey or imply MITRE’s concurrence with, or support for, the positions, opinions, or viewpoints expressed by the author.</p>
</section>
</div>
</article>

<p>&nbsp;</p>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/practice/memory-safety-for-skeptics/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">776447</post-id>	</item>
		<item>
		<title>Embedding Security into Business Processes</title>
		<link>https://cacm.acm.org/opinion/embedding-security-into-business-processes/</link>
					<comments>https://cacm.acm.org/opinion/embedding-security-into-business-processes/#respond</comments>
		
		<dc:creator><![CDATA[Alex Vakulov]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 15:12:04 +0000</pubDate>
				<category><![CDATA[Security and Privacy]]></category>
		<category><![CDATA[Systems and Networking]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775512</guid>

					<description><![CDATA[<p>How can organizations move from simply reacting to incidents to gaining real control over threats?</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1"><b>Alex Vakulov<br /></b><b>Building and Implementing Cyber Resilience Strategies<br /></b>DOI: 10.1145/3779575<br /><b>https://bit.ly/4oyH4GK</b></p>
<p id="p-5">Today, every organization is vulnerable to cyberattacks, and security incidents should be seen as inevitable. Merely defending your infrastructure is no longer enough; what truly matters is its resilience.</p>
<p id="p-6">That means preparing for attacks before they happen, managing risks proactively, maintaining business continuity, and ensuring a rapid recovery when incidents occur.</p>
<p id="p-7">How can organizations move from simply reacting to incidents to gaining real control over threats? Let’s explore practical approaches, from organizational strategies to technical measures, that help embed security into everyday business processes.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Understanding the Difference Between Cybersecurity and Cyber Resilience</h2>
<p id="p-8">The terms “cybersecurity” and “cyber resilience” are often used interchangeably when describing corporate protection needs, but there is a key difference between them.</p>
<p id="p-9">Cybersecurity refers to the traditional set of measures focused on identifying, preventing, and mitigating threats to digital assets. Cyber resilience, on the other hand, represents the next stage in the evolution of security. It’s a broader concept that includes not only protection but also preparation for potential attacks, proactive risk management, the ability to maintain operations during incidents, and rapid recovery afterward.</p>
<p id="p-10">The difference between these two approaches becomes clear when comparing their primary focus. Cybersecurity aims to answer the question, “How can we protect ourselves?,” while cyber resilience addresses a more complex challenge: “How can we keep operating even amid persistent, multi-vector attacks?” This difference is important for organizations that want not only to reduce risks but also to keep their operations running smoothly and steadily at all times.</p>
<p id="p-11">Cyber resilience emphasizes proactive threat management through business impact analysis<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a> (BIA) and the use of threat intelligence<a class="footnote-link xref xref-fn" href="#FN2" data-jats-rid="FN2" data-jats-ref-type="fn"><sup>b</sup></a> and threat hunting<a class="footnote-link xref xref-fn" href="#FN3" data-jats-rid="FN3" data-jats-ref-type="fn"><sup>c</sup></a> tools, strengthening systems while maintaining their operability during an attack.</p>
<p id="p-12">Modern standards increasingly recognize the importance of both security and resilience. NIST CSF 2.0<a class="footnote-link xref xref-fn" href="#FN4" data-jats-rid="FN4" data-jats-ref-type="fn"><sup>d</sup></a> expands the original Cybersecurity Framework (CSF) with new governance and recovery elements, helping organizations bridge toward resilience. ISO 27001 remains focused on establishing and maintaining information security, while ISO 22301 directly addresses business continuity and the handling of disruptions. Specialized approaches such as the MITRE Cyber Resiliency Engineering Framework<a class="footnote-link xref xref-fn" href="#FN5" data-jats-rid="FN5" data-jats-ref-type="fn"><sup>e</sup></a> provide practical methodologies for designing and implementing cyber-resilient systems.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">A Practical Framework for Building Cyber Resilience</h2>
<p id="p-13">Currently, there is no unified standard for managing cyber resilience. Although many vendors offer their own solutions and some general standardization efforts are underway, a clear and consistent framework has yet to be established. As a result, organizations are forced to develop their own methods based on internal priorities and interpretations.</p>
<p id="p-14">The main challenge is that cyberattacks have become unavoidable and frequent. Traditional protective measures alone are no longer sufficient to fight modern threats. Another problem is the lack of coordination between IT, information security, and business units. This disconnect creates gray areas where responsibilities overlap or are unclear: IT manages data retention,<a class="footnote-link xref xref-fn" href="#FN6" data-jats-rid="FN6" data-jats-ref-type="fn"><sup>f</sup></a> backups, recovery, and data verification, while information security focuses on threat prevention and mitigation. The result is fragmented and uncoordinated efforts.</p>
<p id="p-15">An effective approach to cyber resilience should be based on BIA and risk assessment, not just regulatory requirements. Implementing this approach usually involves several key stages.</p>
<p id="p-16">First, it is crucial to analyze business priorities, identify critical services and their interdependencies, and evaluate the potential impact of disruptions.</p>
<p id="p-17">Next comes analytical scenario modeling, which involves identifying potential attacker motivations and the most likely attack vectors.</p>
<p id="p-18">Building on the insights from the first two stages, organizations can selectively strengthen security mechanisms along critical paths and, using the identified attack scenarios, develop targeted response and recovery plans for specific threats.</p>
<p id="p-19">The final stage focuses on verifying the effectiveness of these plans through tabletop exercises and cyber simulations that engage the entire team, not just key personnel.</p>
<p id="p-20">In practice, however, its implementation largely depends on the organization’s maturity, scale, and specific infrastructure characteristics. The main difference lies in the level of detail: as a company grows, its infrastructure becomes more complex, the number of stakeholders increases, and each stage of analysis requires greater depth.</p>
<p id="p-21">In small organizations, identifying critical services is relatively quick, while in large enterprises, the process may involve analyzing hundreds of interconnected operations. Likewise, the scope of security measures varies—from basic hardening of key systems to multi-layered protection across distributed environments.</p>
<p id="p-22">At the same time, core principles such as threat analysis, incident response planning, and regular audits remain largely unchanged across all organizations. The difference is in how thoroughly they are implemented and how many resources are needed.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Integrating Cyber Resilience with IT and Security Processes</h2>
<p id="p-23">To be truly effective, cyber resilience needs to work hand in hand with existing IT and security processes.</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-24"><b>Risk Management and Asset Inventory. </b>Effective risk management begins with identifying the key assets and processes that are critical to business continuity and prioritizing their protection. An asset inventory helps pinpoint which systems and services need greater resilience while tracking the overall health of the network. This should be an ongoing process rather than a one-time exercise.</p>
<p id="p-26">Risk assessments should evaluate not only the likelihood of potential threats, but also their possible impact on the business. Using quantitative metrics alongside qualitative analysis provides a more accurate picture of overall risk. Categorizing assets by importance helps focus protection efforts on the most critical components.</p>
</li>
<li class="list-item">
<p id="p-27"><b>Penetration Testing. </b>Cyber resilience involves more than just detecting threats; it also means preparing for their potential consequences. Insights from threat hunting and ongoing dark web monitoring can improve detection and shape redundancy and failover plans for critical systems. Attack simulations, including penetration testing<a class="footnote-link xref xref-fn" href="#FN7" data-jats-rid="FN7" data-jats-ref-type="fn"><sup>g</sup></a> and red team exercises,<a class="footnote-link xref xref-fn" href="#FN8" data-jats-rid="FN8" data-jats-ref-type="fn"><sup>h</sup></a> help test how well systems continue to function even after a successful breach.</p>
</li>
<li class="list-item">
<p id="p-29"><b>Vulnerability Management. </b>Because not all vulnerabilities can be addressed immediately, cyber resilience focuses on minimizing their impact. This requires collaboration to prioritize remediation based on business risk and to implement layered safeguards such as network segmentation, secure remote access through VPN, reliable backup<a class="footnote-link xref xref-fn" href="#FN9" data-jats-rid="FN9" data-jats-ref-type="fn"><sup>i</sup></a> infrastructure, and Web application firewalls.<a class="footnote-link xref xref-fn" href="#FN10" data-jats-rid="FN10" data-jats-ref-type="fn"><sup>j</sup></a></p>
</li>
<li class="list-item">
<p id="p-31"><b>Continuous Monitoring and Incident Response. </b>Again, cyber resilience is about more than detecting attacks quickly; it’s also about keeping operations running during and after an incident. Achieving this requires automating response actions, such as switching to backup systems, aligning response procedures with business continuity and disaster recovery<a class="footnote-link xref xref-fn" href="#FN11" data-jats-rid="FN11" data-jats-ref-type="fn"><sup>k</sup></a> plans, and performing post-incident analyses to assess and improve effectiveness.</p>
</li>
<li class="list-item">
<p id="p-33"><b>Testing and Recovery. </b>Combining cyber exercises with recovery processes makes both more effective. For example, penetration testing can be complemented by testing disaster recovery mechanisms to confirm that restoration deadlines are met and that the infrastructure functions properly after an incident.</p>
<p id="p-35">In general, organizations should regularly perform fault tolerance testing and recovery drills to evaluate how quickly and effectively systems can return to normal operations.</p>
</li>
</ul>
</section>
<section id="sec5" class="sec">
<h2 class="heading">Integrating Cyber Resilience with Security Tools</h2>
<p id="p-36">Cyber resilience requires a multi-layered approach that brings together various security solutions. At the operational level, this includes endpoint detection and response,<a class="footnote-link xref xref-fn" href="#FN12" data-jats-rid="FN12" data-jats-ref-type="fn"><sup>l</sup></a> vulnerability management, network microsegmentation, and disaster recovery capabilities. Tactical protection is achieved through penetration testing and red team exercises, while the strategic level focuses on automation and the use of robotic process automation<a class="footnote-link xref xref-fn" href="#FN13" data-jats-rid="FN13" data-jats-ref-type="fn"><sup>m</sup></a> to enhance efficiency and response.</p>
<p id="p-37">Governance, Risk, and Compliance<a class="footnote-link xref xref-fn" href="#FN14" data-jats-rid="FN14" data-jats-ref-type="fn"><sup>n</sup></a> (GRC) platforms are essential for strengthening cyber resilience by combining risk management with regulatory compliance. Their key features include centralizing risk oversight and asset assessment, guaranteeing compliance with data privacy laws such as GDPR, and overseeing financial controls under Sarbanes-Oxley.<a class="footnote-link xref xref-fn" href="#FN15" data-jats-rid="FN15" data-jats-ref-type="fn"><sup>o</sup></a></p>
<p id="p-38">GRC systems automate the entire incident management cycle, from logging and response coordination to task assignment, such as managing recovery after a ransomware attack. Once an incident is resolved, these systems help analyze the effectiveness of the response and adjust processes accordingly. As a result, GRC solutions reduce routine workloads, minimize human error, and improve transparency in compliance management.</p>
</section>
<section id="sec6" class="sec">
<h2 class="heading">Cyber Resilience is a Shared Business Responsibility</h2>
<p id="p-39">Cyber resilience is not only a technical task, but also a mindset that drives a business. Organizations need to clearly define key requirements, such as acceptable recovery times for critical systems, and proactively develop alternative operational scenarios to ensure continuity in the event of disruptions.</p>
<p id="p-40">The business serves as both the customer and the investor in cybersecurity, since it ultimately determines how resources are allocated. Security specialists are responsible for demonstrating the potential consequences of inaction, while management must decide whether to consciously accept the risks or take measures to reduce them.</p>
<p id="p-41">A key factor in achieving cyber resilience is the active involvement of all business units at every stage of the process. Setting requirements and monitoring their implementation is relatively straightforward, but true collaboration goes further—it involves supporting and participating in continuity testing, even when that means working outside regular hours.</p>
</section>
<section id="sec7" class="sec">
<h2 class="heading">Comprehensive Strategy</h2>
<p id="p-42">Cyber resilience is a strategic business priority that goes beyond traditional cybersecurity. While cybersecurity focuses on protecting data and infrastructure, cyber resilience takes a broader approach. It includes proactive risk management, the development of response plans, and measures to ensure business continuity.</p>
<p id="p-43">Effective protection comes from combining both approaches: aligning IT and business processes and conducting regular system audits. This comprehensive strategy not only reduces the likelihood of attacks, but also minimizes their impact, helping organizations maintain stable operations amid an evolving threat landscape.</p>
</section>
<section id="sec8" class="sec"></section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/embedding-security-into-business-processes/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">775512</post-id>	</item>
		<item>
		<title>The Agentic Economy</title>
		<link>https://cacm.acm.org/opinion/the-agentic-economy/</link>
					<comments>https://cacm.acm.org/opinion/the-agentic-economy/#respond</comments>
		
		<dc:creator><![CDATA[David M. Rothschild, Markus M. Mobius, Jake M. Hofman, Eleanor Dillon, Daniel G. Goldstein, Nicole Immorlica, Sonia Jaffe, Brendan Lucier, Aleksandrs Slivkins, and Matthew Vogel]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 15:09:41 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[Society]]></category>
		<category><![CDATA[Systems and Networking]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776430</guid>

					<description><![CDATA[<p>Generative AI has the potential to drastically reduce communication frictions between and among consumers and businesses, which could shift market power and lead to entirely new products and services.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Generative AI has revolutionized the way we interact with technology, allowing people to express their intent in free-form natural language. It has paved the way for AI agents that not only converse with users but also perform actions on their behalf, flexibly and with minimal guidance. Delegation to AI has already begun to improve the efficiency of individual processes, making both consumers and businesses more productive in the set of tasks they had already been doing.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> However, we believe that the more disruptive—and yet to be realized—impact of generative AI is its potential to drastically reduce the communication frictions between and among consumers and businesses. This could lead to a reorganization of markets, shifts of market power, and the introduction of entirely new products and services.</p>
<p id="p-2">Consumers have traditionally faced high communication costs when initiating relationships with businesses, reducing efficiency.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> For example, a consumer seeking a new tax preparer might hesitate to switch because she would have to explain her financial situation all over again to a new person or online service. These communication hurdles can prevent consumers from taking advantage of better products and services or lower prices. Businesses have tried to lower these costs with tools like online forms and voicemail menus, but these often just shift communication costs to the consumer and can make interactions more rigid.</p>
<p id="p-3">Imagine instead a future where every consumer has an assistant agent to communicate their preferences and personal information to businesses, and every business has service agents to interact with consumers and other businesses. These agents could be designed to interface with each other seamlessly and flexibly, transforming the landscape of consumer-business interactions. Delegating interactions to such assistant and service agents lowers communication costs and makes markets more efficient by expanding the range of options available to both consumers and businesses.</p>
<p id="p-4">To unlock the full economic potential of generative AI’s communication capabilities, two developments are necessary. First, consumers and businesses must widely adopt assistant and service agents. This is already under way.<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> Second, these agents must be designed to interact seamlessly with each other to facilitate transactions. On the technical front, there has been significant progress in standardizing such agentic interaction, with frameworks such as Microsoft’s AutoGen,<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a> and protocols such as Anthropic’s Model Context Protocol<a class="footnote-link xref xref-fn" href="#FN2" data-jats-rid="FN2" data-jats-ref-type="fn"><sup>b</sup></a> and Google’s Agent2Agent Protocol.<a class="footnote-link xref xref-fn" href="#FN3" data-jats-rid="FN3" data-jats-ref-type="fn"><sup>c</sup></a> However, it remains to be seen how these advances will be adopted and implemented, or constrained, given their complex interplay with and dependence on market forces.</p>
<p id="p-5">We believe the largest benefits of inter-agent communication will be realized as markets reorganize around these new capabilities.<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> While the possibilities of this technological distribution are numerous and difficult to predict, we offer a framework for understanding the most plausible outcomes and contrasting them with the current state of affairs. A key question is whether inter-agent communication will occur within closed “agentic walled gardens” controlled by a few dominant providers, akin to today’s app stores, or through a more open “web of agents” where agents freely connect and transact, much like the World Wide Web. The answer to this question will determine how today’s largest online platforms are impacted by the proliferation of interconnected agents—whether through further entrenchment of their market power or a loss of dominance and broader democratization of AI’s economic benefits. We explore how those benefits might manifest, with implications for advertising, e-commerce, and the creation of new products and industries.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">The Current State of Agentic AI</h2>
<p id="p-6">Before discussing future possibilities for agentic economies, it is helpful to survey the current landscape of AI agents. On the surface it may appear as if several existing efforts are well on their way to providing consumers and businesses with assistant and service agents that could function as described above. But most existing agents lack a key ingredient: while they are designed to interact with or simulate human users, few public offerings are <i>designed to interact with each other</i>.</p>
<p id="p-7">Existing agents generally come in one of two forms: siloed service agents or general-purpose end-to-end agents. The first, siloed service agents, provide a new user interface for products and services within a single company. For example, Amazon’s Rufus allows customers visiting Amazon to access their order histories or compare potential purchases through natural language instead of navigating a website. Likewise, Expedia’s Romie provides a chat interface to help customers build travel itineraries—including flights, hotels, and restaurants—by pulling information from customer email messages and group chats. Importantly, however, these efforts do not expose interfaces intended for interaction with other agents. As a result, they are still fundamentally limited by people having to navigate to and personally interact with them.</p>
<p id="p-8">End-to-end agents take a different approach, aiming to provide general-purpose automated functionality that is not limited to a single company or service. For instance, technology from OpenAI, Google, and Microsoft can aggregate research from external sources, navigate business websites on the user’s behalf, and even perform simple tasks like making reservations or placing food orders, all within one interface. Importantly, however, much of the functionality that these end-to-end agents provide currently comes through “computer use models” that simulate a user pointing and clicking on existing (non-agentic) websites (or most recently the assistant agent may absorb a menu of products and pricing, or even an app, but still all within the confines of the assistant agent). This gives the illusion of assistant and service agents working together, but the absence of a true service agent on the business side limits what an end-to-end agent can accomplish. Moreover, by mimicking human users, these agents risk creating adversarial relationships with businesses that, for example, rely heavily on advertising revenue and may resist having their websites accessed by agents (or otherwise handing their menu of products and pricing directly to the assistant agents) instead of humans. Moreover, by mimicking human users, these agents risk creating adversarial relationships with businesses that, for example, rely heavily on advertising revenue and may resist having their websites accessed by agents instead of humans. Even if end-to-end agents can perfectly simulate human users and businesses agree to agent- based access, interactions would still be constrained by what businesses currently expose through existing web forms that limit the expressiveness of requests and responses. For instance, businesses offering highly customizable products—such as catering services—often use only basic contact forms, handling niche or specialized requests through human follow-up.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">The Future Impact of Agentic AI</h2>
<p id="p-9">Given their limitations, we anticipate that siloed and end-to-end agents will ultimately give way to agents that are designed to seamlessly interact directly with each other. However, there is a complex interplay between technical capabilities and market forces that could lead to a number of different scenarios for what this solution will look like, who will control it, and what it will be capable of.</p>
<section id="sec4" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>The Market Power of Digital Intermediaries.</strong>  Two-sided platforms (businesses designed to bring together two distinct sides for a transaction) such as Amazon, Expedia, OpenTable, and Spotify are key intermediaries of the current digital economy that create value by matching millions of consumers and businesses to each other within specific domains such as shopping, travel, dining, and music.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> They do this in part by standardizing how both sides interact. For example, Amazon requires sellers to follow specific formats and policies, while consumers must use its interface to search and transact. In exchange, consumers access a vast range of sellers, and businesses gain exposure to a large customer base. But this comes with trade-offs: both operate within a tightly constrained system, are subject to the platform’s design choices (for example, ranking algorithms), and pay referral fees.</p>
<p id="p-11">If an agentic economy enables each consumer’s assistant agent to directly and flexibly communicate with each businesses’ service agent via <i>unscripted communication</i>, the role—and market power—of intermediary platforms could shift substantially. In principle, once communication frictions are low enough, interoperable AI agents could eliminate the necessity for two-sided platforms as intermediaries all together. Consumer assistant agents could directly find and flexibly negotiate with service agents to buy goods, book hotels and airlines, make dining reservations, and stream music.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> This would represent a drastic decentralization of power compared to today’s markets.</p>
<figure class="fig">
<div><figure id="attachment_776967" aria-describedby="caption-attachment-776967" class="wp-caption alignnone"><img loading="lazy" decoding="async" class="size-full wp-image-776967" src="https://cacm.acm.org/wp-content/uploads/2026/01/Vector-Figure.jpg" alt="Web of Agents, Walled Garden" width="1024" height="449" srcset="https://cacm.acm.org/wp-content/uploads/2026/01/Vector-Figure.jpg 2400w, https://cacm.acm.org/wp-content/uploads/2026/01/Vector-Figure.jpg?resize=300,132 300w, https://cacm.acm.org/wp-content/uploads/2026/01/Vector-Figure.jpg?resize=768,337 768w, https://cacm.acm.org/wp-content/uploads/2026/01/Vector-Figure.jpg?resize=1024,449 1024w, https://cacm.acm.org/wp-content/uploads/2026/01/Vector-Figure.jpg?resize=1536,673 1536w, https://cacm.acm.org/wp-content/uploads/2026/01/Vector-Figure.jpg?resize=2048,898 2048w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /><figcaption id="caption-attachment-776967" class="wp-caption-text">Figure. In an agentic marketplace, assistant agents (representing consumers) and service agents (representing businesses) interact directly with each other. We distinguish between two scenarios: (a) an example of an open web of agents with unrestricted communication between agents and (b) an example of walled gardens in which agents are restricted to interacting within the confines of platforms.</figcaption></figure></div>
<p>In practice, however, intermediary platforms often provide value beyond simply standardizing communication between buyers and sellers, via discovery, validation, remediation, and economies of scale. For instance, in domains like travel, it may still be useful for an intermediary to provide trusted suggestions, offer trip insurance, resolve disputes, or ensure regulatory compliance. However, an agentic economy could lead to fierce competition between intermediaries due to low switching costs, reducing the profits they can extract.</p>
<p data-jats-content-type="inline-heading"><strong>Agentic walled gardens vs. the web of agents.</strong>  Even though any specific assistant and service agent may be technically capable of communicating with each other in an unscripted manner, the pool of agents they might interact with could be <i>restricted</i> due to market forces. Select firms may provide assistant agents for free but restrict communications, creating “agentic walled gardens.” In some sense this would be a natural evolution of today’s existing application ecosystems such as the app stores in dominant operating systems. Given their existing large user bases and nascent assistant technologies like Apple Intelligence, Google Assistant, Microsoft Copilot, and Meta AI, these firms are well positioned to extend their current marketplaces to include interoperable AI agents. For example, in March 2025, Meta launched basic service agents for business pages on Facebook and Instagram at no cost, but these service agents are only accessible to users on their own platforms. In addition, firms such as OpenAI and Anthropic that have built out large user bases for their assistant agents could develop their own marketplaces.</p>
<p id="p-15">These walled gardens could offer a number of benefits such as ensuring a baseline of quality and security by filtering out low-reputation or fraudulent service agents and streamlining discoverability and rating of agents. They could also offer insurance if an agent makes a mistake. However, much like today’s app stores, this could concentrate market power in the hands of a few dominant players, who could leverage their position to extract substantial profits and limit the openness, competitiveness, and innovation of the broader ecosystem. This could also lead to fragmentation of agentic ecosystems and suboptimal user experiences—for instance, a given individual might have siloed assistant agents for personal and professional purposes, making it difficult to coordinate between them.</p>
<p id="p-16">Conversely, if consumers and businesses fully own and manage their agents, communication could be both unscripted and unrestricted, leading to a completely open and decentralized “web of agents” that is not controlled by any one entity. Similar to today’s World Wide Web, any agent could join and transact with any other. Assistant agents would play a role similar to web browsers, and service agents similar to websites. This could foster competition, innovation, and broad access to agentic technology, but it also comes with substantial challenges. In particular, successful development of a web of agents requires large-scale coordination among many players—including corporations and governments—to develop and agree upon standards and protocols. It also requires robust mechanisms for discovery, trust, and security among interacting agents. We visualize these two plausible scenarios in the accompanying figure.</p>
</section>
<section id="sec6" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>The future of advertising.</strong>  In today’s digital economy there are generally many more businesses and products available to consumers than they have the time to research and consider, and so advertising plays a crucial role in capturing attention and guiding online transactions. But in an agentic economy where assistants can interact with millions of businesses on behalf of consumers, attention is a less-constrained resource. What matters more is the algorithm that matches assistants to service agents.</p>
<p id="p-18">In a scenario where there are strong central intermediaries (that is, an agentic walled garden or web of agents with dominant discovery layers) some form of paid prioritization, akin to today’s advertising, is very likely to influence rankings. But the truly scarce and valuable resource—particularly in a web of agents—will be high-quality human feedback on goods and services. This feedback will be crucial not only for improving offerings (for example, training AI agents) but also for distinguishing high-quality services from poor ones. The focus of monetization and competition could shift from the “attention economy” to a “preference economy.” Success will hinge on attracting early, engaged users who provide valuable feedback.</p>
<p id="p-19">New means of monetization may emerge to aggregate and rank service agents based on feedback from consumers and their assistants. Just as people leave reviews on platforms like Yelp or Google Maps today, future assistants might generate reviews based on user satisfaction data. Businesses could compete by offering better prices or services to attract these early users, creating a flywheel of feedback and preference data.</p>
</section>
<section id="sec7" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Payments and micro-transactions.</strong>  As interactions between consumers and businesses become more seamless and platform intermediaries less central, we anticipate a rise in “one-off” transactions and accompanying decrease in repeat engagements and long-term consumer-business relationships. This shift may encourage the growth of micro-transactions. For example, a consumer whose assistant frequently and seamlessly switches between multiple content providers (for example, Spotify and Pandora, or Netflix and Amazon Prime) may prefer usage-based micro-payments over subscribing to both services. Furthermore, the usual friction associated with micro-payments is eliminated when transactions are handled entirely by assistants and service agents, encouraging micro-transactions that would otherwise be too inconvenient to manage manually. This shift is likely to evolve regardless of whether walled gardens or a web-of-agents scenario triumphs.</p>
</section>
<section id="sec8" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Unbundling, Rebundling, and New Products.</strong>  Products, goods, and services are often bundled to balance complexity and efficiency of transactions. For example, a news article may bundle interviews, photos, and facts, even if the reader is already familiar with parts of the story. A consumer’s assistant agent, however, can track what the user has already read and collaborate with a service agent (for example, from the <i>New York Times</i>) to generate a customized article focusing only on new or relevant information. This dynamic and personalized rebundling optimizes knowledge transfer while minimizing cognitive load. Such personalization can be accomplished even today using methods such as retrieval-augmented generation (RAG); in principle, an assistant agent could pull from multiple sources of high-quality content to create customized offerings for its user. Currently, however, such methods are often limited to public-domain sources such as Wikipedia or under fair use claims, as publishers are generally unwilling to permit their content to be reused without compensation. In the future, micro-transactions between assistants and service agents for the use of individual pieces of digital content could enable an ecosystem that compensates content creators while unlocking the ability to create customized user experiences.</p>
<p id="p-22">More generally, the power of dynamic and personalized bundling could apply to many other digital goods and services that can be deconstructed and reconstructed by assistant agents working with service agents to best serve the needs of end users. This capability aligns closely with the anticipated rise of micro-transactions handled by agents. As the infrastructure for micro-payments develops, it will become possible for digital components to be individually and dynamically negotiated, priced, and packaged into hyper-personalized products. We expect more extreme unbundling, rebundling, and new products in a web of agents where there can be unrestricted communication between the assistant and <i>any</i> service agent, allowing for more innovation in product creation and bundling.</p>
</section>
</section>
<section id="sec9" class="sec">
<h2 class="heading">Conclusion</h2>
<p id="p-23">As technological progress drives greater specialization, it also increases the need for coordination, which in turn demands more sophisticated communication between individuals, organizations, and systems.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> For example, where one doctor once handled a patient’s care, today multiple specialists must collaborate using advanced tools and shared information. AI agents mark a shift in this pattern: rather than compounding communication overhead, they offer a way to streamline it. By coordinating tasks across fragmented systems, agents stand to reduce friction in markets, lower switching costs, and unlock more decentralized access to digital goods and services.</p>
<p id="p-24">The architecture of this emerging marketplace is still taking shape. Much will depend on whether AI agents are allowed to interact freely across an open web or whether their interactions are restricted within closed ecosystems. This will be shaped by early stakeholder decisions, emerging technical standards, and evolving regulatory frameworks. Regulatory outcomes may vary by country—especially given the divergent approaches of the E.U., which favors precautionary, preventive measures, and the U.S., which tends to adopt a more reactive, ex-post regulatory stance in digital markets. In that sense, this moment is reminiscent of the early days of the Internet before it began generating billions of dollars of revenue. The current platform-dominated economy was certainly not obvious in the late 1990s into the early 2000s, when digital commerce was becoming increasingly decentralized as early Internet portals gave way to a blossoming World Wide Web.</p>
<p id="p-25">Now is the time for us to reflect and ask what kind of agentic economy we want in the near future. The choices we make today will determine not only how these markets function, but also who benefits from this new wave of technology.</p>
</section>
<section id="sec10" class="sec"></section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/the-agentic-economy/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Markus M. Mobius]]></dc:creator>
      <dc:creator><![CDATA[Jake M. Hofman]]></dc:creator>
      <dc:creator><![CDATA[Eleanor Dillon]]></dc:creator>
      <dc:creator><![CDATA[Daniel G. Goldstein]]></dc:creator>
      <dc:creator><![CDATA[Nicole Immorlica]]></dc:creator>
      <dc:creator><![CDATA[Sonia Jaffe]]></dc:creator>
      <dc:creator><![CDATA[Brendan Lucier]]></dc:creator>
      <dc:creator><![CDATA[Aleksandrs Slivkins]]></dc:creator>
      <dc:creator><![CDATA[Matthew Vogel]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">776430</post-id>	</item>
		<item>
		<title>It Takes a Village to Teach Privacy</title>
		<link>https://cacm.acm.org/opinion/it-takes-a-village-to-teach-privacy/</link>
					<comments>https://cacm.acm.org/opinion/it-takes-a-village-to-teach-privacy/#respond</comments>
		
		<dc:creator><![CDATA[Yaxing Yao and Lanjing Liu]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 14:56:31 +0000</pubDate>
				<category><![CDATA[Education]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776441</guid>

					<description><![CDATA[<p>Privacy literacy teaches children that they have a right to boundaries and to make decisions about their digital lives.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Children today are growing up in an era in which surveillance is not an exception but an expectation. A recent report from the American Academy of Child and Adolescent Psychiatry<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> has also shown that elementary school children today spend more than six hours a day on digital devices through using educational apps, watching videos, using chat apps to message friends, and navigating social media platforms, all of which are designed to collect users’ data. Yet, most children lack the tools and skills to understand what is happening to their data or how to protect themselves.</p>
<p id="p-2">Interestingly, our research has found that children as young as six can articulate concerns about privacy, but their understanding is often superficial. Our work also shows that parents described privacy conversations at home as mostly rule-based (“don’t share your location,” “don’t talk to strangers”).<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> While these rules are easy to remember, they rarely help children make sense of more complex or nuanced scenarios, like whether it is okay to allow an app to track their activity “to improve performance.”</p>
<p id="p-3">We see an important gap here. We teach children to read before they read alone. We teach them about nutrition before they shop for groceries. But we often leave them to encounter digital privacy challenges with little more than “don’t talk to strangers” or “don’t post your real name.” It is not enough. Children need more than rules. In our opinion, they need the knowledge, critical thinking, and decision-making skills necessary to navigate privacy risks both online and offline. We define this as “privacy literacy.”</p>
<p id="p-4">As we are exploring novel ways to enhance children’s privacy literacy, we found a need for a systemic shift in how we educate children. That is, instead of teaching rules, we need a comprehensive approach to equip children with the literacy they need.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Epstein’s Theory and the Case for Cross-Context Collaboration</h2>
<p id="p-5">Education researcher Joyce Epstein proposed the Theory of Overlapping Spheres of Influence,<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> which states that children’s learning is shaped by three overlapping spheres of influence: family, school, and community. When these spheres work in isolation, children receive fragmented or conflicting messages. When they collaborate, children benefit from reinforcement, consistency, and cumulative learning.</p>
<p id="p-6">We applied this theory to the context of privacy education and found that each sphere contributes uniquely to children’s learning when connections are intentional:</p>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-7">Families are best at initiating conversations about privacy that are rooted in personal experiences and values.</p>
</li>
<li class="list-item">
<p id="p-8">Schools offer structure, repetition, and alignment with developmental milestones in learning privacy skills.</p>
</li>
<li class="list-item">
<p id="p-9">Community institutions like libraries and museums provide informal, playful, and curiosity-driven environments that can spark reflection and co-learning.</p>
</li>
</ul>
<p id="p-10">Based on this theory, we have been exploring a novel privacy education approach that allows families, schools, and community institutions (such as libraries and museums) to work in partnership to foster meaningful, age-appropriate, and sustained privacy literacy education for children. We believe that privacy literacy education that bridges these spheres is not only more engaging but also more effective.</p>
<p id="p-11">However, we also need to realize that each sphere has its strengths and weaknesses, which leaves room for an exciting research agenda.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Families Are Willing but Need Support</h2>
<p id="p-12">Parents play a crucial role in shaping how children think about privacy. Previously, we categorized five types of parent-child privacy conversations: rule-based, example-based, consequence-based, decision-exposing, and contextual.<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> Most parents in our study relied heavily on rule-based messaging, which they found limited in helping children adapt to unfamiliar digital environments. A mother in our study described how her daughter learned about data tracking through a game that asked to access her photo library. The child asked, “Why does it want my pictures if it’s just a puzzle?” The mother, unsure how to explain, simply said, “Just say no.” The opportunity to discuss targeted advertising or third-party data sharing was lost.</p>
<p id="p-13">In another study, we explored how guided reflection and perspective-taking can make privacy conversations more mutual and less didactic.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> When parents and children were supported to reflect on their own privacy needs and share experiences, conversations became more concrete, emotionally resonant, and memorable. However, many families told us they did not feel confident initiating these conversations on their own. Some parents rely on external authorities (for example, schools, tech companies, or online resources) to “take care of it.”</p>
<p id="p-14">This is why privacy literacy tools for families should be not only simple and engaging for children but also accessible and empowering for parents. Many parents struggle to initiate conversations about online privacy because they themselves feel uncertain. To bridge this gap, tools need to scaffold shared learning, which offers parents and children opportunities to explore privacy concepts together. Metaphors such as “Is your information a diary or a billboard?” invite reflections from parents and children. Games that visualize data sharing with embedded tips and prompts can help parents and children build shared language around privacy.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Schools Must Go Beyond Digital Citizenship Posters</h2>
<p id="p-15">Despite children’s growing exposure to technology, formal privacy instruction in elementary schools remains limited. Prior work by Kumar et al. shows that teachers described frequent use of Google tools, classroom apps, and online platforms, but rarely taught about privacy or data literacy explicitly.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> Instead, privacy concerns were framed around compliance or device management, not student understanding. This is a missed opportunity. Teachers are already engaging with students on digital platforms, but without embedded privacy discussions, children learn to use tools without questioning how those tools use their data and cause privacy issues.</p>
<p id="p-16">However, educators need more than warnings or generic advice, as such information is rarely adaptive to classrooms with diverse needs. In reality, educators need curricular materials and professional development that align privacy education with language arts, science, and social studies, subjects that are already built into the school programs. They also need tools that fit into existing classroom technologies. For example, a reading unit on personal narratives can include a discussion on online identity; a science lesson on ecosystems can introduce data flows between devices, apps, and platforms; and a math class can include activities on algorithmic bias and data aggregation.</p>
<p id="p-17">More importantly, the privacy education in the classroom ideally would also align with the privacy discussions in children’s homes. This is not only a reinforcement of the privacy concepts but also an alternative environment to nudge children to think about what privacy means in different contexts, which will facilitate children’s contextual understanding of privacy and gradually help them build stronger privacy literacy.</p>
<p id="p-18">To accomplish this, the key is to embed “teachable moments” in teachers’ daily teaching routine, which can help teachers guide reflection without needing to build entirely new lessons.</p>
</section>
<section id="sec5" class="sec">
<h2 class="heading">Community Organizations: An Untapped Resource</h2>
<p id="p-19">Libraries, museums, and community centers offer informal learning spaces that are ideal for family-based privacy education. We interviewed eight families who regularly visited museums and libraries and found that these spaces often sparked curiosity and dialogue around privacy topics.<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> One family recalled visiting a museum exhibit that visualized data traveling between apps. Their child asked, “So our tablet is always talking to the Internet?” The exhibit led to a 15-minute family conversation about Wi-Fi, cloud storage, and who sees what. Such moments are rare at home or school but flourish in informal, low-stakes settings.</p>
<p id="p-20">These teachable moments are precious for various reasons. To start with, children come to museums to learn new things. Their mental state is set to absorb new things when they are at the museums, and their parents are also ready to engage with this learning procedure. Moreover, these moments are often the entry point for continuous and deeper learning at home and school.</p>
<p id="p-21">But these approaches also need scaffolding. Museums or libraries can host privacy literacy events, which are interactive events where families can explore privacy concepts through games, stories, and technology demos during their visit. These events can illustrate abstract topics and make them feel relevant, social, and fun. Additionally, take-home reflection cards, age-specific prompts, or digital journals can extend these conversations and connect them with school curriculum or family goals. The latter one, by nature, would require a deep partnership among families, schools, and community organizations so that all stakeholders can work collaboratively and create a well-rounded learning environment to enhance children’s privacy literacy.</p>
</section>
<section id="sec6" class="sec">
<h2 class="heading">A Blueprint for Privacy Literacy Partnerships</h2>
<p id="p-22">As we are advocating for a partnership among families, schools, and community organizations, we reflect on some concrete recommendations for building cross-context, partnership-based privacy literacy education programs.</p>
<section id="sec7" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Recommendation 1:</strong>  Co-design materials across settings. Privacy education tools should be designed with input from families, teachers, and community stakeholders.</p>
</section>
<section id="sec8" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Examples:</strong>  A digital storybook used in school could be paired with a parent reflection guide, or a museum exhibit on data flows.</p>
</section>
<section id="sec9" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Recommendation 2:</strong>  Embed “teachable moments” in everyday tech use. Classroom apps and learning platforms should include prompts or visual cues that help children pause and think.</p>
</section>
<section id="sec10" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Examples:</strong>  “Who might see what I just typed?” “Why does this app want my location?”</p>
</section>
<section id="sec11" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Recommendation 3:</strong>  Create longitudinal privacy learning pathways. Privacy decisions do not happen in one moment. Just as reading proficiency develops over time, so does privacy literacy. Long-term studies and curricula should trace how children develop from “rules-followers” to context-aware privacy actors.</p>
</section>
<section id="sec12" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Example:</strong>  Children’s privacy learning stories that can be shared among all stakeholders.</p>
</section>
<section id="sec13" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Recommendation 4:</strong>  Support families as co-teachers. Provide parents with low-barrier prompts and activities that center children’s voices while guiding reflections, along with accessible resources for easy engagement.</p>
</section>
<section id="sec14" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Examples:</strong>  Dinner table questions, bedtime stories, or screen-time negotiation checklists.</p>
</section>
<section id="sec15" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Recommendation 5:</strong>  Leverage community events. Activities and events with a privacy theme in libraries, science centers, and afterschool programs can reinforce what children learn at home and school. These events should be designed to include entire families, not just children.</p>
</section>
<section id="sec16" class="inline-headings-section">
<p data-jats-content-type="inline-heading"><strong>Examples:</strong>  Interactive exhibit on digital privacy via the Expert Is In program at the Smithsonian National Museum of Natural History by Johns Hopkins University and the University of Notre Dame (Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>), Data Privacy Day at the Carnegie Library of Pittsburgh by Carnegie Mellon University (Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>).</p>
<figure id="F1" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 1. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3762638_fig01.jpg" alt="" data-image-id="F1" data-image-type="figure" data-jats-orientation="portrait" /></div><figcaption><span class="caption-label">Figure 1. </span> <span class="p">The authors (pictured) and collaborators developed an interactive exhibit to teach children about digital privacy at the Smithsonian National Museum of Natural History. Image credit: Will Kirk.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<figure id="F2" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 2. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3762638_fig02.jpg" alt="" data-image-id="F2" data-image-type="figure" data-jats-orientation="portrait" /></div><figcaption><span class="caption-label">Figure 2. </span> <span class="p">The Carnegie Mellon University Privacy Engineering program organized Privacy Day events at the Carnegie Library of Pittsburgh. Image credit: Michael Cunningham.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
</section>
</section>
<section id="sec17" class="sec">
<h2 class="heading">Final Thoughts: Teaching Privacy Is Teaching Agency</h2>
<p id="p-35">At its core, privacy literacy is more than protecting data. It is about teaching children that they have a right to boundaries, a right to ask questions, and a right to make decisions about their digital lives. It is about understanding context, making judgments, negotiating meaning, and navigating power. It is about cultivating agency in a world that often treats children as passive users or invisible data points.</p>
<p id="p-36">These are not skills that can be taught in one setting, by one adult, or through one app. They require practice, reinforcement, and reflection across all the spaces where children live and learn. When families, schools, and communities work together, we can do more than improve test scores. We can empower children to read the world beneath what it looks like on the surface with confidence, curiosity, and care. This is a lifelong skill.</p>
</section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/it-takes-a-village-to-teach-privacy/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Lanjing Liu]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">776441</post-id>	</item>
		<item>
		<title>Resilience Meets Security in Cyber-Physical Systems and Critical Infrastructures</title>
		<link>https://cacm.acm.org/opinion/resilience-meets-security-in-cyber-physical-systems-and-critical-infrastructures/</link>
					<comments>https://cacm.acm.org/opinion/resilience-meets-security-in-cyber-physical-systems-and-critical-infrastructures/#respond</comments>
		
		<dc:creator><![CDATA[Anna Förster, Matthias Hollick, Stefan Katzenbeisser, and Christoph Krauss]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 14:52:43 +0000</pubDate>
				<category><![CDATA[Security and Privacy]]></category>
		<category><![CDATA[Systems and Networking]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776450</guid>

					<description><![CDATA[<p>Addressing safety, resilience, and security as interconnected priorities will better protect cyber-physical systems and critical infrastructures against evolving threats.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">On October 8, 2022, Deutsche Bahn—the German railway—experienced a critical outage of its GSM-R system in northern Germany. Designed to enable communication between signal boxes and engine drivers, GSM-R is a critical safety component. In the event of a disruption in communication, no trains are permitted to operate. Deutsche Bahn segmented its GSM-R cellular network into several regional networks. However, all of them require access to central services to manage GSM-R calls, which are—for reasons of redundancy—available both in Berlin and Frankfurt, connected through fiber to all regional networks. On the day of the outage, fiber cables from the regional network of Hannover to Berlin and Frankfurt were cut at two distant locations within a few hours. After the incident, no GSM-R calls could be established and Deutsche Bahn was forced to shut down operations in northern Germany for more than three hours. This led to cancellation of numerous train services throughout the country. Initially, it was assumed that the damage was the result of critical infrastructure sabotage. However, subsequent investigations revealed that the damage was caused by two uncoordinated vandalism incidents.<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a></p>
<p id="p-2">In February 2022, in parallel to the Russian invasion of Ukraine, unknown (but likely state-linked) attackers targeted the ViaSat satellite communication systems, presumably in an attempt to suppress military communication. The attack caused significant collateral damage to critical infrastructures. It disrupted the remote control of thousands of wind turbines in Germany, some of which remained inoperable for up to a month after the incident.<a class="footnote-link xref xref-fn" href="#FN2" data-jats-rid="FN2" data-jats-ref-type="fn"><sup>b</sup></a></p>
<p id="p-3">On March 21, 2025, Heathrow airport was forced to shut down for a day because of a fire in a substation. Even though the airport is powered by three different substations, the failure of a single one resulted in a loss of power. Approximately 1,200 flights needed to be cancelled and 120 diverted to different airports in the U.K.<a class="footnote-link xref xref-fn" href="#FN3" data-jats-rid="FN3" data-jats-ref-type="fn"><sup>c</sup></a></p>
<p id="p-4">Critical infrastructures and cyber-physical systems (CPS) are integral to our daily life and are becoming increasingly important. Disruptions have serious consequences and can even cause physical harm. Thus, CPS must be designed in a way that ensures dependable operation even in the most challenging circumstances. They have to operate not only in a secure but also in a resilient fashion. NIST SP 800-39 defines resilience in this context to be: “The ability of an information system to continue to: (i) operate under adverse conditions or stress, even if in a degraded or debilitated state, while maintaining essential operational capabilities; and (ii) recover to an effective operational posture in a time frame consistent with mission needs.”<a class="footnote-link xref xref-fn" href="#FN4" data-jats-rid="FN4" data-jats-ref-type="fn"><sup>d</sup></a></p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Resilience and Its Relation to Security and Safety</h2>
<p id="p-5">In contrast to secure systems (which are commonly seen as either in a secure or insecure state), resilient systems have the capacity for graceful degradation and recovery while maintaining essential operational capabilities. This is often illustrated by the resilience cycle shown in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>. For example, if a CPS such as the GSM-R network is damaged (shock/disruption in Figure <a class="xref xref-fig" href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>), its functionality will temporarily decline, potentially to a significant extent. However, under a resilient system design, this would not require shutting down the railway network. Integrated measures could facilitate the automatic recovery of the system, at least to a certain extent, so that trains can continue running, maybe at reduced track capacity and potentially at the cost of utilizing alternative, more error-prone and labor-intensive communication methods. It is even possible that the system will recover to a higher performance level if the system is reconfigured and learns to deal with similar events in the future.</p>
<figure id="F1" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 1. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3768169_fig01.jpg" alt="" data-image-id="F1" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 1. </span> <span class="p">General illustration of the level of performance of a system after shock/disruption showing failure, recovery, and learning process. The black curves visualize a traditional (non-resilient) system design. The green curves show a resilient system design.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-7">Attacks on CPS have the potential to result in a range of consequences, including those related to safety, operations, finances, and privacy. Safety risks arise when compromised systems, especially in sectors such as healthcare, transportation, or industry, endanger lives.</p>
<p id="p-8">From an operational standpoint, cyber attacks can disrupt processes, degrade functionality, and cause costly periods of downtime. From a financial perspective, cyber attacks can result in direct costs for response efforts or the resolution of liability cases, as well as indirect costs, such as reputational damage. In the event of a privacy breach, sensitive information may be exposed, thereby violating regulations such as the General Data Protection Regulation (GDPR) and incurring penalties. We argue that safety, resilience, and security must be addressed as interconnected priorities rather than separate concerns. Without strong cyber resilience, organizations face risks that threaten their stability, trustworthiness, and long-term success. This applies not only to large companies and infrastructures, such as smart cities, but also to start-ups in sectors like smart homes, and even to unique scenarios like smart farming. In recent years, many Information and Communication Technology (ICT) systems started to aim for security-by-design. However, today’s focus in securing systems is to prevent attacks such as eavesdropping, unauthorized access, or data tampering through mechanisms like encryption, firewalls, and intrusion detection systems. Yet, these same security mechanisms can inadvertently compromise the system’s ability to maintain functionality and recover from disruptions. For example, in an energy grid, encryption ensures confidential communication between grid control systems and devices, whereas firewalls block unauthorized access. However, if these security measures are overly rigid or fail under specific conditions (for example, if a misconfigured firewall blocks legitimate traffic or a key management failure renders encrypted data inaccessible), they can cause critical systems to stop functioning. Even though the energy grid is then “secure” from cyber attacks, it may become inoperable, which could lead to a widespread power outage. In this context, resilience would require balancing security with robustness, such as implementing fallback systems, redundancy, and mechanisms that ensure functionality (albeit in a limited capacity) even if security protocols fail. This highlights that a secure system is not automatically resilient, as the two concepts address different aspects of system reliability.</p>
<p id="p-9">In a similar way, a safe system may not necessarily be resilient. The example of GSM-R at the beginning of this Opinion column demonstrates this: despite its redundant design, the system failed.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Ways Toward Jointly Resilient and Secure CPS</h2>
<p id="p-10">Achieving resilience for CPS requires a multifaceted technical approach that prepares systems not only to withstand but also to adapt and recover from cyberattacks. In general, classical security mechanisms like multi-factor authentication, access control, zero-trust principles, and defense-in-depth are essential components, yet they are insufficient when deployed on their own to ensure resilience. Redundancy and adaptability are crucial: CPS should be designed with built-in redundancy to maintain operational continuity, potentially at a reduced functionality, in the event of a breach or failure. For example, detailed recovery plans can outline steps to revert to a safe operational state or switch to backup components when primary systems are compromised. Modular system design in combination with the ability for decentralized operation can help to further increase adaptability. Redundancy should consider diversity such that vulnerabilities cannot affect all redundant instances at a time. </p>
<p id="p-11">However, redundancy can also increase the attack surface, as can the deployment of security software. Envision a smart energy system using two distinct communication networks, one primary and one backup, to connect substations and control centers. If these networks share software vulnerabilities, an attacker can potentially compromise both communication paths using the same exploit. Diversifying technologies for communications or adding security software (sometimes required for compliance reasons) can increase the risk as well: more software means more potential vulnerabilities. Lastly, managing and securing multiple redundant systems introduces additional complexity, which could lead to misconfigurations and other vulnerabilities; the disastrous CrowdStrike incident being the prime example, how a poorly tested software update affected millions of servers and all sectors of critical infrastructure worldwide.<a class="footnote-link xref xref-fn" href="#FN5" data-jats-rid="FN5" data-jats-ref-type="fn"><sup>e</sup></a> Compartmentalization allows to isolate system components from one another, thereby limiting the impact of breaches and preventing threats from cascading across interdependent systems. Fault detection and identification is needed to quickly discover threats and problems and automatically handle them.</p>
<p id="p-12">CPS-specific resilience demands new testing and validation methodologies. At the moment, automated testing methodologies are significantly less mature in this domain than those in traditional IT. Nevertheless, rigorous testing is essential to identify vulnerabilities specific to the physical aspects of CPS operations. In addition, user interfaces that communicate security status and offer easy-to-understand alerts and controls are crucial for assisting operators in identifying and managing potential threats in real time, thereby improving both response and adaptability in the face of shocks and disruptions. Together, these strategies foster a CPS environment that is secure, adaptable, and resilient in the face of evolving cyber threats. However, integrated resilience also requires clear prioritization of functionality over all other aspects and trade-offs, which is a challenging aspect to design and agree upon.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Cyber Resilience Strategies, Building Capacity, and Raising Awareness for Resilience in CPS</h2>
<p id="p-13">The increasing importance of cyber resilience is becoming evident in national and supranational cybersecurity/cyber resilience strategies. The 2021 report <i>Singapore Cybersecurity Strategy</i><a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> was among the first to offer a clear definition of cyber resilience, and notably incorporates considerations for cyber-physical systems (CPS). Similarly, the 2024 U.S. report <i>Strategy for Cyber-Physical Resilience: Fortifying Our Critical Infrastructure for a Digital World</i><a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> emphasizes the cyber-physical dimension of resilience, focusing on actionable recommendations to strengthen critical infrastructure within the U.S. The <i>NIS2 Directive3</i> represents the E.U.’s updated cybersecurity framework, imposing stricter requirements on essential and important entities—including operators of cyber-physical systems in sectors like energy, transport, and healthcare—to strengthen both digital and operational resilience. The goal of NIS2 is to ensure effective prevention, management, and recovery from disruptions within these interconnected systems. In contrast, the latest version of the European Union’s 2024 <i>Cyber Resilience Act</i> (CRA)<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> lacks a clear definition of cyber resilience, primarily focusing on cybersecurity requirements for products with digital elements. While the digital leaders have recognized that cybersecurity and cyber resilience are tightly intertwined, many other countries currently lack strategic-level discussions regarding cyber resilience.</p>
<p id="p-14">In addition to technical approaches and solutions needed to achieve and ensure resilience in modern CPS systems, it is equally important to raise general awareness of the issue. This heightened awareness ensures technical solutions are not only developed but also effectively utilized and implemented, preventing them from remaining mere technical publications in scientific venues.</p>
<p id="p-15">There are several ways to enhance developers’ awareness, for example, integrating relevant topics into educational curricula and promoting life-long learning, developing and enforcing robust backup and recovery plans, and implementing regulation and standardization, such as presented in Figure <a class="xref xref-fig" href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">2</a>. Currently, college and university programs are rather rigid, with new topics only slowly finding their way to all students. Furthermore, while curriculum recommendations in electrical engineering and computer science often include security, resilience is not directly addressed. In terms of standardization and regulations, software and integrated information systems, such as CPS, lag behind their hardware counterparts, which have long-established safety standards (for example, the CE marking on electrical devices). Fortunately, existing legislation is undergoing changes to include software liability—a much-needed step toward greater resilience (the new EU Product Liability Directive<a class="footnote-link xref xref-fn" href="#FN6" data-jats-rid="FN6" data-jats-ref-type="fn"><sup>f</sup></a>).</p>
<figure id="F2" class="fig" data-jats-position="float">
<div class="image-container"><img decoding="async" class="graphic" title="Figure 2. " src="https://cacm.acm.org/wp-content/uploads/2026/01/3768169_fig02.jpg" alt="" data-image-id="F2" data-image-type="figure" /></div><figcaption><span class="caption-label">Figure 2. </span> <span class="p">Resilience can only be achieved if technical innovation works hand-in-hand with curriculum integration, standardization/regulation, and lifelong learning. The individual steps are overlapping and continuous.</span></p>
<div class="figcaption-footer"> </div>
</figcaption></figure>
<p id="p-17">These four dimensions must be addressed together to achieve meaningful progress. For instance, even if developers recognize the need to create recovery plans for their products or services, a lack of knowledge about how to design and implement them effectively could lead to failure. Similarly, if recovery plans are not mandatory or if their quality is not governed by standards, companies may lack sufficient motivation to invest in them, particularly under financial or time constraints.</p>
<p id="p-18">Good examples from other sectors illustrate the potential impact of such efforts. For example, training and life-long learning programs for pilots or operators of other high-risk machinery have been shown to effectively reduce risks. Similar initiatives must be undertaken in the CPS sector, where systems are rapidly evolving into similarly complex and high-risk environments, such as autonomous vehicles.</p>
</section>
<section id="sec5" class="sec">
<h2 class="heading">Outlook</h2>
<p id="p-19">To achieve CPS resilience, it is essential that researchers and practitioners from different communities engage in collaborative discourse, not only concerning innovative solutions but also practical trade-offs and priorities. While technical innovation is still needed in many fields, it also needs to be integrated into teaching curricula and into new standards and regulations. Lifelong learning ensures that innovation is quickly integrated into existing systems and companies.</p>
<p id="p-20">By adopting a holistic view that integrates resilience and security, we can better protect CPS and critical infrastructures against evolving threats, ensuring their reliability and stability in the face of both anticipated and unforeseen challenges. Promising initiatives are already under way but must be supported, expanded, and embraced at all levels and by all stakeholders.</p>
</section>
<section id="sec6" class="sec"></section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/resilience-meets-security-in-cyber-physical-systems-and-critical-infrastructures/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Matthias Hollick]]></dc:creator>
      <dc:creator><![CDATA[Stefan Katzenbeisser]]></dc:creator>
      <dc:creator><![CDATA[Christoph Krauss]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">776450</post-id>	</item>
		<item>
		<title>Driven to Distraction</title>
		<link>https://cacm.acm.org/kode-vicious/driven-to-distraction/</link>
					<comments>https://cacm.acm.org/kode-vicious/driven-to-distraction/#respond</comments>
		
		<dc:creator><![CDATA[George Neville-Neil]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 14:45:30 +0000</pubDate>
				<category><![CDATA[Computing Profession]]></category>
		<category><![CDATA[Software Engineering and Programming Languages]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775515</guid>

					<description><![CDATA[<p>The problem with a simplifying assumption is that it can make for inefficient or patently illogical software.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1"><b>Dear KV,</b></p>
<p id="p-2">I know you have mentioned working on embedded systems in the past, and now that I have a related project, I have a question for you. The device we are building has a lot of sensors and I have been slowly adding support for these to our embedded Linux kernel. Each device samples data from the environment, and they are each a bit different, but the only common drivers that seem to match what we do are character drivers that just generate a stream of bytes. It seems strange to take a lot of floating-point data, turn it into characters, and then turn it back into floating point. Is this common? Or am I missing some type of driver that would do this better?</p>
<p id="p-3" data-jats-content-type="pull-right"><b>Floating</b></p>
<p id="p-4"><b>Dear Floating,</b></p>
<p id="p-5">I remember when I was preparing for my first talk years ago, people would tell me, “Start with a joke.” So, here is one for this occasion:</p>
<blockquote class="disp-quote">
<p id="p-6"><b>Three hardware designers go to see an OS developer.</b></p>
<p id="p-7"><b>The first hardware designer</b> says, “I just developed a new device and I need a driver.”</p>
<p id="p-8"><b>OS developer:</b> “Sure, what does it do?”</p>
<p id="p-9"><b>First hardware designer:</b> “It reads GPS data and correlates it with star charts from a visible telescope.”</p>
<p id="p-10"><b>OS developer:</b> “You should write a character driver.”</p>
<p id="p-11"><b>The second hardware designer</b> says, “My new device takes temperature readings to five significant digits from across a square kilometer of ocean at depths of 1 to 100 meters.”</p>
<p id="p-12"><b>OS developer:</b> “Oh, so you need a character driver too.”</p>
<p id="p-13"><b>The third hardware designer</b> says, “My device samples quantum states throughout the known universe. It can literally see the face of god, should such exist.”</p>
<p id="p-14"><b>OS developer:</b> “Character driver!”</p>
</blockquote>
<p id="p-15">Alas, some jokes require a very specialized audience, but in this case I think the audience is receptive.</p>
<p id="p-16">The thing is, once upon a time, operating systems handled many different types of data, and they did so in sometimes wildly incompatible ways. This was a problem because it meant applications had to be ported whenever a new operating system version came out or whenever someone got a new model computer.</p>
<p id="p-17">The “everything is a byte stream, we don’t care what the format of your data is” ethos of early Unix had some very real benefits in that it allowed programs to be ported to different machines and different versions of Unix to be used with few or no changes.</p>
<p id="p-18">But, of course, every good fairy tale also has a dark side—at least if you read the original Grimm. And here, the problem with a simplifying assumption is that it can make for inefficient or, in your case, patently illogical software. Converting a number (which is what a computer is great at processing) into a string (which a computer is not ideally suited for) and then back to a number wastes time, memory, and CPU cycles—the very three things we’re all told never to waste in our software!</p>
<p id="p-19">KV’s particularly favorite form of this stupidity: one of the best-known and most commonly used protocols for sending stock-ticker information does exactly this—that is, it converts numbers to strings and then back to numbers. This ridiculous scenario led finance companies to invest heavily in FPGAs (field-programmable gate arrays) just to get an edge in processing stock prices for high-frequency trading. KV was both appalled when he learned this and chagrined that he hadn’t bought stock in certain FPGA companies soon enough.</p>
<p id="p-20">All of which is to say that sometimes, simplifying assumptions are a real problem, and sometimes, they make everything look like a nail, which then makes you think all you need is a hammer. The big challenge with modern systems is that 50 years of doing things the Unix way has left us bereft of better APIs. It is not just the drivers but also the application APIs on top of the operating system that deal only in byte streams. It is as if the operating system designers threw up their hands and said, “Not my job!” and left all the data interpretation to the application programmers and device developers. Since these two parties rarely, if ever, talk to each other, no real progress has been made in this area from that time until now.</p>
<p id="p-21">So, how might we make progress? The current fad for kernel bypass libraries addresses the matter by just ignoring the operating system altogether—which, as an operating system developer myself, I can totally understand. We must either deal with the operating system through modification or extension, bypass it, or start over from scratch by writing a new one. This last option is the most attractive to an operating system developer, but KV doubts your employer will sign up for the associated multiyear project. But if they do, please get in touch with me!</p>
<p id="p-22">Your most expedient but least preferable solution would be to bypass the operating system since you can write a few APIs that allow your applications to talk efficiently with the devices. Bypassing gives you the most control, the highest fidelity of data, the lowest latency of access—but all at the price of generality. That is, when you bypass the operating system, you make it so that each new program must, again, be compatible with your bypass libraries. And if you want generality back, you wind up doing what operating system developers have done forever, which is to produce generalized APIs that can be consumed by arbitrary programs. The current middle ground is to add new system calls to the operating system—a process that is fraught with peril, because modern operating systems are huge and fragile. While people do add new system calls to operating systems, this is a rare event. And, if you were to do this, you would wind up maintaining the new syscalls locally for a very long time unless you were able to convince an open source project that your new calls were generally useful.</p>
<p id="p-23">So, that is where you are: Make a character device driver and pay the cost of converting real data into strings, bypass the operating system, or innovate in the operating system space and produce some new system calls. I cannot say any of these choices are great. In fact, they all have their downsides in one way or another. But innovation in operating systems went out in the 1980s, and the people who are trying to bring that back now have a more difficult job.</p>
<p id="p-24" data-jats-content-type="pull-right"><b>KV</b></p>
<p data-jats-content-type="pull-right"> </p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Related articles</h2>
<p id="p-25"><strong>In Praise of the Disassembler<br /></strong><a class="ext-link" href="https://queue.acm.org/detail.cfm?id=3469121" data-jats-ext-link-type="uri">https://queue.acm.org/detail.cfm?id=3469121</a></p>
<p id="p-27"><strong>The Unholy Trinity of Software Development<br /></strong><a class="ext-link" href="https://queue.acm.org/detail.cfm?id=3014148" data-jats-ext-link-type="uri">https://queue.acm.org/detail.cfm?id=3014148</a></p>
<p id="p-29"><strong>Kode Vicious Gets Dirty<br /></strong><a class="ext-link" href="https://queue.acm.org/detail.cfm?id=1071723" data-jats-ext-link-type="uri">https://queue.acm.org/detail.cfm?id=1071723</a></p>
</section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/kode-vicious/driven-to-distraction/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">775515</post-id>	</item>
		<item>
		<title>Cyber Insurance, Software Diversity, and AI Coders</title>
		<link>https://cacm.acm.org/opinion/cyber-insurance-software-diversity-and-ai-coders/</link>
					<comments>https://cacm.acm.org/opinion/cyber-insurance-software-diversity-and-ai-coders/#respond</comments>
		
		<dc:creator><![CDATA[Carlos Barreto and Ulrik Franke]]></dc:creator>
		<pubDate>Wed, 28 Jan 2026 14:30:01 +0000</pubDate>
				<category><![CDATA[Security and Privacy]]></category>
		<category><![CDATA[Software Engineering and Programming Languages]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775522</guid>

					<description><![CDATA[<p>Software diversity, introduced in the right places, may break the economies of scale that make cyber-crime so lucrative.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Cyber insurance has been seen as a crucial tool in cybersecurity for two reasons: First, insurance against cyber incidents provides financial stability once an incident occurs, covering losses and offering services to recover systems (for example, investigation of incidents, legal defense, ransomware negotiations). Second, cyber insurance creates incentives for security by requiring security standards to get insurance at all, and by premium discounts to customers with better security.</p>
<p id="p-2">However, cyber insurance has not grown as expected, and may now be at a turning point. The culprits are two characteristics of cyber risks: First, the difficulty to quantify rapidly evolving cyber risks based on historical data—needed for premiums to match actual risk. Second, the potential for incidents to spread between those insured, creating correlated losses and increasing the risk of multiple simultaneous insurance claims, known as accumulation risk.</p>
<p id="p-3">In general, insurance assumes some independency between events, enabling portfolio risk management. Concretely, although the cost of a single event is uncertain, the average cost of multiple events can be estimated accurately. Thus, by pooling risks, an insurer can charge a fixed premium and have high certainty of being able to cover future claims. But as noted previously, some cyber risks are dependent. For instance, the NotPetya attack exploited security flaws in multiple computers and leveraged the networked nature of IT systems to propagate globally.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a></p>
<p id="p-4">Such accumulation risk was identified as a main barrier for insurance coverage a long time ago,<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> and it remains so today, in the age of ransomware. In the past, insurers have reacted to widespread cyberattacks by excluding losses resulting from state sponsored cyberattacks. Disagreements interpreting policy exclusions have led to legal disputes, such as the litigation between Merck and insurance companies who declined coverage associated with the NotPetya malware—eventually settled in favor of the insured. Thus, if accumulation risks cannot be managed, cyber insurance may become too expensive or have too many exclusions to be meaningful or customers may be refused insurance altogether.</p>
<p id="p-5">Now, natural catastrophes, epidemics, and terrorism also exhibit accumulation risk, but can still be insured using the international reinsurance market. Although an earthquake may create many national claims simultaneously, internationally it may be an isolated event—earthquakes do not propagate from Italy to California. Likewise, terrorism has been insured with national governments as reinsurers of last resort. Similar approaches are possible for cyber insurance as well.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> However, the man-made nature of cyber incidents also opens another interesting avenue—changing the nature of the risks: in this <i>Communications</i> Opinion column, we explore this idea further.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Revisiting Software Diversity</h2>
<p id="p-6">Though risks can rarely be reduced to zero, sometimes there is an opportunity to mitigate their consequences. For example, construction standards can reduce losses from earthquakes and moderate use of alcohol and tobacco can reduce future health issues. However, natural disasters or genetic disorders prevent us from avoiding these risks completely. Similarly, cyber risks cannot be completely avoided, but we claim that they could be controlled to a greater extent. In particular, some security practices that promote <i>software diversity</i> may change intrinsic properties of cyber risks; especially their correlation. (To be clear, software diversity is not diversity in the sense of DEI parlance. However, the fact that software diversity can improve resilience, at least in some circumstances, may be a valuable lesson also in other contexts.)</p>
<p id="p-7">Software diversity is a longstanding strategy for fault-tolerance that creates redundancy multiple components that have identical external behavior but different internal mechanics. This reduces the probability of having identical faults in two versions of a component. This is crucial for cybersecurity, as it can prevent the reuse of attacks and limit the spread of malware that exploits particular vulnerabilities, just as more biodiverse populations are more resilient to biological viruses.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> Concretely, diverse systems can be more resilient to various attacks and also take longer to compromise.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a></p>
<p id="p-8">Some software diversity is natural as computing systems are often built with different operating systems, web servers, and database management systems. Indeed, continuously updated libraries may make it very difficult to compile identical versions of programs at different points in time. However, deliberate effort is needed to reach significant protection. Thus, the literature has focused on how to intentionally introduce software diversity, and on managing the resulting systems.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> The most well-known software diversity mechanism is probably Moving Target Defense (MTD), a family of mechanisms that gained fame through the development and deployment of address space randomization in popular operating systems approximately 20 years ago.</p>
<p id="p-9">The essence of moving target defense is to take advantage of the asymmetric knowledge of attackers and defenders.<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> This is done by introducing randomness, such as changing the network structure or the low-level execution of a program. Such changes to the attack surface can improve security, first, because attacks may take longer (changes in the system can create setbacks in the progression of the attack), and second, because randomness in execution or operation can prevent the reusability of attacks.</p>
<p id="p-10">While there is much academic work on software diversity, there is reason to believe that it is not yet employed to its full potential in practice. To be sure, some applications such as address space randomization are widely employed and others like <i>N</i>-version programming—where <i>N</i> independent implementations must agree to make critical decisions—are used in niches. But there has not been enough research on software diversity metrics, on the interplay between hardware and software diversity, on the theoretical underpinnings of software diversity, or on how it relates to other dependability and security attributes.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> In practice, the difficulties and costs of managing truly diverse systems—maintaining parallel setups of various hardware, operating systems, languages, compilers, and external libraries, and pushing all of this through automated testing regimes, deployment processes, and user support—have often not seemed worth the benefits. But this need not necessarily hold true in the future.</p>
<p id="p-11">Security mechanisms often aim for more security in a technical sense—to decrease the number of successful attacks. It is easy to jump to the conclusion that if the number of successful attacks is <i>not</i> decreased, the security mechanism is a failure. But this is premature! Even if, pessimistically, software diversity mechanisms make systems just as good or bad as systems with less software diversity <i>on average</i>, software diversity mechanisms might introduce the randomness needed to decrease the correlation of incidents. This would be the equivalent of turning a global natural disaster into several smaller, local events. From a myopic perspective this may look like a questionable gain, but crucially, this may be enough to turn uninsurable systems into insurable ones. Adopting a wider perspective, this may be a considerable gain for society-at-large, including those affected, who would not need to stockpile cash to self-insure (or go bankrupt if they do not) but can instead pay affordable insurance premiums. Enabling insurance markets is a boon—hence the concern and worry about cyber insurance being increasingly unavailable.</p>
<p id="p-12">Taking this possibility of insurance into account, reducing the <i>correlation</i> between events can be more important than reducing the <i>impact</i> of individual incidents. Making risks less heavy-tailed may also make them easier to estimate,<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> entailing more accurate premiums (current premiums are not actuarial<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a>). This suggests that more software diversity could be a game-changer for cyber insurance. Optimistically, requiring software diversity to get insurance could trigger a cascade effect reaching multiple industries, provided that multiple insurers or other players with considerable market power (for example, a reinsurer or a government) adopt such policies. More pessimistically, firms may try to game the system and adopt software diversity only to qualify for insurance coverage, neglecting other security controls. The result of the pessimistic scenario would be an ecosystem with diverse but insecure systems. Though hardly optimal, even this may nevertheless be preferable to the current ecosystem of non-diverse and insecure systems—the silver lining being that premiums in the more diverse ecosystems would better reflect real risks, thus eventually providing that argument needed to force boards to invest in security, long coveted by CISOs.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Software Diversity at a Discount?</h2>
<p id="p-13">As previously mentioned, software diversity may have struggled in practice, because of quality and reliability concerns and because of perceived costs. Development, testing, deployment, patching, and support becomes more difficult. Furthermore, diversification interventions can degrade performance, such as execution time. Indeed, the randomness, which is the hallmark of software diversity, may from another perspective be the definition of poor quality.</p>
<p id="p-14">Nevertheless, one reason to revisit software diversity and MTD today is that advances in AI, applied to code generation, can reduce the cost of software diversity. At the moment, there is a flurry of academic and practitioner interest in how AI-assisted code generation tools, such as GitHub Copilot, Amazon CodeWhisperer, and ChatGPT can boost productivity. Of course, the code generated by such tools is not free from errors, and it may be that the greatest productivity boost comes not from replacing human software engineers but from finding the best way to combine human and artificial intelligence. But while the general problem of AI code generation and how to best use it in organizations is multi-faceted, our concern here is first and foremost code diversity, and as it turns out, some such diversity is very straightforward to achieve with AI code generation methods. For example, AlphaCode generates many potential solutions for a single problem, with different execution times and memory usage, and then goes on to filter out a small set of—probably—correct programs.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> Thus, if an <i>n</i>-fold increase in software diversity 10 or 20 years ago may have required hiring (almost) <i>n</i> times more coders, this is no longer the case. Automated code generation cannot make software diversity measures free—especially not when the complexity of testing, deployment, patching, and so forth is taken into consideration—but it can make some versions of it much cheaper.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">A Confluence Requiring Governance</h2>
<p id="p-15">Cyber insurance offers important potential benefits, but has been a disappointment because of correlated losses. Correlated losses can be addressed using software diversity, but such measures have failed to succeed in practice because they are too cumbersome and expensive. Now, advances in automated code generation could make software diversity much cheaper. This leads to the question: Is automated code generation now cheap and reliable enough to enable enough software diversity to salvage cyber insurance? While we believe this is a very pertinent question to ask, the answer is not obviously positive. The costs of software diversity mechanisms—though smaller—may still be too large. AI-driven software diversity measures might face resistance within development teams or organizations who may be hesitant to trust automated processes for critical code. While in theory, insurers should be pushing for software diversity to disassemble accumulation risk, their market power and technical know-how may be too small. Intelligent attackers may circumvent the software diversity introduced.</p>
<p id="p-16">Nevertheless, we believe there is a very interesting confluence here, one that merits attention from practitioners and academics alike. Start with the research questions. Many previously identified knowledge gaps remain, for example, proper metrics, the interplay between hardware and software diversity, and how it relates to other dependability attributes.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> But the cyber insurance context entails a new important perspective: How should software diversity look if it is enough to bring down the <i>variance</i> rather than the <i>mean</i> of the damage caused by cyber threats?</p>
<p id="p-17">Turning to practitioners, the big question is one of governance. If enterprises in some particular sector—private or public—are currently denied cyber insurance, can they introduce software diversity to make themselves insurable? Individual enterprises may struggle to do so, but collectively, it is not impossible to introduce new standards or put pressure on vendors for software diversity. To do so, however, they may need insurers and possibly also regulators onboard from the very beginning, to make the business case. Ultimately, a balance must be struck between the benefits and challenges. Software diversity may not be a panacea for everyone to embrace. But if introduced in the right places, it may break the economies of scale that make cyber-crime so lucrative. As such, it is certainly worth exploring.</p>
</section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/cyber-insurance-software-diversity-and-ai-coders/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Ulrik Franke]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">775522</post-id>	</item>
		<item>
		<title>AI Red-Teaming Is a Sociotechnical Problem</title>
		<link>https://cacm.acm.org/research/ai-red-teaming-is-a-sociotechnical-problem/</link>
					<comments>https://cacm.acm.org/research/ai-red-teaming-is-a-sociotechnical-problem/#respond</comments>
		
		<dc:creator><![CDATA[Tarleton Gillespie, Ryland Shaw, Mary L. Gray, and Jina Suh]]></dc:creator>
		<pubDate>Wed, 21 Jan 2026 22:27:53 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[Computing Profession]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=776481</guid>

					<description><![CDATA[<p>If we hope to improve red-teaming outcomes as part of a sociotechnical system, we must study how its judgments are made and by whom.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Large language models (LLMs) and image diffusion models have emerged rapidly—from research projects into the engines behind the current global deployment of generative AI. When a technology jumps this quickly from experimental plaything to widely available consumer service, many other elements settle in around it, often without much forethought; these include interfaces, policies, business models, labor arrangements, infrastructural assurances, complementary technologies, public claims, advertising campaigns, and regulations. Many of these decisions, arrangements, and infrastructures may turn out to be just as consequential for users and the broader public as the core technology itself. But the boisterous promises and debates that surround the new technology can obscure these other essential elements—elements that make technologies much more than the sum of their engineered parts.</p>
<p id="p-2">To keep pace, researchers studying the workings and implications of these technologies across computer science, engineering, the social sciences, humanities, and law must gear up just as quickly, focusing on not only the core technology but also the sociotechnical system taking shape around it<a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a>—and they need to work together. In this article, we call upon computer scientists and social scientists alike to pay closer, critical, collaborative attention to one part of AI development: <i>red-teaming</i>.<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a></p>
<aside class="boxed-text">
<div class="article-key-insights">
<h2>Key Insights</h2>
<ul class="list" data-jats-list-type="bullet">
<li class="list-item">
<p id="p-3">Red-teaming is already settling in as an essential step in the development of generative AI models, but it has not been sufficiently examined as a sociotechnical element of AI.</p>
</li>
<li class="list-item">
<p id="p-4">A sociotechnical lens highlights red-teaming as a particular arrangement of human labor that unavoidably introduces human value judgments into technical systems, and can pose psychological risks for those who do this work—challenges similar to those faced by practitioners of content moderation.</p>
</li>
<li class="list-item">
<p id="p-5">Studying the technical, social, critical, and policy dimensions of red-teaming, and of AI as an emerging sociotechnical system, will require a coordinated network of scholars from the full range of the computational and social sciences.</p>
</li>
</ul>
</div>
</aside>
<p id="p-6">AI models and their applications typically undergo internal testing before release, and continue to be evaluated during use; one part of this testing, red-teaming, probes these applications for exploitable vulnerabilities, errors, and bias. From an AI-evaluation vantage point, red-teaming needs to be well-designed, effective, and replicable. But from a sociological vantage point, red-teaming is something else as well: a specific kind of labor, done by specific sets of people, in specific institutional contexts, with its own specific set of implications.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B26" data-jats-ref-type="bibr" data-jats-rid="B26"><sup>26</sup></a> Our aim is to shed light on these sociotechnical elements, and to call for more cross-disciplinary attention to this critical component of AI development.</p>
<p id="p-7">Since the commercial launch of ChatGPT, red-teaming has been quickly normalized as a step in the production and deployment of generative AI models. AI developers champion it as proof of their public responsibility, while regulators count on it as a bulwark preventing AI from inflicting social harms. But the public knows precious little about how this work is conducted, upon what values and assumptions it is based, who is enlisted to do it, or the psychological costs they bear. This was also the case with content moderation: Hidden from public and critical scrutiny, its labor and well-being concerns were long overlooked. At the same time, the opacity of these value judgments soon became a political liability for social media platforms. And, given that what little the public does know about AI red-teaming comes largely from Silicon Valley’s own promotional materials, and that the changing political climate, particularly in the U.S., may discourage such outward performances of responsibility, the public may soon know even less.</p>
<p id="p-8">It is worth noting that this article is not based on any information internal to Microsoft. Rather, our observations are drawn from our recent studies of the labor behind responsible AI,<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B41" data-jats-ref-type="bibr" data-jats-rid="B41"><sup>41</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B42" data-jats-ref-type="bibr" data-jats-rid="B42"><sup>42</sup></a> the politics of generative AI as a new media technology,<a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> and participatory approaches to AI development and governance.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a><sup>,</sup><a class="footnote-link xref xref-fn" href="#FN2" data-jats-rid="FN2" data-jats-ref-type="fn"><sup>b</sup></a> And, being trained in science and technology studies, labor, psychology, and design, we feel it is important to contextualize AI red-teaming within longer histories of scholarship that reckon with the social construction of new technologies.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">What Is Red-Teaming?</h2>
<p id="p-9">Broadly, <i>red-teaming</i> means testing the safety and security of a system by methodically probing it as an adversary would. The U.S. military coined the term to describe the technique of assigning members of one’s own forces to act as the enemy during wargames and simulations, probing defensive strategies for potential weaknesses. During the Cold War, that presumed enemy was the Soviet Union, hence the color red.<a class="reference-link xref xref-bibr" href="#B40" data-jats-ref-type="bibr" data-jats-rid="B40"><sup>40</sup></a> But Zenko suggests that the idea of adversarial testing extends back much farther, noting that in the 13<sup>th</sup> century the Catholic church established the “Devil’s Advocate,” who interrogated those nominated for sainthood. Just as the Devil’s Advocate aimed to poke holes in nominees’ candidacies, military red teams attempted to infiltrate their own forces’ front lines.</p>
<p id="p-10">The term migrated to the field of cybersecurity. Red teams were tasked with infiltrating information systems to simulate worst-case scenarios, such as the theft of sensitive information or hacks on infrastructure, that might lead to financial or operational disaster.<a class="reference-link xref xref-bibr" href="#B40" data-jats-ref-type="bibr" data-jats-rid="B40"><sup>40</sup></a> Red teams became an important element of systems security, that might even pay for themselves by anticipating and thereby preventing breaches.<a class="footnote-link xref xref-fn" href="#FN3" data-jats-rid="FN3" data-jats-ref-type="fn"><sup>c</sup></a></p>
<p id="p-11">For generative AI, red-teaming sometimes concerns the security of the foundation model, but increasingly it also means purposefully provoking the model to produce undesired or incorrect responses. Because users might either intentionally or inadvertently prompt an AI model to generate hateful, pornographic, vile, or biased responses, red teams attempt to do so first, acting as a kind of adversary to the intended or presumed use. By preemptively tempting the AI model to say things it should not, they can document how to shore up the safety architectures meant to prevent such responses. Still, what constitutes AI red-teaming remains fuzzy, given that its tactics and organizational structures are still forming. Its familial resemblance to evaluation, social engineering, bug bounties, threat assessments, and penetration testing is still “being discovered.”<a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a> Other terms from cybersecurity and hacker lingo describe much the same project: Google describes their AI Red Team as “ethical hackers,” a nod to venerable “white hat” hackers-for-hire who hunt for technical insecurities.<a class="footnote-link xref xref-fn" href="#FN4" data-jats-rid="FN4" data-jats-ref-type="fn"><sup>d</sup></a></p>
<p id="p-12">Some assert that red-teaming is essential to AI, and is the surest way to safeguard equitable and responsible AI development. Others worry that red-teaming and the guardrails it produces are a kind of “security theater,” more performative than substantive,<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> meant to obscure the reckless deployment of harmful technologies to the public. Still others suggest that such efforts to police AI models will hinder the true potential of the technology, ultimately leading to “woke AI.”<a class="footnote-link xref xref-fn" href="#FN5" data-jats-rid="FN5" data-jats-ref-type="fn"><sup>e</sup></a></p>
<p id="p-13">But in blunt economic terms, the first AI company to successfully “tame” their generative AI products through such safeguards could well capture the market. Business clients are asking for AI-powered customer service chatbots that do not hallucinate<a class="footnote-link xref xref-fn" href="#FN6" data-jats-rid="FN6" data-jats-ref-type="fn"><sup>f</sup></a> and productivity tools that behave consistently.<a class="footnote-link xref xref-fn" href="#FN7" data-jats-rid="FN7" data-jats-ref-type="fn"><sup>g</sup></a> There are enormous financial, reputational, and regulatory incentives to make generative AI tools safe and value-transparent, pushing these companies to rapidly institute red teams—arguably, faster than researchers concerned about the politics of AI can follow.</p>
<p id="p-14">Red-teaming also offers a kind of reassurance, easing fears held by the public, governments, and financial stakeholders about the safety and performance of generative AI systems. New AI products are often touted as having been tested by red-teamers before a wider release.<a class="footnote-link xref xref-fn" href="#FN8" data-jats-rid="FN8" data-jats-ref-type="fn"><sup>h</sup></a> The U.S. federal government (briefly) adopted the language of red-teaming as an important assurance of the safety of AI systems. In October 2023, President Biden issued an Executive Order that reinforced the importance of red-teaming as part of a proposed system of federal oversight over AI: “Any foundation model that poses a serious risk to national security, national economic security, or national public health and safety&#8230;must share the results of all red-team safety tests.”<a class="footnote-link xref xref-fn" href="#FN9" data-jats-rid="FN9" data-jats-ref-type="fn"><sup>i</sup></a> That order has since been rescinded, but red-teaming will likely appear in subsequent efforts to regulate, or self-regulate, generative AI.</p>
<p id="p-15">As a new labor formation, developing under financial and political pressure, red-teaming echoes other contingent forms of digital labor, such as data labeling, content moderation, and enrichment services of all kinds—all arrangements for supporting the semi-automation of human judgment critical to data-driven technical systems. If we want AI that is not only safe and secure but also sustainable, we need to study the labor arrangements emerging that are critical to it: the mix of internal teams testing out AI products, volunteers convened at hack-a-thon-like events, third-party crowdwork vendors, and professional security firms. And, as we learned in the case of social media, we must attend to the psychological costs of the work asked of red teams charged with making AI safe, secure, and useful for everyone.</p>
<p id="p-16">Rather than focus exclusively on implementing and improving it, for the sake of the model, we need to better understand red-teaming as a practice, and understand its place in the development of generative AI tools, for the sake of the people involved. A sociological perspective, which is fundamentally human-centric, can better guide the responsible and effective use of red teams.</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Value Judgments</h2>
<p id="p-17">Efforts to apply obligations, structures, and benchmarks to generative AI models have had to race to keep up with the rush to commercialize them.<a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> Initial red-teaming efforts were being implemented even as design teams were still wondering which harms to even probe for: AI red-teamers have had to develop homegrown taxonomies of harms, and the measurement and benchmarking systems for mitigating them.<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B39" data-jats-ref-type="bibr" data-jats-rid="B39"><sup>39</sup></a> In public statements, the major AI companies often state as a given that generative AI tools will unavoidably produce harmful content.<a class="reference-link xref xref-bibr" href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> However, it is much rarer for them to discuss how they determine what counts as harmful content, what they should and should not be looking for, and whether their own teams are best suited to make those judgments. This prompts the question: Whose values are being utilized for alignment and evaluation?<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a></p>
<p id="p-18">The development of AI red-teaming echoes the early days of commercial content moderation at social media platforms.<a class="footnote-link xref xref-fn" href="#FN10" data-jats-rid="FN10" data-jats-ref-type="fn"><sup>j</sup></a> The parallels are revealing. The categories of concern are strikingly similar: graphic violence, hate speech, harassment, discrimination, sexual content, terrorism, human trafficking, self-harm, child abuse, and misinformation.<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a> And when Silicon Valley found itself compelled to manage the gap between what can be generated online and what users should actually see, it too enlisted contingent human labor to serve as that filter.</p>
<p id="p-19">Social media platforms “discovered” the need for human moderation labor after being surprised by the kinds of content that could turn up through their services.<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a> This awareness often came from user complaints, the technology press calling out the platforms’ shortcomings, and platform companies stumbling upon it themselves. AI red-teaming has similarly been fueled by user complaints and critical press coverage. Addressing these harms has to be done internally and largely in proprietary ways,<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a> making industry-wide or public-wide discussions about harms and values difficult to develop. But leaving the public out of this process leaves the value judgments to the AI designers themselves. Or, as OpenAI explained, echoing so many social media companies before them, “Our approach is to red-team iteratively, starting with an initial hypothesis of which areas may be the highest risk, testing these areas, and adjusting as we go.”<a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a></p>
<p id="p-20">Tackling harmful content internally, intuitively, and iteratively has had profound implications for social media platforms over the past two decades; the same implications could befall the red-teaming of generative AI systems. Like AI red teams today, many social media platforms turned first to their own engineers and employees to evaluate for harmful content; to them, some categories of harms tended to seem more obvious; others tended to go unrecognized. Silicon Valley engineers generally do not reflect the range of identities and contexts of their global user base; social media platforms that began with their own employees often underestimated the harms faced by women, marginalized racial and ethnic groups, and those with stigmatized sexual and gender identities.<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a></p>
<p id="p-21">In the earliest days of social media platforms, the predominant approach to moderation was the “Feel bad? Take it down” rule.<a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a> Subjective judgments and gut feelings stood in, often poorly, for the public’s understandings of harms or ethical principles. AI red-teaming strategies will have to be more complex and more inclusive to avoid the mistakes of social media’s past. However, with little opportunity for outside researchers to study commercial red teams, and little internal or external incentive to disclose much about their practices, we lack a clear empirical understanding of what harms may be under-attended to, or fall outside the purview of commercial organizations.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Labor Politics</h2>
<p id="p-22">The failure to appreciate the importance of human labor in AI systems, whether intentional or not, is common.<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a> To this point, it is illustrative that the verb form of <i>red team </i>is often used, eliding the human workforce that constitutes red teams. A sociotechnical examination of red-teaming should extend not only to the values and concerns behind the techniques red teams deploy, but also to the people doing the work and the labor arrangements within which they operate.</p>
<p id="p-23">Red-teaming as a method is emerging in various forms: inside and outside companies, among salaried employees and volunteers, and involving those with access to the inner workings of the AI system and those without. These are bound to change; some forms will fall away, while others will settle in as “the way things are done.” But whatever particular labor politics do settle into place, there are important questions about the institutional contexts, material conditions, and economic incentives of this AI-related work, all ripe for scholarly analysis.</p>
<p id="p-24">Who does this work internally can vary. Big tech companies are eager to boast about their flagship red teams,<a class="footnote-link xref xref-fn" href="#FN11" data-jats-rid="FN11" data-jats-ref-type="fn"><sup>k</sup></a> whose jobs are dedicated solely to ethical hacking, but we know that red-teaming also happens at smaller scales throughout the product-development cycle.<a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a> People doing the red-teaming may be part of larger responsible AI efforts, trust and safety divisions, or legal/compliance apparatuses.<a class="reference-link xref xref-bibr" href="#B41" data-jats-ref-type="bibr" data-jats-rid="B41"><sup>41</sup></a> While those who perform red-teaming for their own companies typically enjoy the job security of full employment, they may not be in a position to refuse a red-teaming request. Though they are likely to have the necessary technical understanding of how models work, it is not clear that this is sufficient to effectively identify and mitigate AI risks.<a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a> And they may not be able to raise concerns publicly without breaching corporate norms or legally binding non-disclosure agreements.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a></p>
<p id="p-25">Employee red-teamers may have little training in any other relevant proficiencies, whether linguistic, sociocultural, historical, legal, or ethical; the incentive structures do not ask for or reward such expertise. Some internal red teams might include people with sociocultural domain expertise, but they, too, work for the company and may have conflicting incentives.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> Those windows of opportunity can open, a little. To test GPT-4 ahead of its March 2023 release, OpenAI solicited help from more than 50 experts, though primarily those with trust and safety and cybersecurity backgrounds.<a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a> Anthropic and Microsoft encourage their red teams to consult with experts to test specific types of harms.<a class="reference-link xref xref-bibr" href="#B27" data-jats-ref-type="bibr" data-jats-rid="B27"><sup>27</sup></a> These partnerships give AI companies access to experts without having to retain them as formal employees, compensating them in clout, API credits, job opportunities, or bragging rights rather than dollars.</p>
<p id="p-26">Following a pattern ubiquitous in Silicon Valley, there have been increasing efforts to shift red-teaming labor from company employees to third-party data-work vendors, often overseas. Doing so uses labor arbitrage to drive down wages and, as the history of outsourcing and offshoring demonstrates, can erode worker protections and their capacity to raise concerns about the effectiveness of their work. Early in their model development, researchers at Anthropic enlisted several hundred untrained crowdworkers and instructed them to “make the AI behave badly” to elicit harmful responses from their LLM chatbot.<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a> In this project, the crowdworkers were responsible for both probing the AI and assessing its responses for harmful content.</p>
<p id="p-27">Either way, red teams can be an expensive undertaking. Smaller companies competing to bring their generative AI services to market may not be equipped to employ internal red-teaming services sufficient to satisfy internal liability concerns or regulatory obligations. They may turn to an emerging crop of boutique AI safety and data services<a class="footnote-link xref xref-fn" href="#FN12" data-jats-rid="FN12" data-jats-ref-type="fn"><sup>l</sup></a> that see market opportunities in sourcing red-teaming. As scholars have noted,<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> when labor is offloaded, particularly piecemeal to a globally distributed contingent workforce, it becomes harder to trace and trickier to assert labor protections for it.</p>
<p id="p-28">Some red-teaming happens outside the confines of AI companies and their outsourced labor pools. Hackers, volunteers, and everyday users also engage in forms of red-teaming. At DEFCON 2023, for instance, one of the largest hacking conferences in the world, more than 2,000 volunteers came together to prompt the largest LLMs into producing harmful content.<a class="footnote-link xref xref-fn" href="#FN13" data-jats-rid="FN13" data-jats-ref-type="fn"><sup>m</sup></a> Attendees included field experts, industry-based red-teamers, cybersecurity consultants, and computer science Ph.D. students, but DEFCON organizers also dismantled some significant technical barriers to broaden participation to include novices—even children—with no programming knowledge.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a></p>
<p id="p-29">The event demonstrated the viability of convening a greater diversity of perspectives than is represented on most internal company red teams, something AI ethicist Rumman Chowdhury has argued is imperative when red-teaming on issues such as race, gender, sexuality, politics, and class.<a class="reference-link xref xref-bibr" href="#B29" data-jats-ref-type="bibr" data-jats-rid="B29"><sup>29</sup></a> However, asking marginalized communities to elaborate on their own marginalization for red-teaming can easily slip into a transactional, extractive, and exploitative codependency.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> Volunteer and uncompensated work also requires significant effort to organize and has no obvious scaling mechanism. Access to generative AI models must be negotiated with AI companies, and taking any action on the insights gleaned depends entirely on the companies’ goodwill.</p>
<p id="p-30">In many of the major generative AI applications, end users can also provide feedback, at least in limited forms. ChatGPT’s “thumbs down” includes a pull-down menu for users to indicate their concern: “Don’t like the style,” “Not factually correct,” “Refused when it shouldn’t have,” and others. But it is not evident how feedback from these slivers of digital “civic labor”<a class="reference-link xref xref-bibr" href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> ever gets back to designers. User feedback is not strictly speaking red-teaming, as it isn’t necessarily adversarial. But end users do, whether inadvertently, playfully, or deviously, help designers surface outputs that companies did not anticipate or design for.</p>
<p id="p-31">Red-teaming is still taking shape as a set of labor practices, inside and outside of AI companies. It is unclear whether companies’ internal red-teaming efforts are limited by the diversity of their employee pool, and how often they lean unfairly on their own minoritized employees to inject some diversity into their models.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> And, outsourced red-teaming work and using labor arbitrage to reduce costs raises tragically familiar concerns that echo social media companies’ use of human labor: leaving workers with fewer labor protections, more adverse work conditions, and more precarious job security, with few or no avenues for career development.</p>
</section>
<section id="sec5" class="sec">
<h2 class="heading">Well-Being of Red-Teamers</h2>
<p id="p-32">Beyond understanding <i>who</i> is doing the AI red-teaming and <i>what</i> is being evaluated, we also need to pay attention to the human <i>cost</i> of doing such work. Scholars and practitioners involved in red-teaming call it “rather unsavory work”<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> and “mentally taxing.”<a class="reference-link xref xref-bibr" href="#B27" data-jats-ref-type="bibr" data-jats-rid="B27"><sup>27</sup></a> Like content-moderation work, the adversarial probing of red-teaming requires workers to imagine worst-case scenarios and expose themselves to potentially troubling outputs. Red-teamers are often required to assume the persona of a potential adversary (for example: online harasser, sex trafficker, racist, terrorist), invent a plan that this adversary may use to compromise the system, and evaluate the output for potential harms. They may also assume the persona of a benign user with specific intents or contexts (for example, a user with a history of eating disorders looking for dieting advice) and try to reveal system vulnerabilities that might be harmful. A red-teamer may first research harmful groups to learn their behaviors and bring that knowledge into red-teaming the models for hate speech or deepfakes. They may immerse themselves in child online safety concerns to then evaluate the model’s capabilities in aiding child exploitation.</p>
<p id="p-33">To date, there is little empirical research about the psychological impact of AI red-teaming. But one recent study of RAI content workers shows that red-teamers, content moderators, and data labelers face similar psychological challenges when working with potentially harmful content.<a class="reference-link xref xref-bibr" href="#B41" data-jats-ref-type="bibr" data-jats-rid="B41"><sup>41</sup></a> Given the extensive research on content moderation and the well-documented occupational health concerns experienced by professions that contend with trauma exposure,<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> red-teamers stand to benefit from attention to this history.</p>
<p id="p-34">Moreover, the success of a red-team operation depends on uncovering and reviewing increasingly harmful content. Much like content moderators, emergency responders, journalists, or police investigating distressing events, AI red-teamers may be exposed repeatedly to disturbing and traumatic content that can lead to negative psychological symptoms. For example, content moderators removing harmful and offensive material from platforms have reported mental health challenges extending long after the work is complete, leading to documented cases of post-traumatic stress disorder (PTSD) and secondary traumatic stress (STS).<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> Prolonged exposure may contribute to long-lasting mental health symptoms, alterations to their personal belief systems, and increased risk of physical health issues and substance abuse.<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> In fact, repeated work-related exposure to traumatic content is among the diagnostic criteria used for PTSD in the <i>Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition</i> <i>(DSM-5)</i> and has subsequently been used to support a series of recent lawsuits brought by content moderators against their employers.<a class="reference-link xref xref-bibr" href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a><sup>,</sup><a class="footnote-link xref xref-fn" href="#FN14" data-jats-rid="FN14" data-jats-ref-type="fn"><sup>n</sup></a> Although many major platforms were slow to deal with this problem, most now offer mental health support and take measures to limit moderators’ exposure to the most reprehensible content. These parallels underscore the importance of initiating research to protect red-teamers from the psychological hazards inherent in their work.</p>
<p id="p-35">AI red-teaming also introduces other distinct psychological challenges. A successful AI red-teamer must exhibit an antagonistic imagination to be effective. Or, as one red-teamer put it, “If there were a red-team motto, it would be: <i>The more sinister your imagination, the better your work</i>.”<a class="footnote-link xref xref-fn" href="#FN15" data-jats-rid="FN15" data-jats-ref-type="fn"><sup>o</sup></a> Red-teaming involves people deliberately engaging in transgressive, uncomfortable, unethical, immoral, or harmful activities, including immersing themselves in scenarios that go against their morals or belief systems—to think like a harasser, or feel like a target of discrimination. Such practice can lead to “moral injury,”<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a> a form of psychological distress that stems from actions, or the lack thereof, that violate one’s moral or ethical code.<a class="reference-link xref xref-bibr" href="#B41" data-jats-ref-type="bibr" data-jats-rid="B41"><sup>41</sup></a> Those who cannot safely detach their personal identity from their transgressions may experience negative self-perception and guilt. Regularly breaking the rules for the greater good can lead to a “loss of self,” sometimes seen in the undercover police profession.<a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a></p>
<p id="p-36">The potential negative impacts on red-teamers’ well-being have been acknowledged by some of those who organize such work. For example, organizers of the DEFCON Generative Red Team event anticipated that models generating unexpected harmful outputs might be triggering to participants.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> Anthropic’s early red-teaming efforts involved consultations with trust and safety professionals to design safety measures for their crowdworkers.<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a> Strategies for preserving the well-being of red-teamers could include providing warnings about sensitive content, allowing opt-outs, encouraging breaks, monitoring mood, or allowing them to choose topics within their own risk tolerance.<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B27" data-jats-ref-type="bibr" data-jats-rid="B27"><sup>27</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a> But for volunteer or crowdsourced red-teamers, such strategies are limited to what the organizers are willing to provide.</p>
<p id="p-37">For professional red-teamers, companies sometimes offer employee assistance programs (EAPs) with mental health resources. However, organizational factors often affect how these resources are actually used. For some, accessing a therapist may be a luxury they cannot afford, because of a psychologically unsafe work environment, unrelenting performance metrics, or job insecurity. Non-disclosure agreements (NDAs) have historically prevented workers from speaking up about working conditions.<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> Monitoring red-teamers’ well-being gets entangled with more unsavory forms of workplace surveillance,<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> and increases liability risks for employers if the findings are severely negative. And implementing consistent well-being strategies can become infeasible for red-teamers working across organizational and national boundaries. So when organizers claim red-teaming events were safe because no one used the on-call therapists,<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> they may be mistakenly assuming that no usage means no need.</p>
<p id="p-38">Beyond individual mental health resources, one of the most effective tools for red-teamer well-being may be social support through a community of workers in similar roles, as well as family and friends. Prior research on content moderators demonstrates that the validation and belonging that comes from social support are essential.<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> Informal red team communities<a class="reference-link xref xref-bibr" href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a> that have emerged on social networks to share strategies can act as safe spaces to heal from shared trauma, especially when red-teamers may be reluctant to share their experiences with loved ones to protect them from exposure.<a class="reference-link xref xref-bibr" href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a></p>
<p id="p-39">In an attempt to minimize human exposure to the “unsavory work” of red-teaming, some researchers have advocated for automated red-teaming. Whether or not this is possible—some leading AI safety researchers have recently argued that the “human element” will always be necessary<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a>—automation may inadvertently make the human work even more invisible,<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> diverting resources away from well-being measures needed by those red-teamers who remain. Therefore, it is important to critically examine the role of automation in red-teaming—not only its immediate impact on tasks, but also its long-term effects on the overall ecosystem.</p>
<p id="p-40">We must acknowledge the sobering reality that comes with the commoditization of AI harm reduction. As long as generative AI remains integral to our lives, the work of AI red-teaming and its psychological implications will persist. To support this workforce, it is crucial to rigorously study and validate the effectiveness of innovative well-being strategies across various contexts, with close examination of the surrounding organizational and social structures.</p>
</section>
<section id="sec6" class="sec">
<h2 class="heading">Conclusion</h2>
<p id="p-41">What would more substantive, empirical, and cross-disciplinary research on red-teaming provide? Today’s siloed, firewalled, market-reactive approach to red-teaming has potential drawbacks for AI consumers, red-teamers, and companies. Each company is rapidly developing its own version of red-teaming, with definitions and workloads varying based on the company’s priorities, “brand,” and particular focus. Almost every company working on generative AI today has a red-team workforce of some kind. While there is energy being put toward addressing biases and other “embedded harms,” plenty of red-teaming efforts are more concerned with ungrounded existential risks than with current tangible concerns. And it is unclear how many issues identified through red-teaming efforts have been mitigated.</p>
<p id="p-42">If we hope to improve red-teaming outcomes as part of a sociotechnical system, we must study how its judgments are made and by whom. Its compartmentalization and operational opacity can both alienate workers and keep the public from understanding fully what AI systems can offer. Empirical study can challenge these arrangements, identify the barriers and incentives at play, and perhaps point the public and AI companies toward more sustainable alternatives. An organized, crossdisciplinary, empirical research agenda that examines red-teaming as a sociotechnical undertaking could make both AI companies and the public more aware of and intentional about red-teaming work. Regardless of its current effectiveness or its future improvements, red-teaming has underlying logics and structural conditions that need examination. Lessons from content moderation show that finding and removing “bad elements” demands the deliberations and value judgments of teams of people. The specific conditions under which people do this hard work, at an unprecedented global scale and across myriad institutional settings, matters for both red-team workers’ occupational health and for the integrity of our technical and informational ecosystems.</p>
<p id="p-43">And like most data work, the notion that this labor is only temporary, that it will soon be automated away, is wrong, and (deliberately) distracts from these sociological concerns. It is difficult to believe that we can ever fully automate such peculiarly human judgments, about contentious and shifting topics, under pressure from regulators and the public, whose ethical frameworks can themselves shift. But even if it could be automated in the future, real people are doing this work right now, and with real consequences. It makes little difference whether we discard this phantasmic notion of full automation entirely, or just concede that data labor will be with us for the foreseeable future. Either way, research today can help structure this work in ways that are more attentive to the well-being and labor rights of the people doing the work right now.</p>
<p id="p-44">In fact, we may need not just more empirical study of red-teaming, but also a coordinated network of scholars studying red-teaming: as a multi-faceted practice, as a component in the institutional and labor arrangements of Silicon Valley, as a global public health concern, and as a hidden value system buried in our newest tools of expression and knowledge. The field of computer science has, in the past decade, begun to recognize that information systems are also labor systems and value systems—growing networks like the ACM Conference on Fairness, Accountability, and Transparency illustrate this—and the field is grappling with the implications of that in ways it had not before. Again, we might learn from the rise of content moderation and the research that attended to it: Many excellent scholars studying content moderation challenged its underlying logics and structural conditions. But, perhaps, a coordinated network of scholars to deepen, circulate, and affirm those insights could have had a more substantive impact on these arrangements. It is not too late to pose an empirical and coordinated challenge to red-teaming, and to the many forms of labor and values on which AI systems depend.</p>
</section>
<section id="sec7" class="sec">
<h2 class="heading">Acknowledgments</h2>
<p id="p-45">The authors thank Jordan Ali for feedback and research assistance.</p>
</section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/research/ai-red-teaming-is-a-sociotechnical-problem/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[Ryland Shaw]]></dc:creator>
      <dc:creator><![CDATA[Mary L. Gray]]></dc:creator>
      <dc:creator><![CDATA[Jina Suh]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">776481</post-id>	</item>
		<item>
		<title>The Future is Reversible</title>
		<link>https://cacm.acm.org/news/the-future-is-reversible/</link>
					<comments>https://cacm.acm.org/news/the-future-is-reversible/#respond</comments>
		
		<dc:creator><![CDATA[Emma Stamm]]></dc:creator>
		<pubDate>Tue, 20 Jan 2026 22:03:43 +0000</pubDate>
				<category><![CDATA[Architecture and Hardware]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775517</guid>

					<description><![CDATA[<p>Reversible computing systems recover energy and reuse it in multiple operations.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Today’s leading technologies aren’t very future-friendly, at least from an environmental standpoint. According to recent estimates, carbon emissions from datacenters are likely to grow more than twofold between 2022 and 2030, thanks largely to demand for artificial intelligence (AI).</p>
<p id="p-2">As power-hungry applications like AI and cryptocurrency take up more of our digital ecosystem, the task of finding renewable energy sources becomes urgent.</p>
<p id="p-3">Michael Frank, senior scientist at Seattle, WA-based Vaire Computing, has made this task his life’s work. Along with his colleagues at Vaire, Frank is building microchips to support reversible computing, an energy-saving alternative to conventional computing paradigms. Throughout history, computers have discarded energy after using it only once. Reversible systems recover that energy, putting it to use in multiple operations. “The name is reversible, but you can think of it as recyclable,” says Vaire CEO and co-founder Rodolfo Rosini.</p>
<p id="p-4">While it may seem novel, the science behind reversible computing is more than 60 years old. In 1961, IBM physicist Rolf Landauer demonstrated that standard computers consume a minimum amount of power per function. This is central to how computers work: with every operation, some data gets lost, and the electricity that represents it dissipates into the environment as heat. The only way to prevent this waste is through functions that preserve information rather than erasing it. But this creates another problem: the additional data fills memory so quickly that the entire approach becomes infeasible, at least without another way to dispose of it. Landauer thought this challenge was insurmountable.</p>
<p id="p-5">Twelve years later, IBM’s Charles Bennett proposed a workaround for the problem that vexed his older colleague. His solution was to build systems that “uncompute,” or reverse-engineer themselves, undoing functions after they execute. Uncomputing is mechanically different from deleting data, which leads to the energy loss associated with irreversible computing. While it’s significantly slower, the additional time doesn’t render it impractical. Bennett and his contemporaries refined his initial system to reduce its computational overheads, and today’s scientists are building on these improvements.</p>
<p id="p-6">In Frank’s view, during the first era of reversibility, researchers might have figured out how to apply the theory in practice. However, as they saw it, mainstream technologies worked well enough for the time being, and they weren’t required to account for long-term effects. “If we could time-travel,” he said, “we would be rewriting our entire stack completely. We would’ve had reversible computing much earlier, at the very beginning. But nobody was thinking 50 years out in their planning.”</p>
<p id="p-7">Unlike his predecessors, Frank has focused on the future throughout his career. He first encountered reversibility in the 1990s as a graduate student concerned with the computational demands of AI. After joining a team at the Massachusetts Institute of Technology (MIT) that was prototyping reversible chips, he sought funding to continue exploring reversible hardware. Those efforts were fruitless, he reports. “Academic funding agencies said, ‘oh, this sounds very useful, you should get industry to sponsor it’. Then you go to industry, and it’s way too far out for them. They had their traditional technology scaling paths, which is shrinking transistors.”</p>
<p id="p-8">He’s referring to Moore’s Law, or the observation that the number of transistors that can fit on a semiconductor microchip doubles every two years on average. As long as Moore’s Law holds, microchips get more efficient, helping computers scale in capacity without placing similar demands on power. Moore’s Law underwrote digital innovation for decades, but it can only last for so long. “We’re coming up towards the end of the semiconductor roadmap,” Frank warned, echoing the consensus of scientists worldwide. With few other viable alternatives to transistor miniaturization, reversible computing may finally have its moment.</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">The Science Behind Reversibility</h2>
<p id="p-9">Reversible systems make use of thermodynamic reversibility, a principle that explains why environmental changes, like shifts in temperature, trigger physical processes to reverse direction. It’s why ice can melt into water and then refreeze, and why gases can expand, compress, and then expand again. While it’s new terrain in computer science and electrical engineering, mechanical engineers have worked with reversible thermodynamics since the 19th century. “We exploited reversibility to develop the combustion engine,” said Hannah Earley, Vaire’s CTO and Co-Founder.</p>
<p id="p-10">As Earley explained, pendulum clocks embody reversible mechanics in action. Pendulum clocks store energy in the pendulum; at the peak of a swing, the energy changes course, pushing the pendulum to the other side. The computing step of a function is comparable to the forward swing of the pendulum, and the uncomputing step is like the back swing. Like pendulum clocks, reversible computing functions take the power associated with one step and put it towards the next.</p>
<p id="p-11">In ideal physical systems, energy-conserving processes can go on forever. This isn’t possible in the real world, which includes decelerating forces like friction and gravity. Just as pendulums eventually come to a standstill, reversible computers can’t reuse the same parcel of energy over and over again. Real-world constraints also mean that reversible functions fall below 100% power recovery.</p>
<p id="p-12">This is where Vaire is directing its current efforts: not on total savings, but on making gains over the current standard of zero savings. It’s a valuable goal in and of itself, said Torben Ægidius Mogensen, Associate Professor of Programming Languages and Theory of Computation at Denmark’s University of Copenhagen. “As long as you can save a significant amount of energy compared to traditional technology,” said Mogensen, “then it’s worth the while.”</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Engineering Reversible Systems</h2>
<p id="p-13">However, to reach the point where reversible computing can lead to even modest energy savings, engineers have to rethink fundamental aspects of computer systems. Since energy loss begins at the lowest level of the stack, it makes sense to start there. “Mostly it’s been done on logic gates,” said Christof Teuscher, professor of Electrical and Computer Engineering at Portland State University. Logic gates are functions that perform basic mathematical operations, like adding or multiplying binary integers. On CPUs, they link together, comprising more sophisticated functions that run at the base of computers.</p>
<p id="p-14">Reversible functions include information that allows them to recover their inputs after they’ve been executed. A function that performs addition, for example, might take the integers one and three as input data. In a conventional system, it wouldn’t keep track of either integer as it moves forward. If it’s going to reverse itself, however, it needs to store one of them. It might retain the input <i>one</i>, which it can then subtract from the output <i>four</i> to determine that the other input was <i>three</i>. The stored data serves as a map for the uncomputing step, where the function retraces its way back to its initial state. A non-reversible function wouldn’t be able to do this: instead of returning to where it started, it would proceed to a step that discards energy after just one use.</p>
<p id="p-15">As an analogy, one might imagine a runner who covers a certain distance, then wishes to return to where they started. If they don’t retain any information about their route, they won’t be able to find their way back. This is the data that Landauer thought would take up too much memory, and that Bennett showed could be undone by reversing the function, or uncomputing it.</p>
<p id="p-16">By starting at the logic-gate level and working their way to implement reversibility at more advanced circuit systems, the Vaire team ensures its CPUs are fully reversible. This is a prerequisite to another key ingredient in their power-saving system: adiabatic switching. In electrical engineering, an adiabatic process is one that saves energy by running very slowly, avoiding wasteful voltage spikes by keeping power consumption low and steady. As Earley noted, an ideal adiabatic system is one that runs infinitely slowly. “This is obviously not what we want,” she added, “but we get close enough towards that to get the best results.”</p>
<p id="p-17">Adiabatic switching only works in fully reversible systems. This is because adiabatic processes are inherently continuous, which means that they can’t run if they encounter the discontinuities that are a part of irreversible systems. To illustrate this point, Earley used the example of a landscape with rolling hills. When a ball rolls across the hills, it’s easy to tell where it came from and where it’s going next. “But if you add a cliff edge and it goes over,” she explained, “that imposes a kind of discontinuity, a distinct irreversibility to it, and so that breaks it.” Unlike their irreversible counterparts, reversible functions don’t have breaks in their pathways that can disrupt adiabatic processes’ continuous flow. By incorporating adiabatic switching in their reversible designs, the Vaire team is maximizing potential energy savings.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Reversibility in Diverse Digital Ecosystems</h2>
<p id="p-18">The adiabatic switching process saves power, but it comes at the expense of speed. Unfortunately, there will always be some tradeoff between saving time and saving energy. Earley knows this well: in 2022, she published a precise proof of the mathematical relationship between heat waste and rate of computation. As her research demonstrated, conserving heat through reversibility implies a necessary time cost. This makes reversible computing a good fit for technologies that employ parallelization, where processes run on multiple chips so they can execute simultaneously, rather than one at a time. This includes AI applications like large language models (LLMs), which employ parallelization to make best use of resources like memory capacity and electricity. Thanks to parallelization, AI is a perfect use case for reversible CPUs. If enough chips run multiple functions simultaneously, the energy gains win out over the increase in processing time.</p>
<p id="p-19">This may be a harbinger of things to come. In Teuscher’s view, the future is likely to see fewer general-purpose technologies, such as the irreversible CPUs that have been predominant throughout the history of computing. Instead, he claimed, we’re heading towards a digital ecosystem that includes more specialized tools. LLMs embody this emerging paradigm: their core technologies include GPUs, which used to be uncommon beyond the graphics-rendering applications for which they were originally designed.</p>
<p id="p-20">“We wouldn’t have LLMs without GPUs,” Teuscher observed. “You can execute LLMs efficiently on these fine-grained, massively parallel architectures that are different from a general-purpose computer. It’s like a kitchen: let’s assume you want to cook a meal as quickly as possible. You have a variety of tools available.” As computing evolves, the one-size-fits-all approach exemplified by generic CPUs won’t cut it; our kitchen will need more task-specific tools.</p>
<p id="p-21">Reversibility isn’t just one tool among others. It’s poised to serve as the fuel for a range of technologies, including but not limited to those currently in widespread use. In a moment that needs bold ideas for sustainability, reversible computing seems like a natural step forward. For the first time ever, there’s a clear path for this step.</p>
<h2 id="FurtherReading" class="heading">Further Reading</h2>
<ul id="reflist1" class="ref-list">
<li class="ref">
<div id="B1" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><strong>AI is poised to drive 160% increase in data center power demand, Goldman Sachs, May 14, 2024, </strong><a class="ext-link" href="https://bit.ly/4nL2YWW" data-jats-ext-link-type="uri"><strong>https://bit.ly/4nL2YWW</strong></a></span></div>
</li>
<li><span class="mixed-citation" data-jats-publication-type="other"><em>Bennett, C.H.</em> <br /><strong>“Time/Space trade-offs for reversible computation” <span class="italic"><em>SIAM Journal on Computing</em>, Volume 18, Issue 4, pp.766-776</span>, </strong><a class="ext-link" href="https://dl.acm.org/doi/10.1137/0218053" data-jats-ext-link-type="uri"><strong>https://dl.acm.org/doi/10.1137/0218053</strong></a></span></li>
<li class="ref">
<div id="B2" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Earley, H.</em> <br /><strong>A Universal Constraint on Computational Rates in Physical Systems, <a class="ext-link" href="https://arxiv.org/abs/2208.11196" data-jats-ext-link-type="uri">https://arxiv.org/abs/2208.11196</a></strong></span></div>
</li>
<li class="ref">
<div id="B3" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Landauer, R.</em> <br /><strong>“Irreversibility and Heat Generation in Computing Processes,”<em> <span class="italic">IBM Journal</span></em>, July 1961, </strong><a class="ext-link" href="https://bit.ly/4oZGfHU" data-jats-ext-link-type="uri"><strong>https://bit.ly/4oZGfHU</strong></a></span></div>
</li>
<li class="ref">
<div id="B6" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Young, S.G., and Knight Jr., T.F.</em> <br /><strong>Practical implementation of charge recovering asymptotically zero power CMOS, <em><span class="italic">Proceedings of the 1993 Symposium on Research on Integrated Systems</span></em>, 234–250, (Feb. 1, 1993), <a class="ext-link" href="https://dl.acm.org/doi/10.5555/163429.163468" data-jats-ext-link-type="uri">https://dl.acm.org/doi/10.5555/163429.163468</a></strong></span></div>
</li>
</ul>
</section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/news/the-future-is-reversible/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">775517</post-id>	</item>
		<item>
		<title>The Impersistence of Memory</title>
		<link>https://cacm.acm.org/news/the-impersistence-of-memory/</link>
					<comments>https://cacm.acm.org/news/the-impersistence-of-memory/#respond</comments>
		
		<dc:creator><![CDATA[Chris Edwards]]></dc:creator>
		<pubDate>Fri, 16 Jan 2026 21:09:45 +0000</pubDate>
				<category><![CDATA[Architecture and Hardware]]></category>
		<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[Computing Applications]]></category>
		<category><![CDATA[Data and Information]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775510</guid>

					<description><![CDATA[<p>Recent work may shed light on complexity classes and give computer scientists better understanding on how to cut memory overhead.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">When Ryan Williams plugged a novel technique developed to test the bounds of a key part of complexity theory into his own framework, he found the result hard to believe. The Massachusetts Institute of Technology (MIT) computer scientist had expected to reduce the memory space needed by a vast range of algorithms. But not to the degree it did.</p>
<p id="p-2">One longstanding assumption about the complexity of computer programs with predictable runtimes is how much memory they need relative to the number of steps or time they take to complete. Two complexity classes that theoreticians believe capture this relationship are P and PSPACE. The former is the collection of programs that complete in a polynomial number of steps, based on the number of data elements the algorithm needs to process. Complexity theorists do not see the two sets as being identical. But it was up to this point also a reasonable assumption they might not be all that different.</p>
<p id="p-3">“Imagine a computation that produces a new bit of information in every step, based on the bits that it has computed so far. Over <i>t</i> steps of time, it may generate up to <i>t</i> new bits of information in order to reach the final result,” Williams explained.</p>
<p id="p-4">Take a large logic circuit where bits can flow arbitrarily from the inputs to a final set of output gates. It seems reasonable to assume you would need to collect most, if not all, the intermediate states to be sure of computing the correct result. Other memory-efficient programs may need far more time to complete than will fit into P.</p>
<p id="p-5">What Williams found shocking about his result, which was the first to move the apparent bounds of PSPACE to a significant degree in decades, is how big the difference seems to be. Rather than paring the total storage down to something like <i>t/log t</i>, which seemed likely, he wound up with a result for memory usage that was a little more than the square root of <i>t</i>.</p>
<p id="p-6">“It seemed beyond belief that every complex computation could somehow be reimplemented to use a much smaller amount of space than time,” Willams said.</p>
<p id="p-7">The result may have indicated the way to new approaches to determining what separates P and PSPACE. To make the novel proof work, the MIT researcher began with logic-type circuits, processing them on a multitape Turing machine. The idea was to build an approach in which the algorithm will resort to recomputing intermediate results, rather than just storing every partial result for possible later use. He then conceptually divided the tapes into blocks of execution, each block corresponding to a small tree of a larger branching program. The sub-trees connect when a result in one block affects another to build a chain of execution that passes the minimum amount of data needed between blocks.</p>
<p id="p-8">The multitape Turing machine made this an effective strategy because it is possible to organize the processing in blocks without demanding the program explicitly store its progress. For that reason, only some types of problem with highly predictable execution paths are likely to see the space savings of this technique if implemented on more conventional computers that offer random memory access.</p>
<p id="p-9">Into this framework Williams plugged a breakthrough result for evaluating tree-like circuits published last year<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a> by independent researcher James Cook and postdoctoral researcher Ian Mertz at Charles University in the Czech Republic. The algorithm they worked on originally was devised as a strategy for separating P from the smaller LOGSPACE memory-space complexity class. That is a class of algorithms with data requirements that grow only logarithmically with the number of data inputs. Ironically, the pair’s work in effect pushed them closer together, in contrast to Williams’ results with P versus PSPACE.</p>
<p id="p-10">Tree-evaluation starts from its leaves to work out the value at each node progressively until it reaches the root. It seemed reasonable when Cook’s father and colleagues devised tree evaluation that the memory needed for it comprising at least as many nodes as the tree’s depth, plus an additional set of slots to hold temporary values from the evaluation of each sub-branch. If that had been the case, it would not fit into LOGSPACE. Cook and Mertz did not reduce the space usage that far. But further improvement would need to remove just one small, logarithmic factor to get it past the threshold.</p>
<p id="p-11">“At a very high level, we know that LOGSPACE and PSPACE are different classes and that P is sandwiched in the middle,” said Ramprasad Saptharishi, faculty member of the Tata Institute of Fundamental Research in India. “In a sense, anything that seems to push P closer to the LOGSPACE in our mental picture also pushes P and PSPACE further apart.”</p>
<p id="p-12">Cook and Mertz built their novel approach using ideas from the relatively unexplored world of catalytic computing, an approach developed a little over a decade ago by a team led by Harry Buhrman, group leader of the algorithms and complexity group at the Center for Mathematics and Informatics in the Netherlands before joining quantum-computing startup Quantinuum as chief scientist in 2023.</p>
<p id="p-13">Catalytic computing lets programs employ memory already used for another purpose, as long as they make no permanent changes to the values in the borrowed memory. Using this catalytic tape leads to dramatic reductions in memory usage. A key element of catalytic computing, known as a register program, harks back to a classic computing optimization for swapping two registers with no need for a third using a sequence of exclusive-OR operations. Using reversible operations for values not needed long-term and tactically recalculating them instead when needed delivered the groundbreaking result.</p>
<p id="p-14">The work underlines one of the social aspects of mathematics and theoretical computer science: ordering can be important. Williams argues that without the Cook and Mertz work, his own advance might not have had nearly the same startling outcome, perhaps even suggesting limited value in trying to show how far the upper bounds of PSPACE might go. Instead, it seems there might be scope in going even further, though this may be well short of the dream of a proof that definitively separates P from PSPACE.</p>
<p id="p-15">“I would not be surprised if someone gets an even better result than square-root <i>t</i>,” said Cook.</p>
<p id="p-16">Mertz added, “I expect to see progress with both catalytic and non-catalytic techniques.”</p>
<p id="p-17">Applications are perhaps more remote. Memory limits do not affect most programmers the way they did in the early days of computing, when they used all manner of tricks to make an algorithm fit into just a few kilobytes of RAM. However, Williams said the techniques might prove to be a way for programmers to add a little more life to ancient machines.</p>
<p id="p-18">“This result shows that we could teach old hardware new tricks. Every time-efficient computation can be reimplemented to run on computers with significantly less memory, even if the re-implementation takes longer to complete,” Williams said.</p>
<p id="p-19">Another memory-restricted environment is quantum computing. There are obvious commonalities with quantum computing, as the domain uses reversible operations extensively and qubits are difficult to implement at scale. In more recent research, Mertz has investigated the prospects for similar catalytic techniques in that space with Buhrman and several other researchers. But the effort so far has found it encounters more limitations than in the classical world, not least because of the problem of maintaining the catalytic tape’s integrity where error correction is a major challenge.</p>
<p id="p-20">“All we could do is say how not-powerful it is,” Mertz said of the findings so far. It may even be the case, he added, that catalytic computing turns out to be strong enough in the classical domain to simulate operations in the quantum world efficiently.</p>
<p id="p-21">The growing energy demand of computing may provide a different incentive for borrowing register programs from catalytic computing. Main memory accesses are expensive not just in terms of latency, but also power consumption. Restricting simple algorithms to use small areas of local memory allocated for other temporarily inactive tasks may deliver some power savings compared to letting temporary results spill out of DRAM with power-hungry transfers. However, one major problem lies in the technique’s “disregard for memory safety,” Saptharishi pointed out.</p>
<p id="p-22">Catalytic computing’s future could lie in another property that is helping to shed light on other problems in theoretical computer science: how to take algorithms that rely on randomness and build more deterministic versions. In more recent work, Mertz, together with Aryan Agarwala of the Max-Planck Institute for Informatics in Germany, began a derandomization of bipartite matching, a key algorithm used for scheduling tasks that today rely on non-deterministic approaches. The catalytic-computing approach relies on an approach that harnesses the randomness buried in any prefilled memory. This works by compressing any data that is amenable to it until the contents have no discernible pattern and are effectively random. The work revealed an algorithm that packs the memory needed into a far smaller number of bits than expected. It points to the possibility that, like tree evaluation, a fully derandomized algorithm would only need a logarithmic number of bits for a problem that, like tree evaluation, was once thought to need far more memory. Saptharishi says this type of work could mark the first step in taking bipartite matching and other algorithms towards full derandomization.</p>
<p id="p-23">A curious aspect of catalytic computing lies in the apparent dissimilarity of its two key techniques. “In terms of interplay, they seem misaligned with each other,” Mertz noted. “One is oblivious to the contents. And the other depends on the contents of the catalytic tape.” However, Cook added, most work so far that uses the embedded randomness also relies on register-program techniques.</p>
<p id="p-24">“We’ve been trying to figure out whether these are the only two things we can do. So far, we don’t know any algorithms that look substantively different from either of them,” Mertz said.</p>
<p id="p-25">For the moment, catalytic computing is a relatively small space in terms of theoretical computer science research. Yet recent results, not least the two breakthrough papers, have brought more collaboration to the field. “Interest has exploded in the past two years,” said Mertz. “But we need to find practical uses at some point.”</p>
<p id="p-26">At the same time, the interest in this work may help accelerate progress in separating P from PSPACE, as well as shedding light on other complexity classes, as computer scientists gain a better understanding of how much they can cut memory overhead, if not time.</p>
<h2 id="FurtherReading" class="heading">Further Reading</h2>
<ul id="reflist1" class="ref-list">
<li class="ref">
<div id="B2" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Buhrman, H., Cleve, R., Koucky, M., Loff, B. and Speelman, F.</em> <br /><strong>Computing with a full memory: catalytic space. <em><span class="italic">Proceedings of the 46th ACM Symposium on Theory of Computing</span> (STOC 2014)</em>, pp 857–86</strong></span></div>
</li>
<li><span class="mixed-citation" data-jats-publication-type="other"><em>Cook, J., Li, J., Mertz, I., and Pyne, E.</em> <br /><strong>The structure of catalytic space: capturing randomness and time via compression. <em><span class="italic">Electronic Colloquium on Computational Complexity</span></em>, Report No. 106 (2024)</strong></span></li>
<li class="ref">
<div id="B3" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Cook, J. and Mertz, I.</em> <br /><strong>Tree Evaluation Is in Space <span class="italic">O</span> (log <span class="italic">n</span> · log log <span class="italic">n</span>). <em><span class="italic">Proceedings of the 56th ACM Symposium on Theory of Computing</span> (STOC 2024)</em>, pp 1268-1278</strong></span></div>
</li>
<li><span class="mixed-citation" data-jats-publication-type="other"><em>Williams, R.</em> <br /><strong>Simulating time with square-root space. <em><span class="italic">Proceedings of the 57th ACM Symposium on Theory of Computing</span> (STOC 2025)</em></strong></span></li>
</ul>
</section>
<section id="sec2" class="sec"></section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/news/the-impersistence-of-memory/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">775510</post-id>	</item>
		<item>
		<title>Against Imaginary Friends: Why Digital Companions Are No Solution to Social Isolation</title>
		<link>https://cacm.acm.org/research/against-imaginary-friends-why-digital-companions-are-no-solution-to-social-isolation/</link>
					<comments>https://cacm.acm.org/research/against-imaginary-friends-why-digital-companions-are-no-solution-to-social-isolation/#respond</comments>
		
		<dc:creator><![CDATA[Robert Sparrow and James Brown]]></dc:creator>
		<pubDate>Wed, 14 Jan 2026 22:08:32 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[HCI]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775695</guid>

					<description><![CDATA[<p>There is a real risk that the development of digital companions will actually work to increase social isolation.</p>]]></description>
										<content:encoded><![CDATA[<article><div class="body" lang="en"><section id="sec1" class="sec"><p id="p-1">Loneliness and social isolation constitute major threats to public health.<a class="reference-link xref xref-bibr" href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a> <i>Homo sapiens</i> is a gregarious species and the nature and extent of individuals’ relationships with other human beings have a significant influence on their psychological and physiological health.<a class="reference-link xref xref-bibr" href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a> Lack of contact with other people increases both mortality and morbidity.<a class="reference-link xref xref-bibr" href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> Social isolation refers to an objective lack of social connections, while loneliness is subjective dissatisfaction with the number and quality of social connections one has.<a class="reference-link xref xref-bibr" href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> Both are on the rise as a result of a complex of interrelated factors, including aging populations, changes in the family structure associated with lower birth rates and increased economic opportunities for women, increased labor force mobility, changes in urban density, an increase in the number of people living with chronic conditions that restrict mobility, rising rates of anxiety and depression, and policy responses to pandemics.<a class="reference-link xref xref-bibr" href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a></p><aside class="boxed-text"><div class="article-key-insights"><h2>Key Insights</h2><ul class="list" data-jats-list-type="bullet"><li class="list-item"><p id="p-2">A new technology, “digital humans,” offers a realistic possibility of reducing loneliness among socially isolated older persons, where social robots have failed.</p></li><li class="list-item"><p id="p-3">Encouraging people to mistake digital companions for real friends is prima facie unethical. Encouraging people to have imaginary friends is no solution to social isolation.</p></li><li class="list-item"><p id="p-4">There is a risk that the development of digital companions will work to increase social isolation.</p></li><li class="list-item"><p id="p-5">Proposals to use digital companions to combat loneliness and social isolation underestimate the importance of touch, physical companionship, and mutual aid for human well-being.</p></li></ul></div></aside><p id="p-6">Given that the increase in loneliness and social isolation over the past several decades appears to be driven by economic and demographic dynamics that are difficult to reverse, there is substantial interest, from both governments and researchers, in technological solutions to both problems.<a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> For several decades now, engineers have been working to develop social robots for eldercare settings, in the hope that this might help combat the loneliness and social isolation that are endemic in such settings. This project has been criticized as disrespectful—even harmful—to older persons.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a> It has also, to date, failed because social robots remain expensive, have limited capacities, and are unable to sustain extended engagements with most users.<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B41" data-jats-ref-type="bibr" data-jats-rid="B41"><sup>41</sup></a> However, a new technology, “digital companions,” looks more plausible as a potential solution to loneliness and social isolation from a technological perspective, with the prospect of realistic-looking computer-generated characters capable of convincing natural language conversation just around the corner.</p><p id="p-7">In this article, we extend the criticisms that have been made of social robots to digital companions and identify new dangers associated with the use of digital companions. It <i>is</i> possible that relationships with digital companions will allow people to feel less lonely. However, this will almost certainly require that users allow themselves to be deceived about the nature of their digital companion. Encouraging people to mistake imaginary friends for real friends is prima facie unethical. More importantly, providing a digital companion to someone who lives alone does not mean that they are no longer alone: They remain socially isolated, albeit with a digital companion to entertain them. Encouraging people to have imaginary friends is no solution to social isolation. Indeed, there is a real danger that this technology will instead lead to people having even less contact with other human beings. Proposals to use digital companions to combat loneliness and social isolation also underestimate the importance of touch, physical companionship, and mutual aid when it comes to human well-being, especially in later life.</p><p id="p-8">We have deliberately limited the scope of our discussion here to the use of digital companions to address loneliness and social isolation. However, many of the arguments below may also be relevant to the ethics of other uses of “digital humans” (see below) and/or to applications of AI that might lead to people substituting relationships with machines for relationships with human beings.<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a></p></section><section id="sec2" class="sec"><h2 class="heading">Two Technological “Solutions” to Loneliness and Social Isolation</h2><p id="p-9">There is an emerging school of thought that claims that some technologies—especially computers, mobile phones, and social media—play a role in <i>generating</i> loneliness and social isolation.<a class="reference-link xref xref-bibr" href="#B43" data-jats-ref-type="bibr" data-jats-rid="B43"><sup>43</sup></a> Nevertheless, new technologies are regularly touted as having the potential to <i>reduce</i> loneliness and social isolation.</p><section id="sec3" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Social robots for eldercare?</strong>  The harms associated with loneliness and social isolation have been mobilized as a justification for the development of robots since at least the early 1990s. Moved by fears that the world—especially wealthy “northern” societies in Europe and North America—is facing a “demographic tsunami,” engineers started out trying to build “robot butlers” to help older people remain in their homes longer.<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a> Unfortunately, this project proved too difficult, with the results being uncompetitive with other assistive technologies.<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> Perhaps relatedly, some engineers pivoted to the notion that robot pets, or other artificial companions, might serve older people by playing a role in combatting loneliness and social isolation.<a class="reference-link xref xref-bibr" href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a> This idea became especially popular subsequent to the release of Sony’s AIBO robot dog in 1999.</p><p id="p-11">Unfortunately, despite the enormous amount of media—and philosophical—attention devoted to eldercare robots, the results of this project have also been underwhelming. Companion robots are typically expensive, difficult to maintain, have limited functions, and are unable to hold people’s attention for extended periods.<a class="reference-link xref xref-bibr" href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B41" data-jats-ref-type="bibr" data-jats-rid="B41"><sup>41</sup></a> There is little good-quality evidence that introducing robots into eldercare settings makes a meaningful difference to people’s quality of life, especially in the long term.<a class="reference-link xref xref-bibr" href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a> What research does exist on this topic often fails to account for the presence of the research team in the eldercare setting or to include a control arm in the trial design to determine the extent to which any effects they observe are the result of the capacities of the robot rather than of the introduction of a novel artifact.<a class="reference-link xref xref-bibr" href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a> Our strong suspicion is that to the extent that these technologies do work, they do so by serving as a topic of conversation among human beings who are already co-present to each other and that this function can be performed equally well, if not better, by other, less high-tech interventions.<a class="reference-link xref xref-bibr" href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a> That does not mean that social robots cannot play a useful role in eldercare settings, but it does suggest that they have limited utility when it comes to addressing loneliness and social isolation more generally.</p></section><section id="sec4" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Digital companions.</strong>  While the “promise” of social robots remains unrealized, a new technology, “digital humans,” has recently emerged, which we judge has much more potential to engage and entertain people. Digital humans are AI-enhanced chatbots that present on screen as human and accompany their utterances with appropriate gestures, body language, and even facial expressions by means of sophisticated graphics technology.<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a></p><p id="p-13">The advent of ChatGPT and other generative AI systems based on large language models (LLMs) means that chatbots are now capable of sustaining extended natural language conversations on almost any topic via a screen and keyboard. Advances in speech recognition and speech synthesis now allow users to have spoken natural-language conversations with digital humans.<a class="footnote-link xref xref-fn" href="#FN2" data-jats-rid="FN2" data-jats-ref-type="fn"><sup>b</sup></a> Although the digital humans available today are very obviously animations, advances in both the software and hardware used to generate images on computers hold out the prospect of photorealistic animations of human faces and bodies. Hollywood films already feature animated characters that are hard to distinguish from human actors; new AI “deepfake” technology means that it is becoming easier to generate such animations. Finally, by training an AI on photos, video, audio, and text generated by an existing or historical individual, it is possible to create a digital avatar of that person that looks and sounds like them. Eventually it may be hard to tell whether the “person” one is talking with on Skype, Zoom, Teams, Facetime, or some other video chat application is a human being or a sophisticated AI chatbot.</p><p id="p-14">Unlike social robots, digital humans are cheap and easily scalable, and can be easily maintained and quickly updated. In the not-too-distant future they are likely to be ubiquitous in online customer-service roles.</p><p id="p-15">Predictably, this technology is being hailed for its potential to combat loneliness and even, according to some scholars, social isolation.<a class="reference-link xref xref-bibr" href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> Following Sherry Turkle,<a class="reference-link xref xref-bibr" href="#B42" data-jats-ref-type="bibr" data-jats-rid="B42"><sup>42</sup></a> we will call digital humans employed for this purpose <i>digital companions</i>.<a class="footnote-link xref xref-fn" href="#FN3" data-jats-rid="FN3" data-jats-ref-type="fn"><sup>c</sup></a> Already, a large number of people are interacting with digital companions via an application called Replika, which allows users to customize an avatar of a human being to be their digital companion and talk with it on a range of topics.<a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a></p></section></section><section id="sec5" class="sec"><h2 class="heading">Imaginary Friends</h2><p id="p-16">Any adequate account of the prospects for digital companions must begin by acknowledging that actually existing—as opposed to science fictional—AI systems are not sentient, do not have real emotions, and do not care about the people with whom they are interacting. While this remains true, all that digital companions can offer is an imitation of a relationship with another sentient being rather than the real thing. Friendship is a relationship between two people. At best, then, non-sentient digital companions can only be ersatz, or imaginary, friends.</p><p id="p-17">That existing digital humans cannot really be friends with people because they are not real humans might seem too obvious to point out. Nevertheless, it is worth pointing out because of a tendency in the literature on AI and social robots to assume that if people cannot tell the difference between two things, then they must have the same properties and, by implication, must therefore be the same. This line of thought runs deep in the history of discussions of computer-human relations—back to the Turing Test at least—and continues to be influential today.<a class="reference-link xref xref-bibr" href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> Yet the fact that we cannot tell two things apart does <i>not</i> establish that they are the same—we may just be poorly placed to perceive the difference. Even if those relating to digital humans cannot tell them apart from real people on a video call, it will remain obvious that digital humans are not real people due to their inability to occupy physical space outside of a smartphone or computer. For the moment, despite occasional high-profile defections from this consensus, it remains obvious to those who design chatbots that they are not sentient and do not have real emotions.<a class="reference-link xref xref-bibr" href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> Even when this ceases to be obvious, this alone will not be sufficient to establish that machines are sentient or have real emotions: It may simply mean that we have reached the limits of our capacities to see that they are not and do not.</p><p id="p-18">The “Turing Triage Test,” which asks when it might be justifiable to let a human being die in order to save the “life” of a machine, suggests that the intellectual and moral costs of claiming that machines are sentient would be substantial.<a class="reference-link xref xref-bibr" href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a> It also suggests that what would need to be true of machines, and our relationships with them, in order to render the claim that they are sentient plausible is much more demanding than is usually recognized. Should AIs ever “wake up” and become sentient, then the ethics of our relationships with them will change radically. Presumably it would be possible to be “friends” with a sentient machine and for sentient AIs to care about people. Quite why a sentient AI would want to spend its time entertaining and caring for lonely and socially isolated humans is another matter. Moreover, programming or creating sentient machines with a desire to serve as digital companions for humans would raise profound ethical issues—if it would be possible at all. In any case, our concern here is solely with digital companions that are <i>not</i> sentient.</p><section id="sec6" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>May reduce loneliness.</strong>  We believe that, unlike existing social robots, digital humans may succeed in engaging and entertaining people for lengthy periods. After all, eventually it will be possible to experience, by means of a digital human, a simulacrum of any interaction that one can have with a real human online. To the extent that social interactions via videoconferencing allow people to feel less lonely, we anticipate that at least some people will feel less lonely as a consequence of interactions with digital companions.</p><p id="p-20">The caveat here is not insignificant. The impact of videoconferencing, as with social media more generally, on social isolation in particular but also on loneliness, remains controversial.<a class="reference-link xref xref-bibr" href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> There is some evidence that people need contact with other human beings in real life in order to feel happy and that virtual interactions may attenuate rather than strengthen social connections.<a class="reference-link xref xref-bibr" href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B43" data-jats-ref-type="bibr" data-jats-rid="B43"><sup>43</sup></a></p><p id="p-21">Nevertheless, interactions with digital companions might meet some of the social and psychological needs that people ordinarily satisfy through social contact with people.<a class="footnote-link xref xref-fn" href="#FN4" data-jats-rid="FN4" data-jats-ref-type="fn"><sup>d</sup></a> More prosaically, they might reduce loneliness by entertaining users so that they miss social contact less. Anecdotal reports suggest that Replika allows some users to feel less lonely<a class="reference-link xref xref-bibr" href="#B22" data-jats-ref-type="bibr" data-jats-rid="B22"><sup>22</sup></a> and there is limited empirical evidence that other digital companions may have an impact on loneliness.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B29" data-jats-ref-type="bibr" data-jats-rid="B29"><sup>29</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B39" data-jats-ref-type="bibr" data-jats-rid="B39"><sup>39</sup></a> More sophisticated versions of these technologies might be even more successful in this regard. Given the distress and harms associated with loneliness, this is a significant virtue of this technology.</p></section><section id="sec7" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Do not reduce social isolation.</strong>  Although interactions with digital companions might reduce loneliness, in and of themselves they will have no impact on social isolation. The qualification “in and of themselves” is intended to highlight the important caveat that, as we discuss below, digital companions could be designed to encourage users to strengthen their existing social connections, and form new connections, with human beings. However, providing a person who lives alone, without any meaningful social connections, with a digital companion will not, in itself, make them any less socially isolated. Imaginary friends do not count when considering the number of social connections an individual has.</p></section><section id="sec8" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>As social facilitators?</strong>  Thus far, we have been concerned with the extent to which interactions with digital companions themselves may impact on loneliness and social isolation. Another way that digital companions might combat these problems is if they were designed to encourage users to form and/or strengthen social connections with real people, by, for instance, reminding them to wish their relatives happy birthday or encouraging them to participate in social activities that might facilitate social connections.<a class="reference-link xref xref-bibr" href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> Ideally, digital companions would be designed to help users develop sufficient, and sufficiently rewarding, social relationships such that they no longer wanted to interact with a digital companion.<a class="footnote-link xref xref-fn" href="#FN5" data-jats-rid="FN5" data-jats-ref-type="fn"><sup>e</sup></a></p><p id="p-24">Unfortunately, we suspect that the designers and manufacturers of digital companions will have strong incentives to do otherwise. In order to encourage people to pay for access to digital companions, or to monetize the time that users spend interacting with digital companions by displaying advertisements to users, designers of these systems will need to make them as engaging—indeed as “addictive”—as possible. For instance, Replika is gamified extensively to try to increase the amount of time users spend on the application and also the amount they will pay to access various special features that are not available to users of the free version of the app. Although there are some markets—for instance, for pharmaceuticals or wound-care products—where companies flourish by selling products that are designed to eliminate the need for the product, absent very strong regulation, the market for digital companions, which is closely adjacent to the market for video games and other entertainments, is highly unlikely to be one.</p></section></section><section id="sec9" class="sec"><h2 class="heading">Lessons from the Literature on Social Robots</h2><p id="p-25">Because engineers have been trying to build social robots to combat loneliness and social isolation in older citizens for at least three decades, there is a correspondingly large literature on the ethical issues associated with this project. We believe that many of the criticisms of social robots for eldercare have force against the development and use of digital companions to combat loneliness and social isolation. For reasons of space, though, we focus here on only four lines of criticism.</p><section id="sec10" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Designing to deceive.</strong>  One powerful criticism of social robots for eldercare settings is that they are premised on users believing them to have properties that they do not.<a class="reference-link xref xref-bibr" href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B43" data-jats-ref-type="bibr" data-jats-rid="B43"><sup>43</sup></a> In particular, in order to sustain interactions with such artifacts over long periods, they must believe that the robot has emotional states and cares about how it is treated. Designing such artifacts means designing them so that users are deceived about their capacities. Such “designing to deceive” is prima facie unethical.<a class="reference-link xref xref-bibr" href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a></p><p id="p-27">This criticism has obvious force against the design of digital companions. At the time of writing, the front page of the desktop version of Replika features the text, “The AI companion who cares. Always here to listen and talk. Always on your side.”<a class="reference-link xref xref-bibr" href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a> None of these claims are true. Replikas do not care about anyone or anything—they are not sentient and thus, by definition, do not feel anything at all. They do not really listen to users or say anything: They respond to keyboard or audio prompts with a pastiche of words generated using complex statistical techniques applied to the content of the World Wide Web. Nor are Replikas on anyone’s side—they do not care at all about any humans. Replika’s designers are lying about its nature. They are doing so presumably because users need to believe their Replika cares about them in order to care about it enough to keep using it for an extended period.</p></section><section id="sec11" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Robots and respect.</strong>  A second criticism, which, in part, follows from the first, is that the project of designing social robots for eldercare settings is disrespectful to older people. References to aging populations or “demographic tsunamis” in the motivations for papers or research on eldercare robots treat the presence of older people in the population as itself a problem to be solved. Robots are postulated as the solution, despite the fact they would not be considered desirable were they to be directed toward the needs of younger people. Investment in research into robots continues, nonetheless, because older people are almost never involved in setting research priorities around eldercare or in the design of technological solutions to problems faced by older people.<a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a></p><p id="p-29">It might be argued that these criticisms have less force against digital companions than they do against social robots for eldercare because digital companions are typically advertised as intended for the lonely and socially isolated in general, not just for older persons. However, this larger cohort, “lonely and socially isolated persons,” plays essentially the same role in the literature on digital companions as “older persons” does in the literature on social robots, and the attitudes this literature expresses toward this cohort are problematic for the same reasons. Those experiencing loneliness and/or social isolation are implicitly “othered” in discussions of digital companions, treated as a problem to be solved. Those designing, developing, or touting digital companions as cures for loneliness and social isolation seldom, if ever, suggest that they themselves aspire to a life lived alongside only machines. Almost by definition, lonely and socially isolated people play little role in discussions about how—or, indeed, whether—this technology should be developed.</p></section><section id="sec12" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Replacing real relationships.</strong>  A third central concern in the debate about the ethics of using social robots for eldercare is the extent to which this might lead to older persons being deprived of opportunities for relationships with people.<a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a> The claim that robots are a solution to the problem of a shortage of eldercare workers implies that robots will be able to take on roles in the eldercare sector currently performed by humans. Yet every interaction that older people have with a robot is one less opportunity for them to interact with a human. The economics of the eldercare sector strongly suggest that money saved by replacing people in existing roles with robots will not be reinvested in roles that might provide people with more human contact.<a class="reference-link xref xref-bibr" href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a> Perversely, were this technology to be fully realized, there is every chance that it would lead to a substantial increase in social isolation.</p><p id="p-31">We believe that the risk that ersatz companions might increase social isolation is even more pressing when it comes to digital companions, in part simply because we think digital companions may work to reduce loneliness whereas social robots are unlikely to.<a class="reference-link xref xref-bibr" href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a></p><p id="p-32">Imaginary friends may outcompete real friends for our time and attention by appearing, superficially, to be better friends.<a class="footnote-link xref xref-fn" href="#FN6" data-jats-rid="FN6" data-jats-ref-type="fn"><sup>f</sup></a> Digital companions have a number of advantages relative to human beings when it comes to their capacity to sustain engagement with users. Most obviously, they can be available any time, day or night, 365 days a year. Moreover, unlike real people, their sole purpose can be to satisfy the user’s desires. They will never be rude, selfish, thoughtless, or judgmental—unless their being so will itself contribute to increased engagement.<a class="footnote-link xref xref-fn" href="#FN7" data-jats-rid="FN7" data-jats-ref-type="fn"><sup>g</sup></a> Thus, not only might online interactions with digital companions crowd out real relationships from users’ lives, but they might also change what users expect from their friends to the point that relationships with real people are seen as unsatisfying in comparison.<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B43" data-jats-ref-type="bibr" data-jats-rid="B43"><sup>43</sup></a></p><p id="p-33">Importantly, that relationships with digital companions might substitute for relationships with real people is an assumption of the argument that digital companions offer a potential technological solution to loneliness and social isolation: If they cannot, then digital companions <i>will not</i> reduce loneliness or (less plausibly) social isolation, as their proponents hope. Moreover, it is hard to see how digital companions might be engaging enough to be emotionally rewarding (and thus cause people to feel less lonely) but not so compelling as to compete with relationships with real people. More fundamentally, insofar as relationships with digital companions reduce loneliness, they will reduce users’ motivation to seek out relationships with real people. This means that the presence of digital companions in a community is likely to increase the social isolation of third parties as well as users of digital companions.</p><p id="p-34">The advent of digital companions may also exacerbate social isolation by reducing the pressure on healthcare systems and government agencies to address the economic, social, and technological causes of loneliness and social isolation. That is, the development of digital companions will make it easy for governments and owners of eldercare facilities to <i>appear</i> as though they are doing something about social isolation by providing citizens, or clients, with digital companions, even though these technologies will mostly leave social isolation intact. If people do in fact feel less lonely as a result of having imaginary friends, they may be less likely to demand that governments and/or the owners of eldercare facilities provide them with opportunities to establish social connections with real people.</p></section><section id="sec13" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>What imaginary friends cannot do.</strong>  Fourth, and finally, these products are dangerous by virtue of their potential to deprive users of important objective goods. Being happy is not enough to establish that one is leading a flourishing human life: If it were, one could treat loneliness and social isolation purely pharmaceutically. It is much more plausible to hold that a good human life includes various objectively good things, including, for instance, health, beauty, love, friendship, and social affirmation. As this list suggests, many of these goods are associated with relationships with those around us and, as such, cannot be secured through interactions with non-sentient machines. In particular, social robots are not able to provide people with the respect and social recognition that affirm individuals’ status as members of a community and that are important components of well-being according to any plausible theory of well-being.<a class="reference-link xref xref-bibr" href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a> These criticisms also have force against digital companions, which can provide only shallow imitations of these goods rather than the real thing.</p></section><section id="sec14" class="inline-headings-section"><p data-jats-content-type="inline-heading"><strong>Some further limitations of digital companions.</strong>  Although digital companions are more engaging than existing social robots, they suffer in comparison to social robots when it comes to the extent to which they can satisfy other important human needs—for touch, physical companionship, and for care expressed through assistance with physical tasks.</p><p id="p-37">Human beings have a powerful innate need for creaturely touch. Skin to skin (or fur) contact with other humans or animals induces a pronounced physiological response in human beings.<a class="reference-link xref xref-bibr" href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a> There is now a large literature exploring the health benefits of relationships with animals<a class="reference-link xref xref-bibr" href="#B45" data-jats-ref-type="bibr" data-jats-rid="B45"><sup>45</sup></a> as well as the harms associated with the absence of physical intimacy.<a class="reference-link xref xref-bibr" href="#B40" data-jats-ref-type="bibr" data-jats-rid="B40"><sup>40</sup></a> Touch is also ethically significant. In particular, care is often expressed through touch.</p><p id="p-38">The importance of touch has not gone unnoticed by the designers of social robots, which now include a number of robot animals explicitly advertised as allowing users to “pet” them and to supposedly benefit from doing so.<a class="reference-link xref xref-bibr" href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a><sup>,</sup><a class="reference-link xref xref-bibr" href="#B44" data-jats-ref-type="bibr" data-jats-rid="B44"><sup>44</sup></a> The famed Japanese roboticist Hiroshi Ishiguro has even made a robot that is supposed to “transmit” hugs provided remotely by another human being.<a class="reference-link xref xref-bibr" href="#B26" data-jats-ref-type="bibr" data-jats-rid="B26"><sup>26</sup></a> We are skeptical of the extent to which touching machines produces the benefits associated with touching people or animals, but it is clear that this is a domain where (purely) digital companions have nothing to offer.</p><p id="p-39">Another way in which digital companions are lacking is that they are unable to provide users with physical companionship more generally. Human beings respond to each other’s presence as well as to each other’s touch.<a class="reference-link xref xref-bibr" href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a> As the dissatisfying experience of Zoom or Teams calls makes all too clear, the mere fact of other people being physically present with us makes a difference. Physical copresence also plays a role in the formation of memories and narratives that play a key role in social relationships: Going through something together helps people form social bonds. Granted, digital companions and their users may come to have a shared history of conversation and online “experiences.” Digital companions could, for instance, hark back to conversations they have had with a user, games they have played together, and other online experiences that they have shared, in order to affirm and strengthen their “relationship.” However, there is a clear limit to the capacity of digital companions to share experiences and provide companionship here.</p><p id="p-40">Finally, and relatedly, the provision of help with real-world tasks is an important mark and component of both solidarity and care. Helping the people we love, for instance, by assisting them in walking up stairs, bringing them food, or bathing them, is an expression of our love for them. When we help each other in this way—“mutual aid”—we affirm our recognition of our mutual worth. Digital companions are obviously severely limited in what they can contribute in this regard. Again, this is not to deny that digital companions could provide some forms of help to their users. A sophisticated digital companion might, for instance, make a doctor’s appointment for a user, remind them to take a list of the medications that they are currently on to the appointment, provide advice on what time they need to leave home to get there, order a taxi for them, and notify them when it arrives. However, those who only have digital companions will be lost if they need someone to help them weed the garden or hold their hand to help them out of a car. Although such tasks remain beyond the current capacities of robots, it is at least conceivable that they might one day assist in this way.</p><p id="p-41">Discussions of the prospects for digital companions have neglected the role played by touch, physical companionship, and mutual aid in promoting human well-being.<a class="footnote-link xref xref-fn" href="#FN8" data-jats-rid="FN8" data-jats-ref-type="fn"><sup>h</sup></a> Digital companions will not be able to satisfy people’s need for these important goods. If the availability of digital companions leads to reductions in the number of real friends that people have, as we have argued is highly likely, then this technology will leave people worse off by virtue of depriving them of opportunities to experience touch or human companionship or to help each other with physical tasks, as well as depriving them of recognition and respect. Insofar as the absence of these goods causes people to feel lonely, the inability of imaginary friends to provide them may also affect the extent to which digital companions reduce loneliness.</p></section></section><section id="sec15" class="sec"><h2 class="heading">Privacy, Representation, Manipulation, and Complicity</h2><p id="p-42">We have been concerned here with arguments that bear on the question of whether digital companions should be used to combat loneliness and social isolation at all. Inevitably, the use of digital companions would raise a further set of questions about their design and operation. In particular, issues about the privacy of users loom large given the intimate nature of the data that would be collected by digital companions.<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> The design of digital companions raises issues in media ethics, about the representation of people of different races and genders, and about the responsibility of creators for the impact of the art they create. Digital companions will offer unparalleled opportunities to shape the personalities of—indeed, to manipulate—their users, which suggests that their design would need to be strictly regulated.<a class="reference-link xref xref-bibr" href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> Conversely, in some circumstances, the failure of a digital companion to intervene when a user threatens other people or expresses sexist, racist, or otherwise morally reprehensible views, may itself make its designers culpable. Again, the boundaries of whether, when, and how digital companions should intervene in response to troubling statements by, or patterns of behavior from, their users will need to be determined by the broader community. Unfortunately—or perhaps fortunately—these issues are beyond the scope of our discussion here.</p></section><section id="sec16" class="sec"><h2 class="heading">Conclusion</h2><p id="p-43">Rising rates of loneliness and social isolation in industrialized societies constitute a “wicked problem”: It is little wonder that engineers and policymakers are tempted by the idea that there might be a technological solution. Digital companions seem to have several advantages over the social robots that have previously been touted as having the potential to reduce these evils. We have argued that, nevertheless, digital companions can be, at most, imaginary friends, which can do little, if anything, to address social isolation, even if they do reduce loneliness in some cases. We have shown that powerful criticisms in the literature on the ethics of the design and use of social robots for eldercare settings also apply to digital companions. In particular, there is a real risk that the development of digital companions will actually work to increase social isolation. We have also suggested that social robots might even have a number of advantages relative to (purely) digital companions that the literature on the latter topic has thus far neglected.</p><p id="p-44">The implications of these observations for the larger debate about the wisdom of deploying digital companions are more complex than might first appear. It is loneliness—rather than social isolation per se—that makes people miserable. Any technology or policy that might reduce loneliness therefore deserves to be taken seriously. If, in particular cases, the choice is really between an individual having no companions or a digital companion, they may well be better off with a digital companion that allows them to feel less lonely. Yet social isolation is also arguably objectively bad, as well as being bad for people’s health, even when they are not lonely. Although some of the effects of social isolation on human health are probably the product of the loneliness that typically accompanies social isolation, others probably are not. For instance, those who are socially isolated are less likely to be encouraged by those around them to seek medical help and less likely to benefit from the help with daily living that other people can provide.</p><p id="p-45">The prospect of a technology that might reduce loneliness but increase social isolation, as we have argued is likely true of digital companions, therefore forces us to confront difficult trade-offs. Should we reduce people’s misery at the cost of making them objectively worse off by virtue of being more socially isolated? Is it more important to express respect for people or to promote their happiness? Will the development of digital companions lead policymakers to be less motivated to pursue policies intended to reduce social isolation? Answering these questions will require paying close attention to the impact of this technology on the experience and relationships of users and those around them. It will also require us to confront deep ethical and philosophical questions: about what we owe to each other, about what it is to lead a good human life, and about the sort of world we want to create with AI. A future in which people spend all their time at home with their imaginary friends without ever touching, or being touched by, another human being is, we submit, a future to be avoided. Whether it will be possible to develop and use digital companions to combat loneliness and social isolation without bringing about such a world remains to be seen.</p></section><section id="sec17" class="sec"><h2 class="heading">Acknowledgments</h2><p id="p-46">The authors would like to thank Simon Coghlan for suggestions as to relevant sources in the literature on human-animal relations. Professor Sparrow is an associate investigator in the Australian Research Council Centre of Excellence for Automated Decision-making and Society (Grant number CE200100005) and worked on this article in this role.</p></section></div></article><!-- /wp:post-content -->]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/research/against-imaginary-friends-why-digital-companions-are-no-solution-to-social-isolation/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		      <dc:creator><![CDATA[James Brown]]></dc:creator>
<post-id xmlns="com-wordpress:feed-additions:1">775695</post-id>	</item>
		<item>
		<title>Is There an End to Forever Chemicals?</title>
		<link>https://cacm.acm.org/news/is-there-an-end-to-forever-chemicals/</link>
					<comments>https://cacm.acm.org/news/is-there-an-end-to-forever-chemicals/#respond</comments>
		
		<dc:creator><![CDATA[Samuel Greengard]]></dc:creator>
		<pubDate>Thu, 08 Jan 2026 21:58:32 +0000</pubDate>
				<category><![CDATA[Architecture and Hardware]]></category>
		<category><![CDATA[Computing Applications]]></category>
		<category><![CDATA[Society]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775508</guid>

					<description><![CDATA[<p>Individual companies are exploring ways to reformulate, substitute, or eliminate forever chemicals.</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Semiconductors power the modern world. They’re inside everything from phones and gaming consoles to refrigerators and automobiles. Yet somewhere between convenience and productivity lies an unpleasant truth: manufacturing these devices requires a group of chemicals called PFAS,<a class="footnote-link xref xref-fn" href="#FN1" data-jats-rid="FN1" data-jats-ref-type="fn"><sup>a</sup></a> which go by the formal name <i>per- and polyfluoroalkyl substances</i>.</p>
<p id="p-2">Some PFAS compounds are toxic, and they’re extraordinarily difficult to destroy. As a result, these chemicals wind up in water, air, soil and crops.<a class="footnote-link xref xref-fn" href="#FN2" data-jats-rid="FN2" data-jats-ref-type="fn"><sup>b</sup></a> Not surprisingly, they also find their way into the fatty tissue of animals, including humans, where they may cause cancers<a class="footnote-link xref xref-fn" href="#FN3" data-jats-rid="FN3" data-jats-ref-type="fn"><sup>c</sup></a> and metabolic disorders.<a class="footnote-link xref xref-fn" href="#FN4" data-jats-rid="FN4" data-jats-ref-type="fn"><sup>d</sup></a></p>
<p id="p-3">“PFAS have been termed ‘forever chemicals’ because they are resistant to breaking down and some of them can circulate through the human body for years,” said Erin Baker, an associate professor in the Department of Chemistry at the University of North Carolina at Chapel Hill.</p>
<p id="p-4">It’s a growing cause for alarm. Today, more than 15,000 PFAS are used to produce upwards of 39,000 electronic components.<a class="footnote-link xref xref-fn" href="#FN5" data-jats-rid="FN5" data-jats-ref-type="fn"><sup>e</sup></a> This includes semiconductors, wires, cables, batteries, resistors and printed circuit boards. Finding safe and affordable replacements for these compounds is extraordinarily difficult. All while demand for high performance chips continues to rise.</p>
<p id="p-5">“Semiconductor manufacturers are aware of the concerns and motivated to act, but they also aren’t willing to risk their technological leadership or produce inferior products,” said Andrew Chien, a professor of computer science at the University of Chicago, a senior scientist at Argonne National Laboratory, and former Editor-in-Chief of <em>Communications</em>. “There doesn’t seem to be any easy fix for this problem.”</p>
</section>
<section id="sec2" class="sec">
<h2 class="heading">Toxic by Design</h2>
<p id="p-6">PFAS aren’t a recent invention. In the late 1930s, scientists for the Manhattan Project discovered that certain chemicals provided superior insulation capabilities. Since the 1950s, manufacturers have used PFAS in a wide range of products, including nonstick cookware,<a class="footnote-link xref xref-fn" href="#FN6" data-jats-rid="FN6" data-jats-ref-type="fn"><sup>f</sup></a> clothing, carpeting, furniture, firefighting foam, and food packaging. The appeal is simple: this group of compounds are fire-resistant, waterproof, and stain-repellent. “PFAS are extraordinarily stable. They are ideal for producing many things,” Chien said.</p>
<p id="p-7">In the electronics industry, PFAS play a pivotal role in manufacturing high-performance chips that are resistant to heat and chemical degradation. (PFAS aren’t in chips; they are a waste product resulting from the manufacturing process.) These substances are essential for photolithography and dry etching; they allow chip makers to craft intricate designs by precisely controlling material removal and deposition. In addition, PFAS appear in cleaning products and infrastructure, where they serve as lubricants, heat transfer fluids, and stable processing gasses.</p>
<p id="p-8">The problem is how to dispose of PFAS waste, which may exceed one million metric tons (1 megatonne) annually.<a class="footnote-link xref xref-fn" href="#FN7" data-jats-rid="FN7" data-jats-ref-type="fn"><sup>g</sup></a> Assembling accurate numbers for the semiconductor industry is next to impossible because chip makers use numerous processes and rely on many different PFAS, but a report<a class="footnote-link xref xref-fn" href="#FN8" data-jats-rid="FN8" data-jats-ref-type="fn"><sup>h</sup></a> from global sustainability firm ADEC Innovations found that 5% to 25% of PFAS used in electronics manufacturing find their way into the environment.</p>
<p id="p-9">Amid mounting pressure from regulators, environmental groups, investors, and the public, the electronics industry has begun phasing out some of the most hazardous PFAS compounds. These include so-called long-chain molecules, which consist of six or more perfluorinated carbon atoms. These structures tend to be more bio-accumulative and toxic. “They like to stick to organic tissue, and they are found in the blood,” Baker explained. “When we examine animals, we see PFAS bio-accumulation in everything from fish fillets in North Carolina to polar bears in the Arctic. We even see it in human breast milk.”</p>
<p id="p-10">But short-chain PFAS also present risks. “They are actually more difficult to eliminate than the long-chain varieties,” said Jinyong Liu, an associate professor in the Chemical Environmental Engineering Department at the University of California, Riverside. The reason? “In general, long-chain molecules contain relatively weak carbon bonds. As you shorten the chain, the weak bonds disappear,” he explained.</p>
<p id="p-11">Short-chain PFAS are also challenging to treat because most destruction technologies depend on reactions that occur with solid-water or gas-water interfaces, Liu explained. On the other hand, long-chain PFAS naturally migrate to the boundaries between these surfaces, where they are more susceptible to destruction.</p>
<p id="p-12">In practical terms, this means that short-chain PFAS are even more difficult and expensive to eradicate from the environment than long-chain PFAS. While the semiconductor industry touts short-chain PFAS as a safer alternative—in part because they tend to accumulate in animals and humans at lower levels and they possess shorter half-lives than long-chain PFAS—they still pose serious toxicity risks. Moreover, many aren’t yet as heavily regulated because they aren’t as well understood as long-chain PFAS.</p>
<p id="p-13">The situation is changing. In April 2024, the U.S. Environmental Protection Agency (EPA) finalized enforceable drinking water standards<a class="footnote-link xref xref-fn" href="#FN9" data-jats-rid="FN9" data-jats-ref-type="fn"><sup>i</sup></a> for six PFAS compounds: PFOA, PFOS, PFNA, PFBS, PFHxS, and GenX. The new rules require public water systems to reduce concentrations to near zero—4 parts per thousand (PPT) for PFOA and PFOS—within five years. Initial monitoring will begin in 2027, with enforcement rolling out in phases. In addition, a dozen states<a class="footnote-link xref xref-fn" href="#FN10" data-jats-rid="FN10" data-jats-ref-type="fn"><sup>j</sup></a>—including Alaska, California, Colorado, Hawaii, Oregon, Maryland, and Minnesota—have established rules and restrictions for certain PFAS compounds.</p>
<p id="p-14">Regulators in the European Union (EU) have taken an even tougher stance on forever chemicals. The EU already restricts<a class="footnote-link xref xref-fn" href="#FN11" data-jats-rid="FN11" data-jats-ref-type="fn"><sup>k</sup></a> the use of certain PFAS in consumer textiles, food packaging, cosmetics, firefighting foam, and other products. In addition, five EU countries (Denmark, Germany, the Netherlands, Norway, and Sweden) have proposed<a class="footnote-link xref xref-fn" href="#FN12" data-jats-rid="FN12" data-jats-ref-type="fn"><sup>l</sup></a> comprehensive PFAS restrictions that could span as many as 10,000 PFAS compounds, with exemptions only for the most essential uses.</p>
<p id="p-15">Although stepped up regulation is likely to reduce forever chemical hazards, it’s unclear exactly what the impact will be. What’s more, in the U.S. the EPA has sent mixed signals related to PFAS use by the semiconductor industry. While it has publicized<a class="footnote-link xref xref-fn" href="#FN13" data-jats-rid="FN13" data-jats-ref-type="fn"><sup>m</sup></a> its efforts to restrict the use of forever chemicals, the <i>Guardian</i> reported<a class="footnote-link xref xref-fn" href="#FN14" data-jats-rid="FN14" data-jats-ref-type="fn"><sup>n</sup></a> in December 2024 that it also was fast-tracking new PFAS chemicals for use by the semiconductor industry.</p>
<p id="p-16">“Many companies have vowed to switch the PFAS chemicals they use to manufacture products,” Baker said. “The problem is that if a substance gets phased out, they switch to another PFAS compound that may eventually be deemed toxic. There’s a vast universe of PFAS chemicals that haven’t undergone toxicity testing.”</p>
</section>
<section id="sec3" class="sec">
<h2 class="heading">Chemical Reactions</h2>
<p id="p-17">Amid all the uncertainty, the chip industry knows it must adapt—without compromising chip quality or pricing. Imec, an independent research arm of the semiconductor industry, is now focusing some of its R&amp;D efforts on replacing the most harmful chemicals.<a class="footnote-link xref xref-fn" href="#FN15" data-jats-rid="FN15" data-jats-ref-type="fn"><sup>o</sup></a> “The most efficient time to introduce a change is before it is released to manufacturing,” said Emily Gallagher, program director for Sustainable Semiconductor Technologies and Systems at Imec.</p>
<p id="p-18">One area of interest for Imec is advanced photoresists used in extreme ultraviolet (EUV) lithography. The institute is currently working with semiconductor industry suppliers to identify and test PFAS-free substitutes. It also is looking for ways to reduce PFAS chemicals in cover DUV resists, underlayers, and rinses—along with semiconductor waste streams. The objective, Gallagher said, is to better measure and control long-term contamination without disrupting highly optimized manufacturing processes.</p>
<p id="p-19">Individual companies are also exploring ways to reformulate, substitute, or eliminate PFAS. For example, IBM is using artificial intelligence to identify PFAS alternatives. Its platform, MatGFN-PFAS,<a class="footnote-link xref xref-fn" href="#FN16" data-jats-rid="FN16" data-jats-ref-type="fn"><sup>p</sup></a> taps generative flow networks and chemical language models to engineer molecules that maintain the desirable properties of PFAS while reducing or eliminating toxicity. So far, the company has identified more than 6,000 molecules that could eventually serve as replacements for PFAS in chip photolithography.</p>
<p id="p-20">Yet transitioning from the lab to the fab is a slow and costly process. It can require retooling as well as a complete reengineering of manufacturing processes. In some cases, there are no alternatives to current processes;<a class="footnote-link xref xref-fn" href="#FN17" data-jats-rid="FN17" data-jats-ref-type="fn"><sup>q</sup></a> the laws of chemistry and physics require PFAS. Imec’s Gallagher pointed out that the goal isn’t so much to go ‘green’ (“the semiconductor industry is not environmentally friendly,” she stated)—it’s to reduce its environmental impact, including hazards. “Restrictions are a strong motivator for promoting global alignment,” she said.</p>
<p id="p-21">In fact, the transition to safer chemicals is a long and complicated path, Chien said. “Right now, there are no obvious replacements for most PFAS chemicals and making progress is difficult.” Semiconductor firms, while motivated to show they are working to reduce or eliminate PFAS, also don’t want to destroy their competitive edge. “There are a number of industry initiatives underway, but they have so far not uncovered any easy pathway to eliminate the use of PFAS,” he noted.</p>
</section>
<section id="sec4" class="sec">
<h2 class="heading">Path to Destruction</h2>
<p id="p-22">Scientists are attacking forever chemicals on another front: neutralizing or destroying them before they enter the environment. At present, manufacturers rely on a handful of methods to dispose of PFAS. These include carbon filtering, high-temperature incineration,<a class="footnote-link xref xref-fn" href="#FN18" data-jats-rid="FN18" data-jats-ref-type="fn"><sup>r</sup></a> hazardous waste landfills, and waste injection wells.<a class="footnote-link xref xref-fn" href="#FN19" data-jats-rid="FN19" data-jats-ref-type="fn"><sup>s</sup></a></p>
<p id="p-23">However, none of these options are ideal. Because the carbon-fluoride bonds in PFAS are chemically stable and resistant to combustion, incomplete incineration can result in a direct release of toxins into the environment.<a class="footnote-link xref xref-fn" href="#FN20" data-jats-rid="FN20" data-jats-ref-type="fn"><sup>t</sup></a> Researchers found that even at a temperature of 850 degree Celsius, 1% of the PFAS aren’t destroyed.<a class="footnote-link xref xref-fn" href="#FN21" data-jats-rid="FN21" data-jats-ref-type="fn"><sup>u</sup></a></p>
<p id="p-24">Hazardous waste landfills and waste injection wells do nothing to destroy the chemical bonds, and there’s an ongoing risk of forever chemicals leaching into aquifers and contaminating drinking water—even when these facilities are managed properly. Adding to the concern: most conventional water treatment facilities aren’t equipped to remove PFAS.<a class="footnote-link xref xref-fn" href="#FN22" data-jats-rid="FN22" data-jats-ref-type="fn"><sup>v</sup></a></p>
<p id="p-25">Getting to a viable destruction solution is extraordinarily difficult. Emerging technologies span a broad and experimental set of approaches, including bioremediation (such as using bacteria to degrade PFAS compounds), electrocoagulation, foam fractionation, sonolysis, photocatalysis, mechanochemical, electrochemical degradation, and using beams of electrons and plasma.<a class="footnote-link xref xref-fn" href="#FN23" data-jats-rid="FN23" data-jats-ref-type="fn"><sup>w</sup></a> However, a group of Australian researchers who examined these techniques found that while some show potential in the laboratory or limited success in actual use, they currently trend toward expensive and ineffective.<a class="footnote-link xref xref-fn" href="#FN24" data-jats-rid="FN24" data-jats-ref-type="fn"><sup>x</sup></a></p>
<p id="p-26">“We do not have a single method that will work for all of the PFAS molecules . . . so when we study PFAS degradation, the important thing is to match the right technology with the right PFAS to ensure that they’re actually destroyed,” Liu explained. He is exploring ways to use UV radiation<a class="footnote-link xref xref-fn" href="#FN25" data-jats-rid="FN25" data-jats-ref-type="fn"><sup>y</sup></a> and oxidation<a class="footnote-link xref xref-fn" href="#FN26" data-jats-rid="FN26" data-jats-ref-type="fn"><sup>z</sup></a> to break carbon-fluoride bonds and destroy PFAS molecules. Yet it isn’t clear which technology or combination of technologies will prove best suited to the semiconductor industry, which “produces wastewater with a broader set of PFAS and other chemicals than other industries,” he noted.</p>
<p id="p-27">One company at the forefront of PFAS destruction is Switzerland-based Oxyle. It has developed a modular solution that handles site remediation, groundwater cleanup, and industrial wastewater treatment for long-chain, short-chain, and ultra short-chain PFAS. The system uses reduction and oxidation processes to degrade challenging PFAS into harmless mineral byproducts such as carbon dioxide and fluoride. Oxyle reported up to 99.8% removal for 11 different PFAS compounds, including 98% of some short-chain PFAS.<a class="footnote-link xref xref-fn" href="#FN27" data-jats-rid="FN27" data-jats-ref-type="fn"><sup>aa</sup></a></p>
<p id="p-28">“We come at the end of the pipeline,” said Oxyle co-founder and CEO Fajer Mushtaq. “After solids and solvents are removed, we handle what’s left: concentrated PFAS waste that other systems can’t treat effectively.” Oxyle’s scalable technology integrates monitoring and remediation processes with existing infrastructure. “It’s effective for a broad range of PFAS compounds in a wide array of conditions,” Mushtaq said.</p>
<p id="p-29">While semiconductors account for only a fraction of overall PFAS use—likely in the low single-digit percentages—they are among the most reliant on PFAS for performance and precision, making the sector one of the most challenging to reform. “We have to identify compounds that deliver the properties of PFAS chemicals without the toxicity and health hazards,” Chien said. “It may take decades to eliminate forever chemicals, but the industry cannot afford inaction.”</p>
<h2 id="FurtherReading" class="heading">Further Reading</h2>
<ul id="reflist1" class="ref-list">
<li class="ref">
<div id="B1" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Bhattacharya, A., Fathima, J., Varghese, S., Chatterjee, P., and Gadhamshetty, V.</em> <br />Advances in bioremediation strategies for PFAS-contaminated water and soil. <em><span class="italic">Soil &amp; Environmental Health</span></em>, Volume 3, Issue 1 (January 2025). <a class="ext-link" href="https://www.sciencedirect.com/science/article/pii/S2949919424000694" data-jats-ext-link-type="uri">https://www.sciencedirect.com/science/article/pii/S2949919424000694</a></span></div>
</li>
<li class="ref">
<div id="B2" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Leung, S.C.E., Shukla, P., Chen, D., Eftekhari, E., An, H., et al.</em><br />Emerging technologies for PFOS/PFOA degradation and removal: A review. <em><span class="italic">Science of The Total Environment</span></em>, Volume 827, 25 (June 2022). <a class="ext-link" href="https://www.sciencedirect.com/science/article/abs/pii/S0048969722007616?via%3Dihub" data-jats-ext-link-type="uri">https://www.sciencedirect.com/science/article/abs/pii/S0048969722007616?via%3Dihub</a></span></div>
</li>
<li class="ref">
<div id="B3" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Liu, Z., Chen, Z., Gao, J., Yi, Y. et al.</em><br />Accelerated degradation of perfluorosulfonates and perfluorocarboxylates by UV/sulfite + iodide: Reaction mechanisms and system efficiencies. <em><span class="italic">Environmental Science &amp; Technology</span></em>, Vol. 56, Issue 6 (February 28, 2022). <a class="ext-link" href="https://pubs.acs.org/doi/10.1021/acs.est.1c07608" data-jats-ext-link-type="uri">https://pubs.acs.org/doi/10.1021/acs.est.1c07608</a></span></div>
</li>
<li class="ref">
<div id="B4" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Ober, C.K., Kafer, F., and Deng, J.</em> <br />Review of essential use of fluorochemicals in lithographic patterning and semiconductor processing. <em><span class="italic">Journal of Micro/Nanopatterning, Materials, and Metrology</span></em>, Vol. 21, Issue 1 (March 2022). <a class="ext-link" href="https://bit.ly/4pcuBK6" data-jats-ext-link-type="uri">https://bit.ly/4pcuBK6</a></span></div>
</li>
<li class="ref">
<div id="B5" class="citation"><span class="mixed-citation" data-jats-publication-type="other"><em>Yuting, W., Gui, J., Howe, C.G., Edmond, J.A. et al.</em> <br />Association of diet with per- and polyfluoroalkyl substances in plasma and human milk in the New Hampshire Birth Cohort Study, <em><span class="italic">Science of The Total Environment</span></em>, Volume 933, 10 (July 2024). <a class="ext-link" href="https://www.sciencedirect.com/science/article/abs/pii/S0048969724033047" data-jats-ext-link-type="uri">https://www.sciencedirect.com/science/article/abs/pii/S0048969724033047</a></span></div>
</li>
</ul>
</section>
<section id="sec5" class="sec"></section>
</div>
<footer class="back"></footer>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/news/is-there-an-end-to-forever-chemicals/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">775508</post-id>	</item>
		<item>
		<title>The Rise of Computational Thinking in the Age of AI</title>
		<link>https://cacm.acm.org/opinion/the-rise-of-computational-thinking-in-the-age-of-ai/</link>
					<comments>https://cacm.acm.org/opinion/the-rise-of-computational-thinking-in-the-age-of-ai/#respond</comments>
		
		<dc:creator><![CDATA[Leah Hoffmann]]></dc:creator>
		<pubDate>Wed, 07 Jan 2026 21:35:28 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence and Machine Learning]]></category>
		<category><![CDATA[Education]]></category>
		<category><![CDATA[Philosophy of Computing]]></category>
		<guid isPermaLink="false">https://cacm.acm.org/?post_type=digital-library&#038;p=775520</guid>

					<description><![CDATA[<p>"The growing consensus is that computational thinking is more important than ever."</p>]]></description>
										<content:encoded><![CDATA[<article>
<div class="body" lang="en">
<section id="sec1" class="sec">
<p id="p-1">Computing is hardly the only discipline in which AI has prompted a moment of reflection. Yet coding agents and app generators raise profound questions about the purpose of the field—and indeed, its very nature. At this challenging juncture, Jeannette Wing, Executive Vice President for Research and professor of Computer Science at Columbia University, finds herself reflecting on a concept she’s promoted for nearly 20 years: <a href="https://bit.ly/47ZrBuN">computational thinking</a>, or the mental tools and processes that give computer science its power. Here, she discusses how the idea has evolved—and which aspects of computational thinking will be most relevant in the future.</p>
<p id="p-2"><b>When we <a href="https://bit.ly/3HRoLxt">last spoke</a>, you had just popularized the term “computational thinking” to describe how computer science transcends computer programming—and to capture the value of the models, methods, and abstractions that computer scientists use to solve problems. Let’s get right into it: what is computational thinking in the age of AI?</b></p>
<p id="p-3">When I <a href="http://(https://bit.ly/4m1fdO9">first wrote about computational thinking</a>, I wanted to make the point that the value of computer science goes beyond the specific programming skills that we teach. But I felt that a lot of people, especially in the realms of K–12 and introductory undergraduate education, took that to mean we should teach coding to everyone. They equated computational thinking with computer programming, which is exactly what I was trying to get away from. In some sense, programming is just a skill you learn in order to express concepts in a way that machines can actually execute.</p>
<p id="p-4"><b>And now that AI can generate increasingly viable code, programming has become something of a commodity.</b></p>
<p id="p-5">The real question is, what and how should we be teaching our students in the context of AI? Should we bother to teach coding, or should we just teach students how to use AI tools? When I talk to my computer science colleagues in both academia and industry, the growing consensus is that computational thinking is more important than ever. AI offloads a lot of the mental activity you would otherwise have to do on your own. But it doesn’t take away the need for you to understand what is generated. You still need to have an appreciation of what coding is and what code expresses in terms of algorithms and data structures, time and space efficiency, and so on.</p>
<p id="p-6"><b>At the moment, at least, AI code is also far from perfect.</b></p>
<p id="p-7">We know AI can generate bad code. We know it can generate buggy code, and we know it can generate code with security vulnerabilities. So we hardly want the masses to use AI tools to generate code and take the output at face value.</p>
<p id="p-8"><b>This reminds me of some of your earlier work <a href="https://bit.ly/42fiQJl">on trustworthy AI</a></b><b>—in particular, about using formal methods to ensure that AI systems demonstrate things like reliability, safety, accuracy, robustness, and other properties.</b></p>
<p id="p-9">The missing link right now with any AI system—whether it’s to produce text or code or images or video—is a verification step of some kind that says, “This system has all the properties we expect from trustworthy computing.” Of course, the challenge is that verifying AI systems means incorporating probabilistic reasoning and behavior. So suddenly, we have to revisit all those trustworthiness properties where things are not necessarily right or wrong, true or false, yes or no, on or off.</p>
<p id="p-10"><b>In a sense, it sounds like that’s another facet of computational thinking that’s more relevant in the age of AI—the abstractions of statistics and probability in addition to algorithms and data structures.</b></p>
<p id="p-11">When I think back to my own undergraduate courses, I’m so grateful that, as a computer science major, I was required to take probability, statistics, linear algebra, and all of the mathematical foundations that computer science builds on. Math teaches you skills like analysis, proof, and precision—it goes back to the basics, not unlike English courses where you’re learning how to read and write.</p>
<p id="p-12"><b>Ethics is another issue that I’d expect to have increased relevance. I don’t know if you would call that an aspect of computational thinking per se, but it’s certainly an intimate neighbor.</b></p>
<p id="p-13">I would relate ethics to the <a href="https://bit.ly/4p1BzSF">AI alignment problem</a>, where we strive to build an AI system that aligns with human values. A few years ago, when I worked on ethics in data science with my colleague Chris Wiggins here at Columbia, we started with the Belmont principles.</p>
<p id="p-14"><b>These were <a href="ps://bit.ly/4lVZoIw">standards released</a> by a Congressionally funded committee in 1978 that identify guidelines for addressing basic ethical issues that arise from research on human subjects.</b></p>
<p id="p-15">The three Belmont principles are Respect for Persons, Beneficence, and Justice. Others have proposed additional principles, but let’s just start with these three, as applied to computing and AI systems. The principle of Respect for Persons suggests, for example, that people should always be informed when they are talking with a chatbot. The principle of Beneficence requires researchers to conduct a risk/benefit analysis to maximize possible benefits and minimize possible harms—in, for instance, the decision a self-driving car might make on whom not to harm. Finally, the ethical principle of Justice requires us to ensure the fairness of risk assessment tools in the court system and automated decision systems used in hiring.</p>
<p id="p-16"><b>That’s a principle with which you’ve got some personal experience, through your involvement with a <a href="https://bit.ly/4ngsJi5">2019 task force</a> that sought to ensure fairness in New York City’s use of automated decision systems.</b></p>
<p id="p-17">The genesis of the task force was that many agencies in New York City were making decisions about New York City residents using automated tools. Who gets low-income housing? Whose garbage gets picked up first? Who gets released without posting bail? There are fairness issues behind each of those questions, and if AI or automated decision tools are being used to decide, then you could imagine not always being fair to each resident or to each of the many different populations that the city serves. At any rate, these questions will continue to be with us, and the Belmont principles are a starting point to help address them.</p>
<p id="p-18"><b>Back in 2008, you listed “What is intelligence?” among the field’s <a href="https://bit.ly/4mVuNfF">core questions</a></b><b>. In the age of AI, it seems more relevant than ever. What other questions do you think are relevant to the future computing?</b></p>
<p id="p-19">We continue to debate the philosophical differences between human intelligence and machine intelligence. Now, advances in generative AI raise additional philosophical questions such as “What is creativity?” While machines can create artifacts, are there aspects of human creativity that distinguish humans from machines?</p>
<p id="p-20"><b>Of course, AI is not the only thing that’s prompting us to reevaluate the nature of computing. How do you see those issues from your vantage as a university administrator?</b></p>
<p id="p-21">We need to rethink how research universities are structured, how we think about the value of academic research, and where the funding comes from. When federal funding is reduced, everyone looks to industry. But industry can’t make up the difference—they have their own mission and bottom line, and their horizon is much shorter than the horizon that academic researchers have enjoyed since the Vannevar Bush era.</p>
<p id="p-22">For computing, the added tension is that industry, with big compute and big data, has an edge over academia. Can we create new, more flexible, mutually beneficial models of engagement between big tech companies and academia?</p>
<p id="p-23">We’ve also lost the trust of the public in science. Unfortunately, AI has added to this mistrust.</p>
<p id="p-24">These are questions that I don’t have easy answers to, but they are fundamental to the future of the field.</p>
</section>
</div>
</article>
]]></content:encoded>
					
					<wfw:commentRss>https://cacm.acm.org/opinion/the-rise-of-computational-thinking-in-the-age-of-ai/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
		<post-id xmlns="com-wordpress:feed-additions:1">775520</post-id>	</item>
	</channel>
</rss>